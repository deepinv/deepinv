from __future__ import annotations
import torch
from einops import rearrange
import numpy as np
from math import ceil, floor
from deepinv.physics.generator import PhysicsGenerator
from deepinv.physics.functional import histogramdd, conv2d
from deepinv.physics.functional.interp import ThinPlateSpline
from deepinv.utils.decorators import _deprecated_alias



class PSFGenerator(PhysicsGenerator):
    r"""
    Base class for generating Point Spread Functions (PSFs).


    :param tuple psf_size: the shape of the generated PSF in 2D
        ``(kernel_size, kernel_size)``. If an `int` is given, it will be used for both dimensions.
    :param int num_channels: number of images channels. Defaults to 1.
    """

    def __init__(
        self,
        psf_size: tuple[int] = (31, 31),
        num_channels: int = 1,
        **kwargs,
    ) -> None:
        super().__init__(**kwargs)
        if isinstance(psf_size, int):
            psf_size = (psf_size, psf_size)

        self.shape = (num_channels,) + psf_size
        self.psf_size = psf_size
        self.num_channels = num_channels


class MotionBlurGenerator(PSFGenerator):
    r"""
    Random motion blur generator.

    See :footcite:t:`schuler2015learning` for more details.

    A blur trajectory is generated by sampling both its x- and y-coordinates independently
    from a Gaussian Process with a Matérn 3/2 covariance function.

    .. math::

        f_x(t), f_y(t) \sim \mathcal{GP}(0, k(t, t'))

    where :math:`k` is defined as

    .. math::

        k(t, s) = \sigma^2 \left( 1 + \frac{\sqrt{5} |t -s|}{l} + \frac{5 (t-s)^2}{3 l^2} \right) \exp \left(-\frac{\sqrt{5} |t-s|}{l}\right)

    :param tuple psf_size: the shape of the generated PSF in 2D, should be `(kernel_size, kernel_size)`
    :param int num_channels: number of images channels. Defaults to 1.
    :param float l: the length scale of the trajectory, defaults to 0.3
    :param float sigma: the standard deviation of the Gaussian Process, defaults to 0.25
    :param int n_steps: the number of points in the trajectory, defaults to 1000

    |sep|

    :Examples:

    >>> from deepinv.physics.generator import MotionBlurGenerator
    >>> generator = MotionBlurGenerator((5, 5), num_channels=1)
    >>> blur = generator.step()  # dict_keys(['filter'])
    >>> print(blur['filter'].shape)
    torch.Size([1, 1, 5, 5])
    """

    def __init__(
        self,
        psf_size: tuple,
        num_channels: int = 1,
        rng: torch.Generator = None,
        device: str = "cpu",
        dtype: type = torch.float32,
        l: float = 0.3,
        sigma: float = 0.25,
        n_steps: int = 1000,
    ) -> None:
        kwargs = {"l": l, "sigma": sigma, "n_steps": n_steps}
        if len(psf_size) != 2:
            raise ValueError(
                "psf_size must 2D. Add channels via num_channels parameter"
            )
        super().__init__(
            psf_size=psf_size,
            num_channels=num_channels,
            device=device,
            dtype=dtype,
            rng=rng,
            **kwargs,
        )

    def matern_kernel(self, diff, sigma: float = None, l: float = None):
        r"""
        Compute the Matérn 3/2 covariance.

        :param torch.Tensor diff: the difference `t - s`
        :param float sigma: the standard deviation of the Gaussian Process
        :param float l: the length scale of the trajectory
        """
        if sigma is None:
            sigma = self.sigma
        if l is None:
            l = self.l
        fraction = 5**0.5 * diff.abs() / l
        return sigma**2 * (1 + fraction + fraction**2 / 3) * torch.exp(-fraction)

    def f_matern(self, batch_size: int = 1, sigma: float = None, l: float = None):
        r"""
        Generates the trajectory.

        :param int batch_size: batch_size.
        :param float sigma: the standard deviation of the Gaussian Process.
        :param float l: the length scale of the trajectory.
        :return: the trajectory of shape `(batch_size, n_steps)`
        """
        vec = torch.randn(
            batch_size, self.n_steps, generator=self.rng, **self.factory_kwargs
        )
        time = torch.linspace(-torch.pi, torch.pi, self.n_steps, **self.factory_kwargs)[
            None
        ]

        kernel = self.matern_kernel(time, sigma, l)
        kernel_fft = torch.fft.rfft(kernel)
        vec_fft = torch.fft.rfft(vec)
        return torch.fft.irfft(vec_fft * torch.sqrt(kernel_fft)).real[
            :,
            torch.arange(self.n_steps // (2 * torch.pi), **self.factory_kwargs).type(
                torch.int
            ),
        ]

    def step(
        self,
        batch_size: int = 1,
        sigma: float = None,
        l: float = None,
        seed: int = None,
        **kwargs,
    ):
        r"""
        Generate a random motion blur PSF with parameters :math:`\sigma` and :math:`l`

        :param int batch_size: batch_size.
        :param float sigma: the standard deviation of the Gaussian Process
        :param float l: the length scale of the trajectory
        :param int seed: the seed for the random number generator.

        :return: dictionary with key `filter`: the generated PSF of shape `(batch_size, 1, psf_size[0], psf_size[1])`
        """
        self.rng_manual_seed(seed)
        f_x = self.f_matern(batch_size, sigma, l)[..., None]
        f_y = self.f_matern(batch_size, sigma, l)[..., None]

        trajectories = torch.cat(
            (
                f_x - torch.mean(f_x, dim=1, keepdim=True),
                f_y - torch.mean(f_y, dim=1, keepdim=True),
            ),
            dim=-1,
        )
        kernels = [
            histogramdd(trajectory, bins=list(self.psf_size), low=[-1, -1], upp=[1, 1])[
                None, None
            ]
            for trajectory in trajectories
        ]
        kernel = torch.cat(kernels, dim=0).to(**self.factory_kwargs)
        kernel = kernel / (torch.sum(kernel, dim=(-2, -1), keepdim=True) + 1e-6)
        return {
            "filter": kernel.expand(
                -1,
                self.num_channels,
                -1,
                -1,
            )
        }


class DiffractionBlurGenerator(PSFGenerator):
    r"""
    Diffraction limited blur generator.

    Generates 2D diffraction PSFs in optics using Zernike decomposition of the phase mask
    (Fresnel/Fraunhoffer diffraction theory).

    Zernike polynomials are a sequence of orthogonal polynomials defined on the unit disk.
    They are commonly used in optical systems to describe wavefront aberrations.

    The PSF :math:`h(\theta)` is defined as the squared magnitude of the Fourier transform of the pupil function :math:`\phi_{\theta}` as:

    .. math::

        h(\theta) = \left| \mathcal{F} \left( \exp \left( - i 2 \pi \phi_\theta \right) \right) \right|^2,

    where :math:`\phi_\theta : \mathbb{R}^2 \to \mathbb{R}` is defined as:

    .. math::
        \phi_\theta= \sum_{k \in K} \theta_k z_k

    is the phase aberration expressed in the Zernike basis, :math:`K` is set of indexes of Zernike polynomials used in the decomposition (equal to `zernike_index`).  
    See :footcite:t:`lakshminarayanan2011zernike` for more details.
    (`or this link <https://e-l.unifi.it/pluginfile.php/1055875/mod_resource/content/1/Appunti_2020_Lezione%2014_4_Zernikepolynomialsaguidefinal.pdf>`_). 
    
    The Zernike polynomials :math:`z_k` are indexed using the ``'noll'`` or ``'ansi'`` convention (defined by `index_convention` parameter).

    Conversion from the two conventions to the standard indexing can be done using the function :func:`deepinv.physics.generator.blur.zernike_index_conversion`.

    :param tuple psf_size: the shape ``H x W`` of the generated PSF in 2D
    :param int num_channels: number of images channels. Defaults to 1.
    :param tuple[int] zernike_index: tuple of activated Zernike coefficients in the following `index_convention` convention.
        Defaults to ``(4, 5, 6, 7, 8, 9, 10, 11)``, correspond to radial order `n` from 2 to 3 (included) and the spherical aberration.
        These correspond to the following aberrations: defocus, astigmatism, coma, trefoil and spherical aberration.
    :param float fc: cutoff frequency (NA/emission_wavelength) * pixel_size. Should be in ``[0, 0.25]``
        to respect the Shannon-Nyquist sampling theorem, defaults to ``0.2``.
    :param float max_zernike_amplitude: maximum amplitude of the Zernike coefficients, defaults to ``0.15``.
        The amplitude of each Zernike coefficient is sampled uniformly in ``[-max_zernike_amplitude/2, max_zernike_amplitude/2]``.
    :param tuple[int] pupil_size: this is used to synthesize the super-resolved pupil.
        The higher the more precise, defaults to ``(256, 256)``.
        If a single ``int`` is given, a square pupil is considered.
    :param bool apodize: whether to apodize the PSF to reduce ringing artifacts, defaults to ``False``.
    :param bool random_rotate: whether to randomly rotate the PSF, defaults to ``False``.
    :param str index_convention: the convention for the Zernike polynomials indexing. Can be either ``'noll'`` (default) or ``'ansi'``.
    :param str, torch.device device: device where the tensors are allocated and processed, defaults to ``'cpu'``.
    :param torch.dtype dtype: data type of the tensors, defaults to ``torch.float32``.
    :param torch.Generator rng: pseudo random number generator for reproducibility. Defaults to ``None``.

    |sep|

    :Examples:

    >>> from deepinv.physics.generator import DiffractionBlurGenerator
    >>> generator = DiffractionBlurGenerator((5, 5), num_channels=3)
    >>> blur = generator.step()  # dict_keys(['filter', 'coeff', 'pupil'])
    >>> print(blur['filter'].shape)
    torch.Size([1, 3, 5, 5])


    """

    @_deprecated_alias(list_param="zernike_index")
    def __init__(
        self,
        psf_size: tuple,
        num_channels: int = 1,
        zernike_index: tuple[int | str, ...] = tuple(range(4, 12)),
        fc: float = 0.2,
        max_zernike_amplitude: float = 0.15,
        pupil_size: tuple[int, ...] = (256, 256),
        apodize: bool = False,
        random_rotate: bool = False,
        index_convention: str = "noll",
        device: str | torch.device = "cpu",
        dtype: torch.dtype = torch.float32,
        rng: torch.Generator = None,
    ):
        super().__init__(
            psf_size=psf_size,
            num_channels=num_channels,
            device=device,
            dtype=dtype,
            rng=rng,
        )
        # For backward compatibility if a list / tuple of a string is given
        zernike_index = list(zernike_index)
        for i, index in enumerate(zernike_index):
            if isinstance(index, str):
                index = int(index[1:])  # Convert "Z4" to 4
            zernike_index[i] = index

        self.zernike_index = sorted(zernike_index)  # list of parameters to provide
        self.fc = fc
        self.max_zernike_amplitude = max_zernike_amplitude
        self.apodize = apodize
        self.random_rotate = random_rotate
        self.index_convention = index_convention

        if self.apodize:
            lin_0 = torch.linspace(
                -psf_size[0] // 2, psf_size[0] // 2, psf_size[0], **self.factory_kwargs
            )
            lin_1 = torch.linspace(
                -psf_size[1] // 2, psf_size[1] // 2, psf_size[1], **self.factory_kwargs
            )
            XX0, XX1 = torch.meshgrid(lin_0, lin_1, indexing="ij")
            dist = (XX0**2 + XX1**2) ** 0.5
            radius = min(psf_size) / 2
            apodize_length = 10
            self.apodize_mask = bump_function(
                dist, a=radius - apodize_length, b=apodize_length
            )
        else:
            self.apodize_mask = None

        pupil_size = (
            max(self.pupil_size[0], self.psf_size[0]),
            max(self.pupil_size[1], self.psf_size[1]),
        )
        self.pupil_size = pupil_size

        lin_x = torch.linspace(-0.5, 0.5, self.pupil_size[0], **self.factory_kwargs)
        lin_y = torch.linspace(-0.5, 0.5, self.pupil_size[1], **self.factory_kwargs)
        self.step_rho = lin_x[1] - lin_x[0]

        # Fourier plane is discretized on [-0.5,0.5]x[-0.5,0.5]
        XX, YY = torch.meshgrid(lin_x / self.fc, lin_y / self.fc, indexing="ij")
        self.register_buffer("rho", cart2pol(XX, YY))  # Cartesian coordinates
        self.register_buffer(
            "indicator_circ",
            bump_function(self.rho, 1 - self.step_rho / 2, b=self.step_rho / 2),
        )

        # In order to avoid layover in Fourier convolution we need to zero pad and then extract a part of image
        # computed from pupil_size and psf_size
        self.pad_pre = (
            ceil((self.pupil_size[0] - self.psf_size[0]) / 2),
            ceil((self.pupil_size[1] - self.psf_size[1]) / 2),
        )
        self.pad_post = (
            floor((self.pupil_size[0] - self.psf_size[0]) / 2),
            floor((self.pupil_size[1] - self.psf_size[1]) / 2),
        )

        # the number of Zernike coefficients
        self.n_zernike = len(self.zernike_index)

        # the tensor of Zernike polynomials in the pupil plane
        self.register_buffer(
            "Z",
            torch.zeros(
                (self.pupil_size[0], self.pupil_size[1], self.n_zernike),
                **self.factory_kwargs,
            ),
        )
        for k, index in enumerate(self.zernike_index):
            n, m = zernike_index_conversion(index, convention=index_convention)
            self.Z[:, :, k] = get_zernike_polynomial(
                n, m, XX, YY
            )  # defining the k-th Zernike polynomial

        self.to(device=device, dtype=dtype)

    def step(
        self,
        batch_size: int = 1,
        coeff: torch.Tensor = None,
        angle: torch.Tensor = None,
        seed: int = None,
        **kwargs,
    ):
        r"""
        Generate a batch of PFS with a batch of Zernike coefficients

        :param int batch_size: batch_size.
        :param torch.Tensor coeff: batch_size x len(zernike_index) coefficients of the Zernike decomposition (defaults is `None`)
        :param torch.Tensor angle: batch_size angles in degree to rotate the PSF (defaults is `None`)
        :param int seed: the seed for the random number generator.

        :return: dictionary with keys
            `filter`: tensor of size `(batch_size x num_channels x psf_size[0] x psf_size[1])` batch of PSFs,
            `coeff`: list of sampled Zernike coefficients in this realization,
            `pupil`: the pupil function,
            `angle`: the random rotation angle in degrees if `random_rotate` is `True`, `None` otherwise.
        :rtype: dict
        """

        self.rng_manual_seed(seed)
        if coeff is None:
            coeff = self.generate_coeff(batch_size)

        pupil = (self.Z @ coeff[:, : self.n_zernike].T).transpose(2, 0)
        pupil = torch.exp(-2.0j * torch.pi * pupil)
        pupil = pupil * self.indicator_circ
        psf = torch.fft.ifftshift(torch.fft.fft2(torch.fft.fftshift(pupil)))
        psf = torch.real(psf * torch.conj(psf))
        psf = psf[
            :,
            self.pad_pre[0] : self.pupil_size[0] - self.pad_post[0],
            self.pad_pre[1] : self.pupil_size[1] - self.pad_post[1],
        ].unsqueeze(1)

        # random rotate the PSF if angle is given
        if self.random_rotate:
            if angle is None:
                angle = self.generate_angles(batch_size)
            psf = rotate_image_via_shear(psf, angle)

        if self.apodize:
            psf = self.apodize_mask * psf

        psf = psf / torch.sum(psf, dim=(-1, -2), keepdim=True)
        return {
            "filter": psf.expand(-1, self.shape[0], -1, -1),
            "coeff": coeff,
            "pupil": pupil,
            "angle": angle if self.random_rotate else None,
        }

    def generate_coeff(self, batch_size):
        r"""Generates random coefficients of the decomposition in the Zernike polynomials.

        :param int batch_size: batch_size.

        :return: a tensor of shape `(batch_size, len(zernike_index))` coefficients in the Zernike decomposition.

        """
        coeff = torch.rand(
            (batch_size, len(self.zernike_index)),
            generator=self.rng,
            **self.factory_kwargs,
        )
        coeff = (coeff - 0.5) * self.max_zernike_amplitude
        return coeff

    def generate_angles(self, batch_size):
        r"""
        Generates random angles for the rotation of the PSF.

        :param int batch_size: batch_size.

        :return: a tensor of shape `(batch_size,)` angles in degrees.
        """
        return torch.rand(batch_size, generator=self.rng, **self.factory_kwargs) * 360


def get_zernike_polynomial(
    n: int, m: int, x: torch.Tensor, y: torch.Tensor
) -> torch.Tensor:
    r"""
    Define the Zernike polynomial of radial order :math:`n` and angular (or azimuthal) frequency :math:`m`.

    The Zernike polynomials are a sequence of orthogonal polynomials defined on the unit disk.
    They are commonly used in optical systems to describe wavefront aberrations.

    This function implements the Zernike polynomials up to order 7 using explicit formulas from :footcite:t:`lakshminarayanan2011zernike`
    (see `this link <https://e-l.unifi.it/pluginfile.php/1055875/mod_resource/content/1/Appunti_2020_Lezione%2014_4_Zernikepolynomialsaguidefinal.pdf>`_).

    :param int n: the radial order of the Zernike polynomial (`n >= 0`)
    :param int m: the angular frequency of the Zernike polynomial (`-n <= m <= n` and `n - m` is even)
    :param torch.Tensor x: x coordinates in the polar plane of any shape.
    :param torch.Tensor y: y coordinates in the polar plane of any shape.

    :return: the Zernike polynomial evaluated at `(x, y)` of the same shape as `x` and `y`.
    """
    out_of_range_error_message = f"The value of m={m} is not valid for n={n}. It should be in the range -n <= m <= n and n - m should be even."
    if n == 0:
        if m == 0:
            return torch.ones_like(x) * (2**0.5)
        else:
            raise ValueError(out_of_range_error_message)
    elif n == 1:
        if m == -1:
            return 2 * x
        elif m == 1:
            return 2 * y
        else:
            raise ValueError(out_of_range_error_message)
    elif n == 2:
        if m == -2:
            return 6**0.5 * 2 * x * y
        elif m == 0:
            return 3**0.5 * (-1 + 2 * x**2 + 2 * y**2)
        elif m == 2:
            return 6**0.5 * (-(x**2) + y**2)
        else:
            raise ValueError(out_of_range_error_message)
    elif n == 3:
        rms = 2 * 2**0.5
        if m == -3:
            return rms * (-(x**3) + 3 * x * y**2)
        elif m == -1:
            return rms * (-2 * x + 3 * x**3 + 3 * x * y**2)
        elif m == 1:
            return rms * (-2 * y + 3 * y**3 + 3 * x**2 * y)
        elif m == 3:
            return rms * (y**3 - 3 * x**2 * y)
        else:
            raise ValueError(out_of_range_error_message)
    elif n == 4:
        sq10 = 10**0.5
        sq5 = 5**0.5
        if m == -4:
            return sq10 * (-4 * x**3 * y + 4 * x * y**3)
        elif m == -2:
            return sq10 * (-6 * x * y + 8 * x**3 * y + 8 * x * y**3)
        elif m == 0:
            return sq5 * (
                1 - 6 * x**2 - 6 * y**2 + 6 * x**4 + 12 * x**2 * y**2 + 6 * y**4
            )
        elif m == 2:
            return sq10 * (3 * x**2 - 3 * y**2 - 4 * x**4 + 4 * y**4)
        elif m == 4:
            return sq10 * (x**4 - 6 * x**2 * y**2 + y**4)
        else:
            raise ValueError(out_of_range_error_message)
    elif n == 5:
        rms = 2 * 3**0.5
        if m == -5:
            return rms * (x**5 - 10 * x**3 * y**2 + 5 * x * y**4)
        elif m == -3:
            return rms * (
                4 * x**3 - 12 * x * y**2 - 5 * x**5 + 10 * x**3 * y**2 + 15 * x * y**4
            )
        elif m == -1:
            return rms * (
                3 * x
                - 12 * x**3
                - 12 * x * y**2
                + 10 * x**5
                + 20 * x**3 * y**2
                + 10 * x * y**4
            )
        elif m == 1:
            return rms * (
                3 * y
                - 12 * y**3
                - 12 * x**2 * y
                + 10 * y**5
                + 20 * x**2 * y**3
                + 10 * x**4 * y
            )
        elif m == 3:
            return rms * (
                -4 * y**3 + 12 * x**2 * y + 5 * y**5 - 10 * x**2 * y**3 - 15 * x**4 * y
            )
        elif m == 5:
            return rms * (y**5 - 10 * x**2 * y**3 + 5 * x**4 * y)
        else:
            raise ValueError(out_of_range_error_message)
    elif n == 6:
        sq14 = 14**0.5
        sq7 = 7**0.5
        if m == -6:
            return sq14 * (6 * x**5 * y - 20 * x**3 * y**3 + 6 * x * y**5)
        elif m == -4:
            return sq14 * (
                20 * x**3 * y - 20 * x * y**3 - 24 * x**5 * y + 24 * x * y**5
            )
        elif m == -2:
            return sq14 * (
                12 * x * y
                - 40 * x**3 * y
                - 40 * x * y**3
                + 30 * x**5 * y
                + 60 * x**3 * y**3
                + 30 * x * y**5
            )  # There is a sign error in the last term of the paper (TAB 1)
        elif m == 0:
            return sq7 * (
                -1
                + 12 * x**2
                + 12 * y**2
                - 30 * x**4
                - 60 * x**2 * y**2
                - 30 * y**4
                + 20 * x**6
                + 60 * x**4 * y**2
                + 60 * x**2 * y**4
                + 20 * y**6
            )
        elif m == 2:
            return sq14 * (
                -6 * x**2
                + 6 * y**2
                + 20 * x**4
                - 20 * y**4
                - 15 * x**6
                - 15 * x**4 * y**2
                + 15 * x**2 * y**4
                + 15 * y**6
            )
        elif m == 4:
            return sq14 * (
                -5 * x**4
                + 30 * x**2 * y**2
                - 5 * y**4
                + 6 * x**6
                - 30 * x**4 * y**2
                - 30 * x**2 * y**4
                + 6 * y**6
            )
        elif m == 6:
            return sq14 * (-(x**6) + 15 * x**4 * y**2 - 15 * x**2 * y**4 + y**6)
        else:
            raise ValueError(out_of_range_error_message)
    elif n == 7:
        rms = 4
        if m == -7:
            return rms * (-(x**7) + 21 * x**5 * y**2 - 35 * x**3 * y**4 + 7 * x * y**6)
        elif m == -5:
            return rms * (
                -6 * x**5
                + 60 * x**3 * y**2
                - 30 * x * y**4
                + 7 * x**7
                - 63 * x**5 * y**2
                - 35 * x**3 * y**4
                + 35 * x * y**6
            )
        elif m == -3:
            return rms * (
                -10 * x**3
                + 30 * x * y**2
                + 30 * x**5
                - 60 * x**3 * y**2
                - 90 * x * y**4
                - 21 * x**7
                + 21 * x**5 * y**2
                + 105 * x**3 * y**4
                + 63 * x * y**6
            )
        elif m == -1:
            return rms * (
                -4 * x
                + 30 * x**3
                + 30 * x * y**2
                - 60 * x**5
                - 120 * x**3 * y**2
                - 60 * x * y**4
                + 35 * x**7
                + 105 * x**5 * y**2
                + 105 * x**3 * y**4
                + 35 * x * y**6
            )
        elif m == 1:
            return rms * (
                -4 * y
                + 30 * y**3
                + 30 * x**2 * y
                - 60 * y**5
                - 120 * x**2 * y**3
                - 60 * x**4 * y
                + 35 * y**7
                + 105 * x**2 * y**5
                + 105 * x**4 * y**3
                + 35 * x**6 * y
            )
        elif m == 3:
            return rms * (
                10 * y**3
                - 30 * x**2 * y
                - 30 * y**5
                + 60 * x**2 * y**3
                + 90 * x**4 * y
                + 21 * y**7
                - 21 * x**2 * y**5
                - 105 * x**4 * y**3
                - 63 * x**6 * y
            )  # There is a sign error in the last term of the paper (TAB 1)
        elif m == 5:
            return rms * (
                -6 * y**5
                + 60 * x**2 * y**3
                - 30 * x**4 * y
                + 7 * y**7
                - 63 * x**2 * y**5
                - 35 * x**4 * y**3
                + 35 * x**6 * y
            )
        elif m == 7:
            return rms * (y**7 - 21 * x**2 * y**5 + 35 * x**4 * y**3 - 7 * x**6 * y)
        else:
            raise ValueError(out_of_range_error_message)

    else:
        # For higher order polynomials, explicit formulas are not implemented here.
        # We fall back to the general definition using recursion.
        # TODO
        pass


def zernike_index_conversion(index, convention="ansi"):
    r"""
    Converts a single index for Zernike polynomials between different conventions.
    For more details on the conventions, see `wikipedia <https://en.wikipedia.org/wiki/Zernike_polynomials#Zernike_polynomials>`_.

    :param int index: the single index of the Zernike polynomial.
    :param str convention: the convention to convert to. Currently only 'ansi' (for OSA/ANSI standard indices) and 'noll' (for Noll's sequential indices) are implemented.

    Single index for Zernike polynomials:
    """
    # For ansi, we implement the following conversion:
    # https://en.wikipedia.org/wiki/Zernike_polynomials#OSA/ANSI_standard_indices
    if convention.lower() == "ansi":
        n = floor((2 * index + 0.25) ** 0.5 - 0.5)
        m = 2 * index - n * (n + 2)
        return n, m

    # For Noll's sequential indices, we refer to the following link:
    # https://en.wikipedia.org/wiki/Zernike_polynomials#Noll's_sequential_indices
    # The formula is taken from: https://oeis.org/A375779/a375779.pdf
    elif convention.lower() == "noll":
        if index < 1:
            raise ValueError("Noll index must be >= 1")

        n = floor((2 * (index - 1) + 0.25) ** 0.5 - 0.5)
        m = n % 2 + 2 * floor((index - n * (n + 1) / 2 - 1 + (n + 1) % 2) / 2)
        # Correct sign of m
        m = m * (-1) ** index

        return n, m
    else:
        raise NotImplementedError("Only 'ansi' and 'noll' conventions are implemented.")


def rotate_image_via_shear(image: torch.Tensor, angle_deg: torch.Tensor, center=None):
    r"""
    2D rotation of image by angle via shear composition through FFT.

    :param torch.Tensor image: input image of shape (B,C,H,W)
    :param torch.Tensor angle_deg: input rotation angles in degrees of shape (B,)
    :return: torch.Tensor containing the rotated images of shape (B, C, H, W )
    """
    # Convert angle to radians
    angle = torch.deg2rad(angle_deg)
    N0, N1 = image.shape[-2:]
    if center is None:
        center = (N0 // 2, N1 // 2)

    mask_angles = (angle > torch.pi / 2.0) & (angle <= 3 * torch.pi / 2)

    angle[angle > 3 * torch.pi / 2] -= 2 * torch.pi

    transformed_image = (
        torch.zeros_like(image).expand(mask_angles.shape[0], -1, -1, -1).clone()
    )
    expanded_image = image.clone().expand(mask_angles.shape[0], -1, -1, -1).clone()
    transformed_image[~mask_angles] = expanded_image[~mask_angles]
    transformed_image[mask_angles] = torch.rot90(
        expanded_image[mask_angles], k=-2, dims=(-2, -1)
    )

    angle[mask_angles] -= torch.pi

    tant2 = -torch.tan(-angle / 2)
    st = torch.sin(-angle)

    def shearx(image, shear):
        fft1 = torch.fft.fft2(image, dim=(-1))
        freq_1 = torch.fft.fftfreq(N1, d=1.0, device=image.device)
        freq_0 = (
            shear[:, None] * (torch.arange(N0, device=image.device) - center[0])[None]
        )
        phase_shift = torch.exp(
            -2j * torch.pi * freq_0[..., None] * freq_1[None, None, :]
        )
        image_shear = fft1 * phase_shift[:, None]
        return torch.abs(torch.fft.ifft2(image_shear, dim=(-1)))

    def sheary(image, shear):
        fft0 = torch.fft.fft2(image, dim=(-2))
        freq_0 = torch.fft.fftfreq(N0, d=1.0, device=image.device)
        freq_1 = (
            shear[:, None] * (torch.arange(N1, device=image.device) - center[1])[None]
        )
        phase_shift = torch.exp(
            -2j * torch.pi * freq_0[None, :, None] * freq_1[:, None, :]
        )
        image_shear = fft0 * phase_shift[:, None]
        return torch.abs(torch.fft.ifft2(image_shear, dim=(-2)))

    rot = shearx(sheary(shearx(transformed_image, tant2), st), tant2)
    return rot


def cart2pol(x, y):
    r"""
    Cartesian to polar coordinates

    :param torch.Tensor x: x coordinates
    :param torch.Tensor y: y coordinates

    :return: rho of torch.Tensor of radius
    :rtype: tuple
    """

    rho = torch.sqrt(x**2 + y**2)
    return rho


def bump_function(x, a=1.0, b=1.0):
    r"""
    Defines a function which is 1 on the interval [-a,a]
    and goes to 0 smoothly on [-a-b,-a]U[a,a+b] using a bump function
    For the discretization of indicator functions, we advise b=1, so that
    a=0, b=1 yields a bump.

    :param torch.Tensor x: tensor of arbitrary size
        input.
    :param Float a: radius (default is 1)
    :param Float b: interval on which the function goes to 0. (default is 1)

    :return: the bump function sampled at points x
    :rtype: torch.Tensor

    :Examples:

    >>> import deepinv as dinv
    >>> x = torch.linspace(-15, 15, 31)
    >>> X, Y = torch.meshgrid(x, x, indexing = 'ij')
    >>> R = torch.sqrt(X**2 + Y**2)
    >>> Z = bump_function(R, 3, 1)
    >>> Z = Z / torch.sum(Z)
    """
    v = torch.zeros_like(x)
    v[torch.abs(x) <= a] = 1
    I = (torch.abs(x) > a) * (torch.abs(x) < a + b)
    v[I] = torch.exp(-1.0 / (1.0 - ((torch.abs(x[I]) - a) / b) ** 2)) / np.exp(-1.0)
    return v


class ProductConvolutionBlurGenerator(PhysicsGenerator):
    r"""
    Generates parameters of space-varying blurs.

    Parameters generated:

    -`'filters'`: tensor of shape ``(B, C, n_eigen_psf, psf_size, psf_size)``
    - 'multipliers': tensor of shape ``(B, C, n_eigen_psf, H, W)``

    See :class:`deepinv.physics.SpaceVaryingBlur` for more details.

    :param deepinv.physics.generator.PSFGenerator psf_generator: A PSF generator, such as :class:`motion blur <deepinv.physics.generator.MotionBlurGenerator>` or
        :class:`diffraction blur generator <deepinv.physics.generator.DiffractionBlurGenerator>`.
    :param tuple img_size: image size ``(H,W)``.
    :param int n_eigen_psf: each PSF in the field of view will be a linear combination of ``n_eigen_psf`` eigen PSF grids.
        Defaults to 10.
    :param tuple spacing: steps between the PSF grids used for interpolation (defaults ``(H//8, W//8)``).
    :param str padding: boundary conditions in (options = ``'valid'``, ``'circular'``, ``'replicate'``, ``'reflect'``).
        Defaults to ``'valid'``.

    |sep|

    :Examples:

    >>> from deepinv.physics.generator import DiffractionBlurGenerator
    >>> from deepinv.physics.generator import ProductConvolutionBlurGenerator
    >>> psf_size = 7
    >>> psf_generator = DiffractionBlurGenerator((psf_size, psf_size), fc=0.25)
    >>> pc_generator = ProductConvolutionBlurGenerator(psf_generator, img_size=(64, 64), n_eigen_psf=8)
    >>> params = pc_generator.step(1)
    >>> print(params.keys())
    dict_keys(['filters', 'multipliers'])

    """

    def __init__(
        self,
        psf_generator: PSFGenerator,
        img_size: tuple[int],
        n_eigen_psf: int = 10,
        spacing: tuple[int] = None,
        device: str = "cpu",
        **kwargs,
    ) -> None:
        super().__init__(device=device, **kwargs)
        if isinstance(img_size, int):
            img_size = (img_size, img_size)
        if isinstance(spacing, int):
            spacing = (spacing, spacing)

        self.psf_generator = psf_generator
        self.img_size = img_size
        self.n_eigen_psf = n_eigen_psf
        self.spacing = (
            spacing
            if spacing is not None
            else (self.img_size[0] // 8, self.img_size[1] // 8)
        )

        self.n_psf_prid = (self.img_size[0] // self.spacing[0]) * (
            self.img_size[1] // self.spacing[1]
        )
        assert (
            self.n_psf_prid >= self.n_eigen_psf
        ), f"n_eigen_psf={n_eigen_psf} must be smaller than the number of PSF grid points = {self.n_psf_prid}"

        # Interpolating the psf_grid coefficients with thin plate splines
        T0 = torch.linspace(
            0, 1, self.img_size[0] // self.spacing[0], **self.factory_kwargs
        )
        T1 = torch.linspace(
            0, 1, self.img_size[1] // self.spacing[1], **self.factory_kwargs
        )
        yy, xx = torch.meshgrid(T0, T1, indexing="ij")
        self.X = torch.stack((yy.flatten(), xx.flatten()), dim=1)

        T0 = torch.linspace(0, 1, self.img_size[0], **self.factory_kwargs)
        T1 = torch.linspace(0, 1, self.img_size[1], **self.factory_kwargs)
        yy, xx = torch.meshgrid(T0, T1, indexing="ij")
        self.XX = torch.stack((yy.flatten(), xx.flatten()), dim=1)

        self.tps = ThinPlateSpline(0.0, **self.factory_kwargs)

    def step(self, batch_size: int = 1, seed: int = None, **kwargs):
        r"""
        Generates a random set of filters and multipliers for space-varying blurs.

        :param int batch_size: number of space-varying blur parameters to generate.
        :param int seed: the seed for the random number generator.

        :returns: a dictionary containing filters, multipliers and paddings.
            filters: a tensor of shape (B, C, n_eigen_psf, psf_size, psf_size).
            multipliers: a tensor of shape (B, C, n_eigen_psf, H, W).
        """
        self.rng_manual_seed(seed)
        self.psf_generator.rng_manual_seed(seed)

        # Generating psf_grid on a grid
        psf_grid = self.psf_generator.step(self.n_psf_prid * batch_size)["filter"]
        psf_size = psf_grid.shape[-2:]
        channels = psf_grid.shape[1]
        psf_grid = psf_grid.view(
            batch_size, self.n_psf_prid, channels, *psf_size
        )  # B x n_psf_prid x C x psf_size x psf_size

        # Computing the eigen-PSF
        psf_grid = psf_grid.flatten(-2, -1).transpose(
            1, 2
        )  # B x C x n_psf_prid x (psf_size*psf_size)
        _, _, V = torch.linalg.svd(psf_grid, full_matrices=False)
        n_eigen_chosen = min(self.n_eigen_psf, V.size(-2))
        V = V[..., :n_eigen_chosen, :]  # B x C x n_eigen_psf x (psf_size*psf_size)
        coeffs = torch.matmul(
            psf_grid, V.transpose(-1, -2)
        )  # B x C x n_psf_prid x n_eigen_psf
        eigen_psf = V.reshape(V.size(0), channels, n_eigen_chosen, *psf_size)

        # compute multipliers by interpolating the coeffs with thin-plate splines
        self.tps.fit(self.X, coeffs)
        w = self.tps.transform(self.XX).transpose(-1, -2)
        w = w.reshape(w.size(0), channels, n_eigen_chosen, *self.img_size)

        # Ending
        params_blur = {"filters": eigen_psf, "multipliers": w}
        return params_blur


class DiffractionBlurGenerator3D(PSFGenerator):
    r"""
    3D diffraction limited kernels using Zernike decomposition of the phase mask.

    Fresnel/Fraunhoffer diffraction theory, this class uses :class:`deepinv.physics.generator.DiffractionBlurGenerator` under the hood to generate the pupil function. Refer to its documentation for more details.

    :param tuple psf_size: give in the order (depth, height, width)
    :param int num_channels: number of channels. Default to 1.
    :param tuple[int] zernike_index: list of activated Zernike coefficients.
    :param float fc: cutoff frequency (NA/emission_wavelength) * pixel_size. Should be in `[0, 1/4]` to respect Shannon, defaults to `0.2`
    :param float kb: wave number (NI/emission_wavelength) * pixel_size or (NA/NI) * fc. Must be greater than `fc`. Defaults to `0.3`.
    :param float max_zernike_amplitude: maximum amplitude of Zernike coefficients. Defaults to 0.15.
    :param tuple[int] pupil_size: this is used to synthesize the super-resolved pupil. The higher the more precise, defaults to `(512, 512)`.
        If an `int` is given, a square pupil is considered.
    :param bool apodize: whether to apodize the PSF to reduce ringing effects. Defaults to `False`.
    :param bool random_rotate: whether to randomly rotate the PSF in the xy plane. Defaults to `False`.
    :param float stepz_pixel: Ratio between the physical size of the z direction to that in the x/y direction of the voxels in the 3D image.
        Defaults to 1.0.
    :param str index_convention: convention for the Zernike indices, either ``'noll'`` (default) or ``'ansi'``.
    :param torch.Generator rng: random number generator (default to `None`).
    :param str device: device (default to ``'cpu'``).
    :param type dtype: data type (default to `torch.float32`).
    :param kwargs: additional arguments for :class:`deepinv.physics.generator.DiffractionBlurGenerator`.
    
    .. note::

        NA: numerical aperture, NI: refraction index of the immersion medium,
        emission_wavelength: wavelength of the light,
        pixel_size: physical size of the pixels in the xy plane
        in the same unit as emission_wavelength

    |sep|

    :Examples:

    >>> import torch
    >>> from deepinv.physics.generator import DiffractionBlurGenerator3D
    >>> generator = DiffractionBlurGenerator3D((21, 51, 51), stepz_pixel = 2, zernike_index=(0,))
    >>> dict = generator.step()
    >>> filter = dict['filter']
    >>> print(filter.shape)
    torch.Size([1, 1, 21, 51, 51])
    >>> batch_size = 2
    >>> n_zernike = len(generator.generator2d.zernike_index)
    >>> dict = generator.step(batch_size=batch_size, coeff=0.1 * torch.rand(batch_size, n_zernike, **generator.factory_kwargs))
    >>> dict.keys()
    dict_keys(['filter', 'pupil', 'coeff'])


    """

    @_deprecated_alias(list_param="zernike_index")
    def __init__(
        self,
        psf_size: tuple,
        num_channels: int = 1,
        zernike_index: tuple[int | str, ...] = tuple(range(4, 12)),
        fc: float = 0.2,
        kb: float = 0.25,
        max_zernike_amplitude: float = 0.15,
        pupil_size: tuple[int] = (512, 512),
        apodize: bool = False,
        random_rotate: bool = False,
        stepz_pixel: float = 1.0,
        index_convention: str = "noll",
        rng: torch.Generator = None,
        device: str = "cpu",
        dtype: type = torch.float32,
        **kwargs,
    ):
        if len(psf_size) != 3:
            raise ValueError(
                "You should provide a tuple of len == 3 to generate 3D PSFs."
            )

        super().__init__(device=device, dtype=dtype, rng=rng)

        self.generator2d = DiffractionBlurGenerator(
            psf_size=psf_size[1:],
            num_channels=num_channels,
            zernike_index=zernike_index,
            fc=fc,
            max_zernike_amplitude=max_zernike_amplitude,
            pupil_size=pupil_size,
            device=device,
            dtype=dtype,
            rng=rng,
            index_convention=index_convention,
            **kwargs,
        )
        self.apodize = apodize
        self.random_rotate = random_rotate
        self.stepz_pixel = stepz_pixel
        self.kb = kb
        self.nzs = self.psf_size[0]
        self.defocus = (
            torch.linspace(
                -self.nzs / 2, self.nzs / 2, self.nzs, device=device, dtype=dtype
            )[:, None, None]
            * self.stepz_pixel
        )
        self.to(device=device, dtype=dtype)

    def step(
        self,
        batch_size: int = 1,
        coeff: torch.Tensor = None,
        angle: torch.Tensor = None,
        seed: int = None,
        **kwargs,
    ):
        r"""
        Generate a batch of PSF with a batch of Zernike coefficients

        :param int batch_size: number of PSFs to generate.
        :param torch.Tensor coeff: tensor of size (batch_size x len(zernike_index)) containing the Zernike coefficients.
            If `None`, random coefficients are generated.
        :param int seed: the seed for the random number generator.

        :return: dictionary with keys
            `filter`: tensor of size `(batch_size x num_channels x psf_size[0] x psf_size[1])` batch of PSFs,
            `pupil`: the pupil function,
            `coeff`: list of sampled Zernike coefficients in this realization,
            `angle`: the random rotation angles in degrees if `random_rotate` is `True`, `None` otherwise.
        :rtype: dict
        """
        gen_dict = self.generator2d.step(
            batch_size=batch_size, coeff=coeff, seed=seed, **kwargs
        )

        pupil = gen_dict["pupil"]
        d = ((self.kb) ** 2 - (self.generator2d.rho * self.fc) ** 2 + 0j) ** 0.5

        propKer = torch.exp(-1j * 2 * torch.pi * d * self.defocus) + 0j
        p = pupil[:, None, ...] * propKer[None, ...]
        p[torch.isnan(p)] = 0
        pshift = torch.fft.fftshift(p, dim=(-2, -1))
        pfft = torch.fft.fft2(pshift, dim=(-2, -1))
        psf = torch.fft.ifftshift(pfft, dim=(-2, -1))
        psf = torch.real(psf * torch.conj(psf))

        psf = psf[
            :,
            :,
            self.generator2d.pad_pre[0] : self.generator2d.pupil_size[0]
            - self.generator2d.pad_post[0],
            self.generator2d.pad_pre[1] : self.generator2d.pupil_size[1]
            - self.generator2d.pad_post[1],
        ].unsqueeze(1)

        if self.random_rotate:
            if angle is None:
                angle = self.generator2d.generate_angles(batch_size)

            psf = rotate_image_via_shear(
                rearrange(psf, "b c d h w -> b (c d) h w"), angle
            )
            psf = rearrange(psf, "b (c d) h w -> b c d h w", d=self.psf_size[0])

        if self.apodize:
            psf = self.generator2d.apodize_mask[None, None, None] * psf
        psf = psf / torch.sum(psf, dim=(-3, -2, -1), keepdim=True)

        return {
            "filter": psf.expand(-1, self.shape[0], -1, -1, -1),
            "pupil": pupil,
            "coeff": gen_dict["coeff"],
            "angle": angle if self.random_rotate else None,
        }


class ConfocalBlurGenerator3D(PSFGenerator):
    r"""
    Generates the 3D point spread function of a confocal laser scanning microsope.

    :param tuple psf_size: give in the order (depth, height, width)
    :param int num_channels: number of channels. Default to 1.
    :param tuple[int] zernike_index: tuple of activated Zernike index, defaults to ``(4, 5, 6, 7, 8, 9, 10, 11)``.
    :param float NI: Refractive index of  the immersion medium. Defaults to 1.51 (oil),
    :param float NA: Numerical aperture. Should be less than NI. Defaults to 1.37.
    :param float lambda_ill: Wavelength of the illumination light (fluorescence excitation). Defaults to 489e-9.
    :param float lambda_coll: Wavelength of the collection light (fluorescence emission). Defaults to 395e-9.
    :param float pixelsize_XY: Physical pixel size in the lateral direction (height, width). Defaults to 50e-9.
    :param float pixelsize_Z:  Physical pixel size in the axial direction (depth). Defaults to 100e-9.
    :param float pinhole_radius: Radius of pinhole in Airy units. Defaults to 1.
    :param float max_zernike_amplitude: maximum amplitude of Zernike coefficients. Defaults to 0.1.
    :param tuple[int] pupil_size: this is used to synthesize the super-resolved pupil. The higher the more precise, defaults to (512, 512).
            If an int is given, a square pupil is considered.
    :param torch.Generator rng: random number generator (default to `None`).
    :param str device: device (default to `cpu`).
    :param type dtype: data type (default to `torch.float32`).

    |sep|

    :Examples:

    >>> import torch
    >>> from deepinv.physics.generator import ConfocalBlurGenerator3D
    >>> generator = ConfocalBlurGenerator3D((21, 51, 51), zernike_index=['Z0'])
    >>> dict = generator.step()
    >>> filter = dict['filter']
    >>> print(filter.shape)
    torch.Size([1, 1, 21, 51, 51])
    >>> batch_size = 2
    >>> n_zernike = len(generator.generator_ill.generator2d.zernike_index)
    >>> dict = generator.step(batch_size=batch_size,
    ...                       coeff_ill = 0.1 * torch.rand(batch_size, n_zernike, **generator.factory_kwargs),
    ...                       coeff_coll = 0.1 * torch.rand(batch_size, n_zernike, **generator.factory_kwargs))
    >>> dict.keys()
    dict_keys(['filter', 'coeff_ill', 'coeff_coll'])

    """

    @_deprecated_alias(list_param="zernike_index")
    def __init__(
        self,
        psf_size: tuple,
        num_channels: int = 1,
        zernike_index: tuple[int | str, ...] = tuple(range(4, 12)),
        NI: float = 1.51,
        NA: float = 1.37,
        lambda_ill: float = 489e-9,
        lambda_coll: float = 395e-9,
        pixelsize_XY: float = 50e-9,
        pixelsize_Z: float = 100e-9,
        pinhole_radius: float = 1,
        max_zernike_amplitude: float = 0.1,
        pupil_size: tuple[int] = (512, 512),
        device: str = "cpu",
        dtype: type = torch.float32,
        rng: torch.Generator = None,
        **kwargs,
    ):
        if len(psf_size) != 3:
            raise ValueError(
                "You should provide a tuple of len == 3 to generate 3D PSFs."
            )

        super().__init__()

        self.fc_ill = (
            NA / lambda_ill
        ) * pixelsize_XY  # cutoff frequency for illumination
        self.kb_ill = (NI / lambda_ill) * pixelsize_XY  # wavenumber for illumination

        self.fc_coll = (
            NA / lambda_coll
        ) * pixelsize_XY  # cutoff freauency for collection
        # wavenumber for collection
        self.kb_coll = (NI / lambda_coll) * pixelsize_XY  # wavenumber for collection
        self.pinhole_radius = pinhole_radius
        self.pixelsize_XY = pixelsize_XY
        self.pixel_size_Z = pixelsize_Z

        self.lambda_ill = lambda_ill
        self.lambda_coll = lambda_coll
        self.NI = NI
        self.NA = NA

        # Initialize generator for the Illumniation PSF
        self.generator_ill = DiffractionBlurGenerator3D(
            psf_size=psf_size,
            num_channels=num_channels,
            fc=self.fc_ill,
            kb=self.kb_ill,
            stepz_pixel=int(pixelsize_Z / pixelsize_XY),
            zernike_index=zernike_index,
            max_zernike_amplitude=max_zernike_amplitude,
            pupil_size=pupil_size,
            rng=rng,
            device=device,
            dtype=dtype,
        )

        # Initialize generator for the Collection PSF
        self.generator_coll = DiffractionBlurGenerator3D(
            psf_size=psf_size,
            num_channels=num_channels,
            fc=self.fc_coll,
            kb=self.kb_coll,
            stepz_pixel=int(pixelsize_Z / pixelsize_XY),
            zernike_index=zernike_index,
            max_zernike_amplitude=max_zernike_amplitude,
            pupil_size=pupil_size,
            rng=rng,
            device=device,
            dtype=dtype,
        )
        self.to(device=device, dtype=dtype)

    def step(
        self,
        batch_size: int = 1,
        coeff_ill: torch.Tensor = None,
        coeff_coll: torch.Tensor = None,
        **kwargs,
    ):
        r"""
        Generate a batch of 3D confocal PSF with a batch of Zernike coefficients
        for illumination and collection
        
        :param int batch_size: number of PSFs to generate.
        :param torch.Tensor coeff_ill: tensor of size (batch_size x len(zernike_index)) containing the Zernike coefficients for illumination.
            If `None`, random coefficients are generated.
        :param torch.Tensor coeff_coll: tensor of size (batch_size x len(zernike_index)) containing the Zernike coefficients for collection. 
            If `None`, random coefficients are generated.

        :return: dictionary with keys
            `filter`: tensor of size `(batch_size x num_channels x psf_size[0] x psf_size[1])` batch of PSFs,
            `coeff_ill`: list of sampled Zernike coefficients in this realization of illumination,
            `coeff_coll`: list of sampled Zernike coefficients in this realization of collection,

        :rtype: dict
        """
        dict_ill = self.generator_ill.step(
            batch_size=batch_size, coeff=coeff_ill
        )  # generate illumuinition PSF
        psf_ill = dict_ill["filter"]
        coeff_ill = dict_ill["coeff"]
        dict_coll = self.generator_coll.step(
            batch_size=batch_size, coeff=coeff_coll
        )  # generate collection PSF
        psf_coll = dict_coll["filter"]
        coeff_coll = dict_coll["coeff"]

        # convolution of the collection PSF by pinhole
        # 1. Define the pinhole D
        airy_unit = 0.61 * self.lambda_coll / self.NA
        PH_radius = self.pinhole_radius * airy_unit
        lin_x = torch.linspace(
            -1.5 * PH_radius,
            1.5 * PH_radius,
            int(3 * PH_radius / self.pixelsize_XY),
            **self.factory_kwargs,
        )
        lin_y = torch.linspace(
            -1.5 * PH_radius,
            1.5 * PH_radius,
            int(3 * PH_radius / self.pixelsize_XY),
            **self.factory_kwargs,
        )
        PH_step_rho = lin_x[1] - lin_x[0]
        # The plane is discretized on [-1.5 * r_pinhole, 1.5 * r_pinhole] x  [-1.5 * r_pinhole, 1.5 * r_pinhole]
        XX, YY = torch.meshgrid(lin_x, lin_y, indexing="ij")
        PH_rho = torch.sqrt(XX**2 + YY**2)  # Cartesian coordinates
        D = bump_function(
            PH_rho, PH_radius - PH_step_rho / 2, b=PH_step_rho / 2
        )  # D(r) in equation

        # 2. Apply 2D convolution in all z planes
        psf_coll_convolved = torch.zeros(psf_coll.shape, **self.factory_kwargs)
        for i in range(psf_coll.shape[-3]):
            psf_coll_convolved[:, :, i] = conv2d(
                psf_coll[:, :, i], filter=D[None, None], padding="constant"
            )

        psf_confocal = psf_ill * psf_coll_convolved  # final PSF of confocal microscope

        psf = psf_confocal / torch.sum(psf_confocal, dim=(-3, -2, -1), keepdim=True)

        return {
            "filter": psf.expand(-1, self.shape[0], -1, -1, -1),
            "coeff_ill": coeff_ill,
            "coeff_coll": coeff_coll,
        }
