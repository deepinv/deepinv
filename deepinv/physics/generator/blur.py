from __future__ import annotations
import torch
import numpy as np
from math import ceil, floor
from deepinv.physics.generator import PhysicsGenerator
from deepinv.physics.functional.hist import histogramdd
from deepinv.physics.functional.convolution import conv2d
from deepinv.physics.functional.interp import ThinPlateSpline
from deepinv.utils.decorators import _deprecated_alias
from deepinv.transform.rotate import rotate_via_shear
from .zernike import Zernike
from deepinv.physics.functional.tiled_product_convolution import TiledPConv2dConfig


class PSFGenerator(PhysicsGenerator):
    r"""
    Base class for generating Point Spread Functions (PSFs).


    :param tuple psf_size: the shape of the generated PSF in 2D
        ``(kernel_size, kernel_size)``. If an `int` is given, it will be used for both dimensions.
    :param int num_channels: number of images channels. Defaults to 1.
    """

    def __init__(
        self,
        psf_size: tuple[int] = (31, 31),
        num_channels: int = 1,
        **kwargs,
    ) -> None:
        super().__init__(**kwargs)
        if isinstance(psf_size, int):
            psf_size = (psf_size, psf_size)

        self.shape = (num_channels,) + psf_size
        self.psf_size = psf_size
        self.num_channels = num_channels


class MotionBlurGenerator(PSFGenerator):
    r"""
    Random motion blur generator.

    See :footcite:t:`schuler2015learning` for more details.

    A blur trajectory is generated by sampling both its x- and y-coordinates independently
    from a Gaussian Process with a Matérn 3/2 covariance function.

    .. math::

        f_x(t), f_y(t) \sim \mathcal{GP}(0, k(t, t'))

    where :math:`k` is defined as

    .. math::

        k(t, s) = \sigma^2 \left( 1 + \frac{\sqrt{5} |t -s|}{l} + \frac{5 (t-s)^2}{3 l^2} \right) \exp \left(-\frac{\sqrt{5} |t-s|}{l}\right)

    :param int, tuple[int] psf_size: the shape of the generated PSF in 2D, should be `(kernel_size, kernel_size)`. If an `int` is given, the same value will be used for both dimensions.
    :param int num_channels: number of images channels. Defaults to 1.
    :param float l: the length scale of the trajectory, defaults to 0.3
    :param float sigma: the standard deviation of the Gaussian Process, defaults to 0.25
    :param int n_steps: the number of points in the trajectory, defaults to 1000

    |sep|

    :Examples:

    >>> from deepinv.physics.generator import MotionBlurGenerator
    >>> generator = MotionBlurGenerator((5, 5), num_channels=1)
    >>> blur = generator.step()  # dict_keys(['filter'])
    >>> print(blur['filter'].shape)
    torch.Size([1, 1, 5, 5])
    """

    def __init__(
        self,
        psf_size: tuple,
        num_channels: int = 1,
        rng: torch.Generator = None,
        device: str = "cpu",
        dtype: type = torch.float32,
        l: float = 0.3,
        sigma: float = 0.25,
        n_steps: int = 1000,
    ) -> None:
        kwargs = {"l": l, "sigma": sigma, "n_steps": n_steps}
        if isinstance(psf_size, int):
            psf_size = (psf_size, psf_size)

        if len(psf_size) != 2:
            raise ValueError(
                "psf_size must 2D. Add channels via num_channels parameter"
            )
        super().__init__(
            psf_size=psf_size,
            num_channels=num_channels,
            device=device,
            dtype=dtype,
            rng=rng,
            **kwargs,
        )

    def matern_kernel(self, diff, sigma: float = None, l: float = None):
        r"""
        Compute the Matérn 3/2 covariance.

        :param torch.Tensor diff: the difference `t - s`
        :param float sigma: the standard deviation of the Gaussian Process
        :param float l: the length scale of the trajectory
        """
        if sigma is None:
            sigma = self.sigma
        if l is None:
            l = self.l
        fraction = 5**0.5 * diff.abs() / l
        return sigma**2 * (1 + fraction + fraction**2 / 3) * torch.exp(-fraction)

    def f_matern(self, batch_size: int = 1, sigma: float = None, l: float = None):
        r"""
        Generates the trajectory.

        :param int batch_size: batch_size.
        :param float sigma: the standard deviation of the Gaussian Process.
        :param float l: the length scale of the trajectory.
        :return: the trajectory of shape `(batch_size, n_steps)`
        """
        vec = torch.randn(
            batch_size, self.n_steps, generator=self.rng, **self.factory_kwargs
        )
        time = torch.linspace(-torch.pi, torch.pi, self.n_steps, **self.factory_kwargs)[
            None
        ]

        kernel = self.matern_kernel(time, sigma, l)
        kernel_fft = torch.fft.rfft(kernel)
        vec_fft = torch.fft.rfft(vec)
        return torch.fft.irfft(vec_fft * torch.sqrt(kernel_fft)).real[
            :,
            torch.arange(self.n_steps // (2 * torch.pi), **self.factory_kwargs).type(
                torch.int
            ),
        ]

    def step(
        self,
        batch_size: int = 1,
        sigma: float = None,
        l: float = None,
        seed: int = None,
        **kwargs,
    ):
        r"""
        Generate a random motion blur PSF with parameters :math:`\sigma` and :math:`l`

        :param int batch_size: batch_size.
        :param float sigma: the standard deviation of the Gaussian Process
        :param float l: the length scale of the trajectory
        :param int seed: the seed for the random number generator.

        :return: dictionary with keys

            - `filter`: the generated PSF of shape `(batch_size, 1, psf_size[0], psf_size[1])`
        """
        self.rng_manual_seed(seed)
        f_x = self.f_matern(batch_size, sigma, l)[..., None]
        f_y = self.f_matern(batch_size, sigma, l)[..., None]

        trajectories = torch.cat(
            (
                f_x - torch.mean(f_x, dim=1, keepdim=True),
                f_y - torch.mean(f_y, dim=1, keepdim=True),
            ),
            dim=-1,
        )
        kernels = [
            histogramdd(trajectory, bins=list(self.psf_size), low=[-1, -1], upp=[1, 1])[
                None, None
            ]
            for trajectory in trajectories
        ]
        kernel = torch.cat(kernels, dim=0).to(**self.factory_kwargs)
        kernel = kernel / (torch.sum(kernel, dim=(-2, -1), keepdim=True) + 1e-6)
        return {
            "filter": kernel.expand(
                -1,
                self.num_channels,
                -1,
                -1,
            )
        }


class DiffractionBlurGenerator(PSFGenerator):
    r"""
    Diffraction limited blur generator.

    Generates 2D diffraction PSFs in optics using Zernike decomposition of the phase mask (Fresnel/Fraunhoffer diffraction theory).

    Zernike polynomials are a sequence of orthogonal polynomials defined on the unit disk.
    They are commonly used in optical systems to describe wavefront aberrations.

    The PSF :math:`h(\theta)` is defined as the squared magnitude of the Fourier transform of the pupil function :math:`p_{\theta} = \exp(- i 2 \pi \phi_{\theta})`:

    .. math::

        h(\theta) = \left| \mathcal{F} \left( \exp \left( - i 2 \pi \phi_\theta \right) \right) \right|^2,

    where :math:`\phi_\theta : \mathbb{R}^2 \to \mathbb{R}`  is the wavefront error function (or aberration function), expressed in the Zernike basis:

    .. math::

        \phi_\theta= \sum_{k \in K} \theta_k z_k

    where :math:`K` is set of indices of Zernike polynomials :math:`z_k` used in the decomposition (equal to `zernike_index`).
    See :footcite:t:`lakshminarayanan2011zernike`
    `or this link <https://e-l.unifi.it/pluginfile.php/1055875/mod_resource/content/1/Appunti_2020_Lezione%2014_4_Zernikepolynomialsaguidefinal.pdf>`_
    or :class:`deepinv.physics.generator.Zernike` for more details.

    In the ideal diffraction-limited case (i.e., no aberrations), the PSF corresponds to the Airy pattern.

    The Zernike polynomials :math:`z_k` are indexed using the ``'noll'`` or ``'ansi'`` convention (defined by `index_convention` parameter).
    Conversion from the two conventions to the standard radial-angular indexing is done internally (see `wikipedia page <https://en.wikipedia.org/wiki/Zernike_polynomials>`_).

    :param tuple psf_size: the shape ``H x W`` of the generated PSF in 2D
    :param int num_channels: number of images channels. Defaults to 1.
    :param tuple[int, ...], tuple[tuple[int, int], ...] zernike_index: activated Zernike coefficients in the following `index_convention` convention.
        It can be either:

            - a tuple of `int` corresponding to the Noll or ANSI indices, in which case the `index_convention` parameter is required to interpret them correctly.
            - a tuple of `tuple[int, int]` corresponding to the standard radial-angular indexing :math:`(n,m)`. In this case, the `index_convention` parameter is ignored.

        Defaults to ``(4, 5, 6, 7, 8, 9, 10, 11)``, correspond to radial order `n` from 2 to 3 (included) and the spherical aberration.
        These correspond to the following aberrations: defocus, astigmatism, coma, trefoil and spherical aberration.
    :param float fc: cutoff frequency ``(NA/emission_wavelength) * pixel_size``. Should be in ``[0, 0.25]``
        to respect the Shannon-Nyquist sampling theorem, defaults to ``0.2``.
    :param float max_zernike_amplitude: maximum amplitude of the Zernike coefficients, defaults to ``0.15``.
        The amplitude of each Zernike coefficient is sampled uniformly in ``[-max_zernike_amplitude/2, max_zernike_amplitude/2]``.
    :param tuple[int] pupil_size: pixel size used to synthesize the super-resolved pupil.
        The higher the more precise, defaults to ``(256, 256)``.
        If a single ``int`` is given, a square pupil is considered.
    :param bool apodize: whether to apodize the PSF to reduce ringing artifacts, defaults to ``False``.
    :param bool random_rotate: whether to randomly rotate the PSF, defaults to ``False``.
    :param str index_convention: the convention for the Zernike polynomials indexing. Can be either ``'noll'`` (default) or ``'ansi'``.
    :param str, torch.device device: device where the tensors are allocated and processed, defaults to ``'cpu'``.
    :param torch.dtype dtype: data type of the tensors, defaults to ``torch.float32``.
    :param torch.Generator rng: pseudo random number generator for reproducibility. Defaults to ``None``.

    |sep|

    :Examples:

    >>> from deepinv.physics.generator import DiffractionBlurGenerator
    >>> generator = DiffractionBlurGenerator((5, 5), num_channels=3)
    >>> print("\n".join(generator.zernike_polynomials)) # list of Zernike polynomials used
    Zernike(n = 2, m = 0) -- Defocus
    Zernike(n = 2, m = -2) -- Oblique Astigmatism
    Zernike(n = 2, m = 2) -- Vertical Astigmatism
    Zernike(n = 3, m = -1) -- Vertical Coma
    Zernike(n = 3, m = 1) -- Horizontal Coma
    Zernike(n = 3, m = -3) -- Vertical Trefoil
    Zernike(n = 3, m = 3) -- Oblique Trefoil
    Zernike(n = 4, m = 0) -- Primary Spherical
    >>> blur = generator.step()  # dict_keys(['filter', 'coeff', 'pupil'])
    >>> print(blur['filter'].shape)
    torch.Size([1, 3, 5, 5])


    """

    @_deprecated_alias(list_param="zernike_index")
    def __init__(
        self,
        psf_size: tuple,
        num_channels: int = 1,
        zernike_index: tuple[int, ...] | tuple[tuple[int, int], ...] = tuple(
            range(4, 12)
        ),
        fc: float = 0.2,
        max_zernike_amplitude: float = 0.15,
        pupil_size: tuple[int, ...] = (256, 256),
        apodize: bool = False,
        random_rotate: bool = False,
        index_convention: str = "noll",
        device: str | torch.device = "cpu",
        dtype: torch.dtype = torch.float32,
        rng: torch.Generator = None,
    ):
        super().__init__(
            psf_size=psf_size,
            num_channels=num_channels,
            device=device,
            dtype=dtype,
            rng=rng,
        )
        # For backward compatibility if a list / tuple of a string is given
        # Should be removed in future versions
        zernike_index = list(zernike_index)
        for i, index in enumerate(zernike_index):
            if isinstance(index, str):
                if not index.upper().startswith("Z"):
                    raise ValueError(f"Zernike index must start with 'Z', got {index}")
                index = int(index[1:])  # Convert "Z4" to 4
            zernike_index[i] = index

        self.zernike_index = sorted(zernike_index)  # list of parameters to provide
        self.fc = fc
        self.max_zernike_amplitude = max_zernike_amplitude
        self.apodize = apodize
        self.random_rotate = random_rotate
        self.index_convention = index_convention

        if self.apodize:
            lin_0 = torch.linspace(
                -psf_size[0] // 2, psf_size[0] // 2, psf_size[0], **self.factory_kwargs
            )
            lin_1 = torch.linspace(
                -psf_size[1] // 2, psf_size[1] // 2, psf_size[1], **self.factory_kwargs
            )
            XX0, XX1 = torch.meshgrid(lin_0, lin_1, indexing="ij")
            dist = (XX0**2 + XX1**2) ** 0.5
            radius = min(psf_size) / 2
            apodize_length = min(10, radius)
            self.apodize_mask = bump_function(
                dist, a=radius - apodize_length, b=apodize_length
            )
        else:
            self.apodize_mask = None

        pupil_size = (
            max(pupil_size[0], self.psf_size[0]),
            max(pupil_size[1], self.psf_size[1]),
        )
        self.pupil_size = pupil_size

        lin_x = torch.linspace(-0.5, 0.5, self.pupil_size[0], **self.factory_kwargs)
        lin_y = torch.linspace(-0.5, 0.5, self.pupil_size[1], **self.factory_kwargs)
        self.step_rho = lin_x[1] - lin_x[0]

        # Fourier plane is discretized on [-0.5,0.5]x[-0.5,0.5]
        XX, YY = torch.meshgrid(lin_x / self.fc, lin_y / self.fc, indexing="ij")
        self.register_buffer(
            "rho", cart2pol(XX, YY)
        )  # Cartesian coordinates to polar coordinates
        self.register_buffer(
            "indicator_circ",
            bump_function(self.rho, 1 - self.step_rho / 2, b=self.step_rho / 2),
        )

        # In order to avoid layover in Fourier convolution we need to zero pad and then extract a part of image
        # computed from pupil_size and psf_size
        self.pad_pre = (
            ceil((self.pupil_size[0] - self.psf_size[0]) / 2),
            ceil((self.pupil_size[1] - self.psf_size[1]) / 2),
        )
        self.pad_post = (
            floor((self.pupil_size[0] - self.psf_size[0]) / 2),
            floor((self.pupil_size[1] - self.psf_size[1]) / 2),
        )

        # the number of Zernike coefficients
        self.n_zernike = len(self.zernike_index)

        # the tensor of Zernike polynomials in the pupil plane
        self.register_buffer(
            "Z",
            torch.zeros(
                (self.pupil_size[0], self.pupil_size[1], self.n_zernike),
                **self.factory_kwargs,
            ),
        )
        for k, index in enumerate(self.zernike_index):
            if isinstance(index, int):
                n, m = Zernike.index_conversion(index, convention=index_convention)
            elif isinstance(index, tuple) and len(index) == 2:
                n, m = index
            else:
                raise ValueError(
                    f"Zernike index must be either int or tuple of (n,m), got {index!r}"
                )
            self.Z[:, :, k] = Zernike.cartesian_evaluate(
                n, m, XX, YY
            )  # defining the k-th Zernike polynomial

        self.to(device=device, dtype=dtype)

    def step(
        self,
        batch_size: int = 1,
        coeff: torch.Tensor = None,
        angle: torch.Tensor = None,
        seed: int = None,
        **kwargs,
    ) -> dict:
        r"""
        Generate a batch of PFS with a batch of Zernike coefficients

        :param int batch_size: batch_size.
        :param torch.Tensor coeff: `batch_size x len(zernike_index)` coefficients of the Zernike decomposition (default is `None`)
        :param torch.Tensor angle: `batch_size` angles in degree to rotate the PSF (defaults is `None`)
        :param int seed: the seed for the random number generator.

        :return: dictionary with keys

            - `filter`: tensor of size `(batch_size x num_channels x psf_size[0] x psf_size[1])` batch of PSFs,
            - `coeff`: list of sampled Zernike coefficients in this realization,
            - `pupil`: the pupil function,
            - `angle`: the random rotation angle in degrees if `random_rotate` is `True`, nothing otherwise.
        """

        self.rng_manual_seed(seed)
        if coeff is None:
            coeff = self.generate_coeff(batch_size)

        pupil = (self.Z @ coeff[:, : self.n_zernike].T).transpose(2, 0)
        pupil = torch.exp(-2.0j * torch.pi * pupil)
        pupil = pupil * self.indicator_circ
        psf = torch.fft.ifftshift(torch.fft.fft2(torch.fft.fftshift(pupil)))
        psf = torch.real(psf * torch.conj(psf))
        psf = psf[
            :,
            self.pad_pre[0] : self.pupil_size[0] - self.pad_post[0],
            self.pad_pre[1] : self.pupil_size[1] - self.pad_post[1],
        ].unsqueeze(1)

        # random rotate the PSF if angle is given
        if self.random_rotate:
            if angle is None:
                angle = self.generate_angles(batch_size)
            psf = rotate_via_shear(psf, angle)

        if self.apodize:
            psf = self.apodize_mask * psf

        psf = psf / torch.sum(psf, dim=(-1, -2), keepdim=True)
        params = {
            "filter": psf.expand(-1, self.shape[0], -1, -1),
            "coeff": coeff,
            "pupil": pupil,
        }
        if self.random_rotate:
            params["angle"] = angle
        return params

    @property
    def zernike_polynomials(self) -> list[str]:
        r"""
        List of Zernike polynomials used in the decomposition, with the corresponding aberration if available.
        """
        zernike_polynomials = []
        for index in self.zernike_index:
            if isinstance(index, int):
                n, m = Zernike.index_conversion(index, convention=self.index_convention)
            elif isinstance(index, tuple) and len(index) == 2:
                n, m = index
            else:
                raise ValueError(
                    f"Zernike index must be either int or tuple of (n,m), got {index!r}"
                )
            zernike_polynomials.append(Zernike.get_name(n, m))
        return zernike_polynomials

    def generate_coeff(self, batch_size) -> torch.Tensor:
        r"""Generates random coefficients of the decomposition in the Zernike polynomials.

        :param int batch_size: batch_size.

        :return: a tensor of shape `(batch_size, len(zernike_index))` coefficients in the Zernike decomposition.

        """
        coeff = torch.rand(
            (batch_size, len(self.zernike_index)),
            generator=self.rng,
            **self.factory_kwargs,
        )
        coeff = (coeff - 0.5) * self.max_zernike_amplitude
        return coeff

    def generate_angles(self, batch_size) -> torch.Tensor:
        r"""
        Generates random angles for the rotation of the PSF.

        :param int batch_size: batch_size.

        :return: a tensor of shape `(batch_size,)` angles in degrees.
        """
        return torch.rand(batch_size, generator=self.rng, **self.factory_kwargs) * 360


def cart2pol(x, y):
    r"""
    Cartesian to polar coordinates

    :param torch.Tensor x: x coordinates
    :param torch.Tensor y: y coordinates

    :return: rho of torch.Tensor of radius
    :rtype: tuple
    """

    rho = torch.sqrt(x**2 + y**2)
    return rho


def bump_function(x, a=1.0, b=1.0):
    r"""
    Defines a function which is 1 on the interval [-a,a]
    and goes to 0 smoothly on [-a-b,-a]U[a,a+b] using a bump function
    For the discretization of indicator functions, we advise b=1, so that
    a=0, b=1 yields a bump.

    :param torch.Tensor x: tensor of arbitrary size
        input.
    :param Float a: radius (default is 1)
    :param Float b: interval on which the function goes to 0. (default is 1)

    :return: the bump function sampled at points x
    :rtype: torch.Tensor

    :Examples:

    >>> import deepinv as dinv
    >>> x = torch.linspace(-15, 15, 31)
    >>> X, Y = torch.meshgrid(x, x, indexing = 'ij')
    >>> R = torch.sqrt(X**2 + Y**2)
    >>> Z = bump_function(R, 3, 1)
    >>> Z = Z / torch.sum(Z)
    """
    v = torch.zeros_like(x)
    v[torch.abs(x) <= a] = 1
    I = (torch.abs(x) > a) * (torch.abs(x) < a + b)
    v[I] = torch.exp(-1.0 / (1.0 - ((torch.abs(x[I]) - a) / b) ** 2)) / np.exp(-1.0)
    return v


class ProductConvolutionBlurGenerator(PhysicsGenerator):
    r"""
    Generates parameters of space-varying blurs.

    Parameters generated:

    -`'filters'`: tensor of shape ``(B, C, n_eigen_psf, psf_size, psf_size)``
    - 'multipliers': tensor of shape ``(B, C, n_eigen_psf, H, W)``

    See :class:`deepinv.physics.SpaceVaryingBlur` for more details.

    :param deepinv.physics.generator.PSFGenerator psf_generator: A PSF generator, such as :class:`motion blur <deepinv.physics.generator.MotionBlurGenerator>` or
        :class:`diffraction blur generator <deepinv.physics.generator.DiffractionBlurGenerator>`.
    :param tuple img_size: image size ``(H,W)``.
    :param int n_eigen_psf: each PSF in the field of view will be a linear combination of ``n_eigen_psf`` eigen PSF grids.
        Defaults to 10.
    :param tuple spacing: steps between the PSF grids used for interpolation (defaults ``(H//8, W//8)``).
    :param str padding: boundary conditions in (options = ``'valid'``, ``'circular'``, ``'replicate'``, ``'reflect'``).
        Defaults to ``'valid'``.

    |sep|

    :Examples:

    >>> from deepinv.physics.generator import DiffractionBlurGenerator
    >>> from deepinv.physics.generator import ProductConvolutionBlurGenerator
    >>> psf_size = 7
    >>> psf_generator = DiffractionBlurGenerator((psf_size, psf_size), fc=0.25)
    >>> pc_generator = ProductConvolutionBlurGenerator(psf_generator, img_size=(64, 64), n_eigen_psf=8)
    >>> params = pc_generator.step(1)
    >>> print(params.keys())
    dict_keys(['filters', 'multipliers'])

    """

    def __init__(
        self,
        psf_generator: PSFGenerator,
        img_size: tuple[int],
        n_eigen_psf: int = 10,
        spacing: tuple[int] = None,
        device: str = "cpu",
        **kwargs,
    ) -> None:
        super().__init__(device=device, **kwargs)
        if isinstance(img_size, int):
            img_size = (img_size, img_size)
        if isinstance(spacing, int):
            spacing = (spacing, spacing)

        self.psf_generator = psf_generator
        self.img_size = img_size
        self.n_eigen_psf = n_eigen_psf
        self.spacing = (
            spacing
            if spacing is not None
            else (self.img_size[0] // 8, self.img_size[1] // 8)
        )

        self.n_psf_prid = (self.img_size[0] // self.spacing[0]) * (
            self.img_size[1] // self.spacing[1]
        )
        assert (
            self.n_psf_prid >= self.n_eigen_psf
        ), f"n_eigen_psf={n_eigen_psf} must be smaller than the number of PSF grid points = {self.n_psf_prid}"

        # Interpolating the psf_grid coefficients with thin plate splines
        T0 = torch.linspace(
            0, 1, self.img_size[0] // self.spacing[0], **self.factory_kwargs
        )
        T1 = torch.linspace(
            0, 1, self.img_size[1] // self.spacing[1], **self.factory_kwargs
        )
        yy, xx = torch.meshgrid(T0, T1, indexing="ij")
        self.X = torch.stack((yy.flatten(), xx.flatten()), dim=1)

        T0 = torch.linspace(0, 1, self.img_size[0], **self.factory_kwargs)
        T1 = torch.linspace(0, 1, self.img_size[1], **self.factory_kwargs)
        yy, xx = torch.meshgrid(T0, T1, indexing="ij")
        self.XX = torch.stack((yy.flatten(), xx.flatten()), dim=1)

        self.tps = ThinPlateSpline(0.0, **self.factory_kwargs)

    def step(self, batch_size: int = 1, seed: int = None, **kwargs):
        r"""
        Generates a random set of filters and multipliers for space-varying blurs.

        :param int batch_size: number of space-varying blur parameters to generate.
        :param int seed: the seed for the random number generator.

        :returns: a dictionary containing filters, multipliers and paddings.
            filters: a tensor of shape (B, C, n_eigen_psf, psf_size, psf_size).
            multipliers: a tensor of shape (B, C, n_eigen_psf, H, W).
        """
        self.rng_manual_seed(seed)
        self.psf_generator.rng_manual_seed(seed)

        # Generating psf_grid on a grid
        psf_grid = self.psf_generator.step(self.n_psf_prid * batch_size)["filter"]
        psf_size = psf_grid.shape[-2:]
        channels = psf_grid.shape[1]
        psf_grid = psf_grid.view(
            batch_size, self.n_psf_prid, channels, *psf_size
        )  # B x n_psf_prid x C x psf_size x psf_size

        # Computing the eigen-PSF
        psf_grid = psf_grid.flatten(-2, -1).transpose(
            1, 2
        )  # B x C x n_psf_prid x (psf_size*psf_size)
        _, _, V = torch.linalg.svd(psf_grid, full_matrices=False)
        n_eigen_chosen = min(self.n_eigen_psf, V.size(-2))
        V = V[..., :n_eigen_chosen, :]  # B x C x n_eigen_psf x (psf_size*psf_size)
        coeffs = torch.matmul(
            psf_grid, V.transpose(-1, -2)
        )  # B x C x n_psf_prid x n_eigen_psf
        eigen_psf = V.reshape(V.size(0), channels, n_eigen_chosen, *psf_size)

        # compute multipliers by interpolating the coeffs with thin-plate splines
        self.tps.fit(self.X, coeffs)
        w = self.tps.transform(self.XX).transpose(-1, -2)
        w = w.reshape(w.size(0), channels, n_eigen_chosen, *self.img_size)

        # Ending
        params_blur = {"filters": eigen_psf, "multipliers": w}
        return params_blur


class DiffractionBlurGenerator3D(PSFGenerator):
    r"""
    3D diffraction limited kernels using Zernike decomposition of the phase mask (Fresnel/Fraunhoffer diffraction theory).

    This method simulates the propagation of the wavefront from the pupil plane
    (frequency domain) to multiple defocus planes in the image space.
    The pupil function is constructed using a Zernike polynomial decomposition
    of the wavefront aberrations, see :class:`deepinv.physics.generator.DiffractionBlurGenerator` for more details.

    At each depth :math:`z`, the pupil function is modulated by a phase term
    corresponding to the axial wave vector :math:`k_z`,
    which is derived from the dispersion relation of light in free space.

    .. math::

        k_z = \sqrt{k_{\text{total}}^2 - k_{\text{lateral}}^2}

    where :math:`k_{\text{total}}` is the total wave number (`kb`) and :math:`k_{\text{lateral}}` is the lateral wave vector component.
    The pupil function at depth :math:`z` is given by:

    .. math::

        P(x, y, z) = P(x, y, 0) \cdot \exp \left( - i 2 \pi \cdot k_z \cdot z \right)

    And the depth planes are sampled according to the `stepz_pixel` parameter, which defines the ratio between the physical size of the :math:`z` direction to that in the :math:`x/y` direction of the voxels in the 3D image.


    The 3D PSF is then computed by square modulus of Fourier transform of the modulated pupil function at each depth plane, followed by normalization across the spatial dimensions.


    .. note::

        This class uses :class:`deepinv.physics.generator.DiffractionBlurGenerator` under the hood to generate the pupil function at :math:`z=0`. Refer to its documentation for more details.

    :param tuple psf_size: give in the order `(depth, height, width)` the size of the PSF to generate.
    :param int num_channels: number of channels. Default to `1`.
    :param tuple[int, ...], tuple[tuple[int, int], ...] zernike_index: activated Zernike coefficients in the following `index_convention` convention.
        It can be either:

            - a tuple of `int` corresponding to the Noll or ANSI indices, in which case the `index_convention` parameter is required to interpret them correctly.
            - a tuple of `tuple[int, int]` corresponding to the standard radial-angular indexing :math:`(n,m)`. In this case, the `index_convention` parameter is ignored.

        Defaults to ``(4, 5, 6, 7, 8, 9, 10, 11)``, correspond to radial order `n` from 2 to 3 (included) and the spherical aberration.
        These correspond to the following aberrations: defocus, astigmatism, coma, trefoil and spherical aberration.
    :param float fc: cutoff frequency `(NA/emission_wavelength) * pixel_size`. Should be in `[0, 1/4]` to respect Shannon, defaults to `0.2`.
    :param float kb: wave number `(NI/emission_wavelength) * pixel_size` or `(NA/NI) * fc`. Must be greater than `fc`. Defaults to `0.3`.
    :param float max_zernike_amplitude: maximum amplitude of Zernike coefficients. Defaults to 0.15.
    :param tuple[int] pupil_size: pixel size to synthesize the super-resolved pupil. The higher the more precise, defaults to `(512, 512)`.
        If an `int` is given, a square pupil is considered.
    :param bool apodize: whether to apodize the PSF to reduce ringing effects. Defaults to `False`.
    :param bool random_rotate: whether to randomly rotate the PSF in the xy plane. Defaults to `False`.
    :param float stepz_pixel: Ratio between the physical size of the :math:`z` direction to that in the :math:`x/y` direction of the voxels in the 3D image.
        Defaults to `1.0`.
    :param str index_convention: convention for the Zernike indices, either ``'noll'`` (default) or ``'ansi'``.
    :param torch.Generator rng: random number generator (default to `None`).
    :param str device: device (default to ``'cpu'``).
    :param type dtype: data type (default to `torch.float32`).
    :param kwargs: additional arguments for :class:`deepinv.physics.generator.DiffractionBlurGenerator`.

    .. note::

        - `NA`: numerical aperture,
        - `NI`: refraction index of the immersion medium,
        - `emission_wavelength`: wavelength of the light,
        - `pixel_size`: physical size of the pixels in the :math:`xy` plane in the same unit as `emission_wavelength`.

    |sep|

    :Examples:

    >>> import torch
    >>> from deepinv.physics.generator import DiffractionBlurGenerator3D
    >>> generator = DiffractionBlurGenerator3D((21, 51, 51), stepz_pixel = 2, zernike_index=(3,), index_convention='ansi')
    >>> print(generator.zernike_polynomials) # list of Zernike polynomials used
    ['Zernike(n = 2, m = -2) -- Oblique Astigmatism']
    >>> dict = generator.step()
    >>> filter = dict['filter']
    >>> print(filter.shape)
    torch.Size([1, 1, 21, 51, 51])
    >>> batch_size = 2
    >>> n_zernike = len(generator.generator2d.zernike_index)
    >>> dict = generator.step(batch_size=batch_size, coeff=0.1 * torch.rand(batch_size, n_zernike))
    >>> dict.keys()
    dict_keys(['filter', 'pupil', 'coeff'])


    """

    @_deprecated_alias(list_param="zernike_index")
    def __init__(
        self,
        psf_size: tuple,
        num_channels: int = 1,
        zernike_index: tuple[int, ...] | tuple[tuple[int, int], ...] = tuple(
            range(4, 12)
        ),
        fc: float = 0.2,
        kb: float = 0.25,
        max_zernike_amplitude: float = 0.15,
        pupil_size: tuple[int] = (512, 512),
        apodize: bool = False,
        random_rotate: bool = False,
        stepz_pixel: float = 1.0,
        index_convention: str = "noll",
        rng: torch.Generator = None,
        device: str = "cpu",
        dtype: type = torch.float32,
        **kwargs,
    ):
        if len(psf_size) != 3:
            raise ValueError(
                "You should provide a tuple of len == 3 to generate 3D PSFs."
            )

        super().__init__(
            psf_size=psf_size,
            num_channels=num_channels,
            device=device,
            dtype=dtype,
            rng=rng,
        )

        self.generator2d = DiffractionBlurGenerator(
            psf_size=psf_size[1:],
            num_channels=num_channels,
            zernike_index=zernike_index,
            fc=fc,
            max_zernike_amplitude=max_zernike_amplitude,
            pupil_size=pupil_size,
            apodize=apodize,
            device=device,
            dtype=dtype,
            rng=rng,
            index_convention=index_convention,
            **kwargs,
        )
        self.apodize = apodize
        self.random_rotate = random_rotate
        self.stepz_pixel = stepz_pixel
        self.kb = kb
        self.psf_size = psf_size
        self.nzs = psf_size[0]
        self.fc = fc
        self.zernike_index = zernike_index
        self.n_zernike = len(self.zernike_index)
        self._defocus = (
            torch.linspace(
                -self.nzs / 2, self.nzs / 2, self.nzs, device=device, dtype=dtype
            )[:, None, None]
            * self.stepz_pixel
        )
        self.to(device=device, dtype=dtype)

    def step(
        self,
        batch_size: int = 1,
        coeff: torch.Tensor = None,
        angle: torch.Tensor = None,
        seed: int = None,
        **kwargs,
    ) -> dict:
        r"""
        Generate a batch of PSF with a batch of Zernike coefficients

        :param int batch_size: number of PSFs to generate.
        :param torch.Tensor coeff: tensor of size (batch_size x len(zernike_index)) containing the Zernike coefficients.
            If `None`, random coefficients are generated.
        :param int seed: the seed for the random number generator.

        :return: dictionary with keys

            - `filter`: tensor of size `(batch_size x num_channels x psf_size[0] x psf_size[1])` batch of PSFs,
            - `pupil`: the pupil function,
            - `coeff`: list of sampled Zernike coefficients in this realization,
            - `angle`: the random rotation angles in degrees if `random_rotate` is `True`, nothing otherwise.
        """
        gen_dict = self.generator2d.step(
            batch_size=batch_size, coeff=coeff, seed=seed, **kwargs
        )

        pupil = gen_dict["pupil"]
        d = ((self.kb) ** 2 - (self.generator2d.rho * self.fc) ** 2 + 0j) ** 0.5

        propKer = torch.exp(-1j * 2 * torch.pi * d * self._defocus) + 0j
        p = pupil[:, None, ...] * propKer[None, ...]
        p = torch.nan_to_num(p, nan=0.0)
        pshift = torch.fft.fftshift(p, dim=(-2, -1))
        pfft = torch.fft.fft2(pshift, dim=(-2, -1))
        psf = torch.fft.ifftshift(pfft, dim=(-2, -1))
        psf = torch.real(psf * torch.conj(psf))

        psf = psf[
            :,
            :,
            self.generator2d.pad_pre[0] : self.generator2d.pupil_size[0]
            - self.generator2d.pad_post[0],
            self.generator2d.pad_pre[1] : self.generator2d.pupil_size[1]
            - self.generator2d.pad_post[1],
        ].unsqueeze(1)
        if self.random_rotate:
            from einops import rearrange

            if angle is None:
                angle = self.generator2d.generate_angles(batch_size)

            psf = rotate_via_shear(rearrange(psf, "b c d h w -> b (c d) h w"), angle)
            psf = rearrange(psf, "b (c d) h w -> b c d h w", d=self.psf_size[0])

        if self.apodize:
            psf = self.generator2d.apodize_mask[None, None, None] * psf
        psf = psf / torch.sum(psf, dim=(-3, -2, -1), keepdim=True)

        params = {
            "filter": psf.expand(-1, self.shape[0], -1, -1, -1),
            "pupil": pupil,
            "coeff": gen_dict["coeff"],
        }
        if self.random_rotate:
            params["angle"] = angle
        return params

    @property
    def zernike_polynomials(self) -> list[str]:
        r"""
        List of Zernike polynomials used in the decomposition, with the corresponding aberration if available.
        """
        return self.generator2d.zernike_polynomials


class ConfocalBlurGenerator3D(PSFGenerator):
    r"""
    Generates the 3D point spread function (PSF) of a confocal laser scanning microsope.

    :param tuple psf_size: give in the order `(depth, height, width)`
    :param int num_channels: number of channels. Default to `1`.
    :param tuple[int, ...], tuple[tuple[int, int], ...] zernike_index: activated Zernike coefficients in the following `index_convention` convention.
        It can be either:

            - a tuple of `int` corresponding to the Noll or ANSI indices, in which case the `index_convention` parameter is required to interpret them correctly.
            - a tuple of `tuple[int, int]` corresponding to the standard radial-angular indexing :math:`(n,m)`. In this case, the `index_convention` parameter is ignored.

        Defaults to ``(4, 5, 6, 7, 8, 9, 10, 11)``, correspond to radial order `n` from 2 to 3 (included) and the spherical aberration.
        These correspond to the following aberrations: defocus, astigmatism, coma, trefoil and spherical aberration.

    :param float NI: Refractive index of  the immersion medium. Defaults to `1.51` (oil),
    :param float NA: Numerical aperture. Should be less than NI. Defaults to `1.37`.
    :param float lambda_ill: Wavelength of the illumination light (fluorescence excitation). Defaults to `489e-9`.
    :param float lambda_coll: Wavelength of the collection light (fluorescence emission). Defaults to `395e-9`.
    :param float pixelsize_XY: Physical pixel size in the lateral direction (height, width). Defaults to `50e-9`.
    :param float pixelsize_Z:  Physical pixel size in the axial direction (depth). Defaults to `100e-9`.
    :param float pinhole_radius: Radius of pinhole in Airy units. Defaults to `1`.
    :param float max_zernike_amplitude: maximum amplitude of Zernike coefficients. Defaults to `0.1`.
    :param tuple[int] pupil_size: pixel size to synthesize the super-resolved pupil. The higher the more precise, defaults to `(512, 512)`.
            If an `int` is given, a square pupil is considered.
    :param str index_convention: convention for the Zernike indices, either ``'noll'`` (default) or ``'ansi'``.
    :param torch.Generator rng: random number generator (default to `None`).
    :param str device: device (default to `cpu`).
    :param type dtype: data type (default to `torch.float32`).

    |sep|

    :Examples:

    >>> import torch
    >>> from deepinv.physics.generator import ConfocalBlurGenerator3D
    >>> generator = ConfocalBlurGenerator3D((21, 51, 51), zernike_index=(3,))
    >>> print(generator.zernike_polynomials)
    ['Zernike(n = 1, m = -1) -- Vertical Tilt']
    >>> dict = generator.step()
    >>> filter = dict['filter']
    >>> print(filter.shape)
    torch.Size([1, 1, 21, 51, 51])
    >>> batch_size = 2
    >>> n_zernike = len(generator.generator_ill.generator2d.zernike_index)
    >>> dict = generator.step(batch_size=batch_size,
    ...                       coeff_ill = 0.1 * torch.rand(batch_size, n_zernike),
    ...                       coeff_coll = 0.1 * torch.rand(batch_size, n_zernike))
    >>> dict.keys()
    dict_keys(['filter', 'coeff_ill', 'coeff_coll'])

    """

    @_deprecated_alias(list_param="zernike_index")
    def __init__(
        self,
        psf_size: tuple,
        num_channels: int = 1,
        zernike_index: tuple[int, ...] | tuple[tuple[int, int], ...] = tuple(
            range(4, 12)
        ),
        NI: float = 1.51,
        NA: float = 1.37,
        lambda_ill: float = 489e-9,
        lambda_coll: float = 395e-9,
        pixelsize_XY: float = 50e-9,
        pixelsize_Z: float = 100e-9,
        pinhole_radius: float = 1,
        max_zernike_amplitude: float = 0.1,
        pupil_size: tuple[int] = (512, 512),
        index_convention: str = "noll",
        device: str = "cpu",
        dtype: type = torch.float32,
        rng: torch.Generator = None,
        **kwargs,
    ):
        if len(psf_size) != 3:
            raise ValueError(
                "You should provide a tuple of len == 3 to generate 3D PSFs."
            )

        super().__init__()

        self.fc_ill = (
            NA / lambda_ill
        ) * pixelsize_XY  # cutoff frequency for illumination
        self.kb_ill = (NI / lambda_ill) * pixelsize_XY  # wavenumber for illumination

        self.fc_coll = (
            NA / lambda_coll
        ) * pixelsize_XY  # cutoff freauency for collection
        # wavenumber for collection
        self.kb_coll = (NI / lambda_coll) * pixelsize_XY  # wavenumber for collection
        self.pinhole_radius = pinhole_radius
        self.pixelsize_XY = pixelsize_XY
        self.pixel_size_Z = pixelsize_Z

        self.lambda_ill = lambda_ill
        self.lambda_coll = lambda_coll
        self.NI = NI
        self.NA = NA

        # Initialize generator for the Illumniation PSF
        self.generator_ill = DiffractionBlurGenerator3D(
            psf_size=psf_size,
            num_channels=num_channels,
            fc=self.fc_ill,
            kb=self.kb_ill,
            stepz_pixel=int(pixelsize_Z / pixelsize_XY),
            zernike_index=zernike_index,
            max_zernike_amplitude=max_zernike_amplitude,
            pupil_size=pupil_size,
            index_convention=index_convention,
            rng=rng,
            device=device,
            dtype=dtype,
        )

        # Initialize generator for the Collection PSF
        self.generator_coll = DiffractionBlurGenerator3D(
            psf_size=psf_size,
            num_channels=num_channels,
            fc=self.fc_coll,
            kb=self.kb_coll,
            stepz_pixel=int(pixelsize_Z / pixelsize_XY),
            zernike_index=zernike_index,
            max_zernike_amplitude=max_zernike_amplitude,
            pupil_size=pupil_size,
            index_convention=index_convention,
            rng=rng,
            device=device,
            dtype=dtype,
        )
        self.to(device=device, dtype=dtype)

    def step(
        self,
        batch_size: int = 1,
        coeff_ill: torch.Tensor = None,
        coeff_coll: torch.Tensor = None,
        **kwargs,
    ) -> dict:
        r"""
        Generate a batch of 3D confocal PSF with a batch of Zernike coefficients
        for illumination and collection

        :param int batch_size: number of PSFs to generate.
        :param torch.Tensor coeff_ill: tensor of size `batch_size x len(zernike_index)` containing the Zernike coefficients for illumination.
            If `None`, random coefficients are generated.
        :param torch.Tensor coeff_coll: tensor of size `batch_size x len(zernike_index)` containing the Zernike coefficients for collection.
            If `None`, random coefficients are generated.

        :return: dictionary with keys

            - `filter`: tensor of size `batch_size x num_channels x psf_size[0] x psf_size[1]` batch of PSFs,
            - `coeff_ill`: list of sampled Zernike coefficients in this realization of illumination,
            - `coeff_coll`: list of sampled Zernike coefficients in this realization of collection,

        """
        dict_ill = self.generator_ill.step(
            batch_size=batch_size, coeff=coeff_ill
        )  # generate illumuinition PSF
        psf_ill = dict_ill["filter"]
        coeff_ill = dict_ill["coeff"]
        dict_coll = self.generator_coll.step(
            batch_size=batch_size, coeff=coeff_coll
        )  # generate collection PSF
        psf_coll = dict_coll["filter"]
        coeff_coll = dict_coll["coeff"]

        # convolution of the collection PSF by pinhole
        # 1. Define the pinhole D
        airy_unit = 0.61 * self.lambda_coll / self.NA
        PH_radius = self.pinhole_radius * airy_unit
        lin_x = torch.linspace(
            -1.5 * PH_radius,
            1.5 * PH_radius,
            int(3 * PH_radius / self.pixelsize_XY),
            **self.factory_kwargs,
        )
        lin_y = torch.linspace(
            -1.5 * PH_radius,
            1.5 * PH_radius,
            int(3 * PH_radius / self.pixelsize_XY),
            **self.factory_kwargs,
        )
        PH_step_rho = lin_x[1] - lin_x[0]
        # The plane is discretized on [-1.5 * r_pinhole, 1.5 * r_pinhole] x  [-1.5 * r_pinhole, 1.5 * r_pinhole]
        XX, YY = torch.meshgrid(lin_x, lin_y, indexing="ij")
        PH_rho = torch.sqrt(XX**2 + YY**2)  # Cartesian coordinates
        D = bump_function(
            PH_rho, PH_radius - PH_step_rho / 2, b=PH_step_rho / 2
        )  # D(r) in equation

        # 2. Apply 2D convolution in all z planes
        psf_coll_convolved = torch.zeros(psf_coll.shape, **self.factory_kwargs)
        for i in range(psf_coll.shape[-3]):
            psf_coll_convolved[:, :, i] = conv2d(
                psf_coll[:, :, i], filter=D[None, None], padding="constant"
            )

        psf_confocal = psf_ill * psf_coll_convolved  # final PSF of confocal microscope

        psf = psf_confocal / torch.sum(psf_confocal, dim=(-3, -2, -1), keepdim=True)

        return {
            "filter": psf.expand(-1, self.shape[0], -1, -1, -1),
            "coeff_ill": coeff_ill,
            "coeff_coll": coeff_coll,
        }

    @property
    def zernike_polynomials(self) -> list[str]:
        r"""
        List of Zernike polynomials used in the decomposition, with the corresponding aberration if available.
        """
        return self.generator_ill.zernike_polynomials


class TiledBlurGenerator(PSFGenerator):
    r"""
    Generates parameters of the :class:`deepinv.physics.TiledSpaceVaryingBlur` operator.
    The image is divided into overlapping patches, each local patch is convolved with a different PSF.

    This generates a dict with key `'filter'`, which is tensor of shape `(B, C, K, psf_size, psf_size)`
    where `K` is the number of patches in which the image is divided.
    It is computed based on the `patch_size`, `stride` and the given `img_size` during the `step()` function call.

    :param deepinv.physics.generator.PSFGenerator psf_generator: A PSF generator, such as :class:`motion blur <deepinv.physics.generator.MotionBlurGenerator>` or :class:`diffraction blur generator <deepinv.physics.generator.DiffractionBlurGenerator>`.

    :param int | tuple[int, int] patch_size: size of the patches (height, width) in which the image is divided.
    :param int | tuple[int, int] stride: stride between adjacent patches (height, width). Defaults to `patch_size`.
    """

    def __init__(
        self,
        psf_generator: PSFGenerator,
        patch_size: int | tuple[int, int],
        stride: int | tuple[int, int] = None,
        rng: torch.Generator = None,
        device: str = "cpu",
        **kwargs,
    ):
        super().__init__(rng=rng, device=device, **kwargs)
        self.psf_generator = psf_generator
        self.psf_size = psf_generator.psf_size

        self.patch_size = patch_size
        self.stride = stride if stride is not None else patch_size
        self.config = TiledPConv2dConfig(
            patch_size=patch_size, stride=self.stride, psf_size_init=self.psf_size
        )

    def step(
        self,
        batch_size: int = 1,
        img_size: int | tuple[int, int] | None = None,
        seed: int = None,
        **kwargs,
    ) -> dict:
        num_patches = self.config.get_num_patches(img_size)
        num_patches = num_patches[0] * num_patches[1]

        params = self.psf_generator.step(
            batch_size=batch_size * num_patches, seed=seed, **kwargs
        )
        psf = (
            params["filter"]
            .view(batch_size, num_patches, -1, *self.psf_size)
            .transpose(1, 2)
        )  # B x C x num_patches x psf_size x psf_size

        return dict(filters=psf)
