
.. DO NOT EDIT.
.. THIS FILE WAS AUTOMATICALLY GENERATED BY SPHINX-GALLERY.
.. TO MAKE CHANGES, EDIT THE SOURCE PYTHON FILE:
.. "auto_examples/sampling/demo_diffusion_sde.py"
.. LINE NUMBERS ARE GIVEN BELOW.

.. only:: html

    .. note::
        :class: sphx-glr-download-link-note

        New to DeepInverse? Get started with the basics with the
        :ref:`5 minute quickstart tutorial <sphx_glr_auto_examples_basics_demo_quickstart.py>`..

.. rst-class:: sphx-glr-example-title

.. _sphx_glr_auto_examples_sampling_demo_diffusion_sde.py:


Building your diffusion posterior sampling method using SDEs
==============================================================

This demo shows you how to use
:class:`deepinv.sampling.PosteriorDiffusion` to perform posterior sampling. It also can be used to perform unconditional image generation with arbitrary denoisers, if the data fidelity term is not specified.

This method requires:

* A well-trained denoiser with varying noise levels (ideally with large noise levels) (e.g., :class:`deepinv.models.NCSNpp`).

* A (noisy) data fidelity term (e.g., :class:`deepinv.sampling.DPSDataFidelity`).

* Define a drift term :math:`f(x, t)` and a diffusion term :math:`g(t)` for the forward-time SDE. They can be defined through the :class:`deepinv.sampling.DiffusionSDE` (e.g., :class:`deepinv.sampling.VarianceExplodingDiffusion`).

The :class:`deepinv.sampling.PosteriorDiffusion` class can be used to perform posterior sampling for inverse problems.
Consider the acquisition model:

.. math::
     y = \noise{\forw{x}}

where :math:`\forw{x}` is the forward operator (e.g., a convolutional operator) and :math:`\noise{\cdot}` is the noise operator (e.g., Gaussian noise).
This class defines the reverse-time SDE for the posterior distribution :math:`p(x|y)` given the data :math:`y`:

.. math::
     d\, x_t = \left( f(x_t, t) - \frac{1 + \alpha}{2} g(t)^2 \nabla_{x_t} \log p_t(x_t | y) \right) d\,t + g(t) \sqrt{\alpha} d\, w_{t}

where :math:`f` is the drift term, :math:`g` is the diffusion coefficient and :math:`w` is the standard Brownian motion.
The drift term and the diffusion coefficient are defined by the underlying (unconditional) forward-time SDE `sde`.
In this example, we will use 2 well-known SDE in the literature: the Variance-Exploding (VE) and Variance-Preserving (VP or DDPM).

The (conditional) score function :math:`\nabla_{x_t} \log p_t(x_t | y)` can be decomposed using the Bayes' rule:

.. math::
     \nabla_{x_t} \log p_t(x_t | y) = \nabla_{x_t} \log p_t(x_t) + \nabla_{x_t} \log p_t(y | x_t).

The first term is the score function of the unconditional SDE, which is typically approximated by an MMSE denoiser (`denoiser`) using the well-known Tweedie's formula, while the
second term is approximated by the (noisy) data-fidelity term (`data_fidelity`).
We implement various data-fidelity terms in `the user guide <https://deepinv.github.io/deepinv/user_guide/reconstruction/sampling.html#id2>`_.

.. note::

    In this demo, we limit the number of diffusion steps for the sake of speed, but in practice, you should use a larger number of steps to obtain better results.

.. GENERATED FROM PYTHON SOURCE LINES 47-55

---------------------------------------------------

Let us import the necessary modules, define the denoiser and the SDE.

In this first example, we use the Variance-Exploding SDE, whose forward process is defined as:

.. math::
    d\, x_t = g(t) d\, w_t \quad \mbox{where } g(t) = \sigma_{\mathrm{min}}\left( \frac{\sigma_{\mathrm{max}}}{\sigma_{\mathrm{min}}}\right)^t\sqrt{2\log\frac{\sigma_{\mathrm{max}}}{\sigma_{\mathrm{min}}} }.

.. GENERATED FROM PYTHON SOURCE LINES 55-65

.. code-block:: Python


    import torch
    import deepinv as dinv
    from deepinv.models import NCSNpp

    device = dinv.utils.get_device()
    dtype = torch.float64
    dtype = torch.float32
    figsize = 2.5
    gif_frequency = 10  # Increase this value to save the GIF saving time




.. rst-class:: sphx-glr-script-out

 .. code-block:: none

    Selected GPU 0 with 5065.25 MiB free memory




.. GENERATED FROM PYTHON SOURCE LINES 66-92

.. code-block:: Python

    from deepinv.sampling import (
        PosteriorDiffusion,
        DPSDataFidelity,
        EulerSolver,
        VarianceExplodingDiffusion,
        VariancePreservingDiffusion,
    )
    from deepinv.optim import ZeroFidelity

    # In this example, we use the pre-trained FFHQ-64 model from the
    # EDM framework: https://arxiv.org/pdf/2206.00364 .
    # The network architecture is from Song et al: https://arxiv.org/abs/2011.13456 .
    denoiser = NCSNpp(pretrained="download").to(device)


    # The solution is obtained by calling the SDE object with a desired solver (here, Euler).
    # The reproducibility of the SDE Solver class can be controlled by providing the pseudo-random number generator.
    num_steps = 150
    rng = torch.Generator(device).manual_seed(42)
    timesteps = torch.linspace(1, 0.001, num_steps)
    solver = EulerSolver(timesteps=timesteps, rng=rng)
    sde = VarianceExplodingDiffusion(
        device=device,
        dtype=dtype,
    )





.. rst-class:: sphx-glr-script-out

 .. code-block:: none

    Downloading: "https://huggingface.co/deepinv/edm/resolve/main/edm-ffhq-64x64-uncond-ve.pt?download=true" to /local/jtachell/.cache/torch/hub/checkpoints/edm-ffhq-64x64-uncond-ve.pt
      0%|          | 0.00/240M [00:00<?, ?B/s]      4%|▍         | 9.50M/240M [00:00<00:02, 98.7MB/s]      9%|▊         | 20.5M/240M [00:00<00:02, 108MB/s]      13%|█▎        | 31.5M/240M [00:00<00:01, 111MB/s]     18%|█▊        | 42.4M/240M [00:00<00:01, 112MB/s]     22%|██▏       | 53.2M/240M [00:00<00:01, 113MB/s]     27%|██▋       | 64.2M/240M [00:00<00:01, 113MB/s]     31%|███▏      | 75.2M/240M [00:00<00:01, 114MB/s]     36%|███▌      | 86.1M/240M [00:00<00:01, 113MB/s]     40%|████      | 97.0M/240M [00:00<00:01, 113MB/s]     45%|████▌     | 108M/240M [00:01<00:01, 113MB/s]      50%|████▉     | 119M/240M [00:01<00:01, 114MB/s]     54%|█████▍    | 130M/240M [00:01<00:01, 114MB/s]     59%|█████▊    | 141M/240M [00:01<00:00, 114MB/s]     63%|██████▎   | 152M/240M [00:01<00:00, 114MB/s]     68%|██████▊   | 162M/240M [00:01<00:00, 114MB/s]     72%|███████▏  | 173M/240M [00:01<00:00, 114MB/s]     77%|███████▋  | 184M/240M [00:01<00:00, 114MB/s]     81%|████████▏ | 195M/240M [00:01<00:00, 113MB/s]     86%|████████▌ | 206M/240M [00:01<00:00, 113MB/s]     91%|█████████ | 217M/240M [00:02<00:00, 114MB/s]     95%|█████████▌| 228M/240M [00:02<00:00, 114MB/s]    100%|█████████▉| 239M/240M [00:02<00:00, 114MB/s]    100%|██████████| 240M/240M [00:02<00:00, 113MB/s]




.. GENERATED FROM PYTHON SOURCE LINES 93-98

Reverse-time SDE as sampling process
--------------------------------------

When the data fidelity is not given, the posterior diffusion is equivalent to the unconditional diffusion.
Sampling is performed by solving the reverse-time SDE. To do so, we generate a reverse-time trajectory.

.. GENERATED FROM PYTHON SOURCE LINES 98-132

.. code-block:: Python



    model = PosteriorDiffusion(
        data_fidelity=ZeroFidelity(),
        sde=sde,
        denoiser=denoiser,
        solver=solver,
        dtype=dtype,
        device=device,
        verbose=True,
    )
    x, trajectory = model(
        y=None,
        physics=None,
        x_init=(1, 3, 64, 64),
        seed=10,
        get_trajectory=True,
    )

    dinv.utils.plot(
        x,
        titles="Unconditional generation",
        save_fn="sde_sample.png",
        figsize=(figsize, figsize),
    )

    dinv.utils.save_videos(
        trajectory.cpu()[::gif_frequency],
        time_dim=0,
        titles=["VE-SDE Trajectory"],
        save_fn="sde_trajectory.gif",
        figsize=(figsize, figsize),
    )





.. rst-class:: sphx-glr-script-out

 .. code-block:: none

      0%|          | 0/149 [00:00<?, ?it/s]      2%|▏         | 3/149 [00:00<00:05, 25.96it/s]      5%|▌         | 8/149 [00:00<00:03, 37.45it/s]      9%|▊         | 13/149 [00:00<00:03, 41.06it/s]     12%|█▏        | 18/149 [00:00<00:03, 42.95it/s]     15%|█▌        | 23/149 [00:00<00:02, 43.98it/s]     19%|█▉        | 28/149 [00:00<00:02, 44.57it/s]     22%|██▏       | 33/149 [00:00<00:02, 44.94it/s]     26%|██▌       | 38/149 [00:00<00:02, 45.22it/s]     29%|██▉       | 43/149 [00:00<00:02, 45.44it/s]     32%|███▏      | 48/149 [00:01<00:02, 45.42it/s]     36%|███▌      | 53/149 [00:01<00:02, 45.54it/s]     39%|███▉      | 58/149 [00:01<00:01, 45.57it/s]     42%|████▏     | 63/149 [00:01<00:01, 45.58it/s]     46%|████▌     | 68/149 [00:01<00:01, 45.66it/s]     49%|████▉     | 73/149 [00:01<00:01, 45.63it/s]     52%|█████▏    | 78/149 [00:01<00:01, 45.68it/s]     56%|█████▌    | 83/149 [00:01<00:01, 45.23it/s]     59%|█████▉    | 88/149 [00:01<00:01, 44.44it/s]     62%|██████▏   | 93/149 [00:02<00:01, 44.04it/s]     66%|██████▌   | 98/149 [00:02<00:01, 44.32it/s]     69%|██████▉   | 103/149 [00:02<00:01, 44.74it/s]     72%|███████▏  | 108/149 [00:02<00:00, 44.92it/s]     76%|███████▌  | 113/149 [00:02<00:00, 43.69it/s]     79%|███████▉  | 118/149 [00:02<00:00, 43.49it/s]     83%|████████▎ | 123/149 [00:02<00:00, 43.39it/s]     86%|████████▌ | 128/149 [00:02<00:00, 43.50it/s]     89%|████████▉ | 133/149 [00:03<00:00, 43.49it/s]     93%|█████████▎| 138/149 [00:03<00:00, 43.91it/s]     96%|█████████▌| 143/149 [00:03<00:00, 43.96it/s]     99%|█████████▉| 148/149 [00:03<00:00, 44.21it/s]    100%|██████████| 149/149 [00:03<00:00, 44.13it/s]




.. GENERATED FROM PYTHON SOURCE LINES 149-164

We obtain the following unconditional sample

.. container:: image-row

   .. image-sg-ignore:: /auto_examples/images/sde_sample.png
      :alt: example of unconditional sample
      :srcset: /auto_examples/images/sde_sample.png
      :class: custom-img
      :ignore_missing: true

   .. image-sg-ignore:: /auto_examples/images/sde_trajectory.gif
      :alt: example of unconditional trajectory
      :srcset: /auto_examples/images/sde_trajectory.gif
      :class: custom-gif
      :ignore_missing: true

.. GENERATED FROM PYTHON SOURCE LINES 166-169

When the data fidelity is given, together with the measurements and the physics, this class can be used to perform posterior sampling for inverse problems.
For example, consider the inpainting problem, where we have a noisy image and we want to recover the original image.
We can use the :class:`deepinv.sampling.DPSDataFidelity` as the data fidelity term.

.. GENERATED FROM PYTHON SOURCE LINES 170-218

.. code-block:: Python

    mask = torch.ones_like(x)
    mask[..., 24:40, 24:40] = 0.0
    physics = dinv.physics.Inpainting(img_size=x.shape[1:], mask=mask, device=device)
    y = physics(x)

    weight = 4.0  # guidance strength
    dps_fidelity = DPSDataFidelity(denoiser=denoiser, weight=weight)

    model = PosteriorDiffusion(
        data_fidelity=dps_fidelity,
        denoiser=denoiser,
        sde=sde,
        solver=solver,
        dtype=dtype,
        device=device,
        verbose=True,
    )

    # To perform posterior sampling, we need to provide the measurements, the physics and the solver.
    # Moreover, when the physics is given, the initial point can be inferred from the physics if not given explicitly.

    seed_1 = 11

    x_hat, trajectory = model(
        y,
        physics,
        seed=seed_1,
        get_trajectory=True,
    )


    # Here, we plot the original image, the measurement and the posterior sample
    dinv.utils.plot(
        [x, y, x_hat],
        show=True,
        titles=["Original", "Measurement", "Posterior sample"],
        figsize=(figsize * 3, figsize),
    )
    # We can also save the trajectory of the posterior sample
    dinv.utils.save_videos(
        trajectory[::gif_frequency],
        time_dim=0,
        titles=["Posterior sample with VE"],
        save_fn="posterior_trajectory.gif",
        figsize=(figsize, figsize),
    )






.. rst-class:: sphx-glr-script-out

 .. code-block:: none

      0%|          | 0/149 [00:00<?, ?it/s]      1%|▏         | 2/149 [00:00<00:10, 13.99it/s]      3%|▎         | 4/149 [00:00<00:09, 15.04it/s]      4%|▍         | 6/149 [00:00<00:09, 15.67it/s]      5%|▌         | 8/149 [00:00<00:08, 15.91it/s]      7%|▋         | 10/149 [00:00<00:08, 16.07it/s]      8%|▊         | 12/149 [00:00<00:08, 15.28it/s]      9%|▉         | 14/149 [00:00<00:08, 15.64it/s]     11%|█         | 16/149 [00:01<00:08, 15.80it/s]     12%|█▏        | 18/149 [00:01<00:08, 15.84it/s]     13%|█▎        | 20/149 [00:01<00:08, 15.79it/s]     15%|█▍        | 22/149 [00:01<00:08, 15.59it/s]     16%|█▌        | 24/149 [00:01<00:08, 15.42it/s]     17%|█▋        | 26/149 [00:01<00:08, 15.07it/s]     19%|█▉        | 28/149 [00:01<00:07, 15.90it/s]     20%|██        | 30/149 [00:01<00:07, 16.26it/s]     21%|██▏       | 32/149 [00:02<00:07, 16.43it/s]     23%|██▎       | 34/149 [00:02<00:06, 16.97it/s]     24%|██▍       | 36/149 [00:02<00:06, 16.68it/s]     26%|██▌       | 38/149 [00:02<00:06, 16.29it/s]     27%|██▋       | 40/149 [00:02<00:06, 16.05it/s]     28%|██▊       | 42/149 [00:02<00:06, 17.01it/s]     30%|██▉       | 44/149 [00:02<00:05, 17.59it/s]     31%|███       | 46/149 [00:02<00:05, 17.67it/s]     32%|███▏      | 48/149 [00:02<00:05, 17.90it/s]     34%|███▎      | 50/149 [00:03<00:05, 17.25it/s]     35%|███▍      | 52/149 [00:03<00:05, 16.88it/s]     36%|███▌      | 54/149 [00:03<00:05, 17.24it/s]     38%|███▊      | 56/149 [00:03<00:05, 17.92it/s]     39%|███▉      | 58/149 [00:03<00:05, 17.78it/s]     40%|████      | 60/149 [00:03<00:05, 17.70it/s]     42%|████▏     | 62/149 [00:03<00:04, 18.07it/s]     43%|████▎     | 64/149 [00:03<00:04, 17.99it/s]     44%|████▍     | 66/149 [00:03<00:04, 16.81it/s]     46%|████▌     | 68/149 [00:04<00:04, 16.56it/s]     47%|████▋     | 70/149 [00:04<00:04, 17.18it/s]     48%|████▊     | 72/149 [00:04<00:04, 17.67it/s]     50%|████▉     | 74/149 [00:04<00:04, 17.34it/s]     51%|█████     | 76/149 [00:04<00:04, 15.97it/s]     52%|█████▏    | 78/149 [00:04<00:04, 15.39it/s]     54%|█████▎    | 80/149 [00:04<00:04, 15.38it/s]     55%|█████▌    | 82/149 [00:05<00:04, 15.26it/s]     56%|█████▋    | 84/149 [00:05<00:04, 15.37it/s]     58%|█████▊    | 86/149 [00:05<00:03, 16.10it/s]     59%|█████▉    | 88/149 [00:05<00:03, 17.04it/s]     60%|██████    | 90/149 [00:05<00:03, 16.90it/s]     62%|██████▏   | 92/149 [00:05<00:03, 16.71it/s]     63%|██████▎   | 94/149 [00:05<00:03, 17.50it/s]     64%|██████▍   | 96/149 [00:05<00:03, 17.42it/s]     66%|██████▌   | 98/149 [00:05<00:03, 16.63it/s]     67%|██████▋   | 100/149 [00:06<00:02, 16.82it/s]     68%|██████▊   | 102/149 [00:06<00:02, 16.71it/s]     70%|██████▉   | 104/149 [00:06<00:02, 17.49it/s]     71%|███████   | 106/149 [00:06<00:02, 17.50it/s]     72%|███████▏  | 108/149 [00:06<00:02, 17.95it/s]     74%|███████▍  | 110/149 [00:06<00:02, 17.98it/s]     75%|███████▌  | 112/149 [00:06<00:02, 17.31it/s]     77%|███████▋  | 114/149 [00:06<00:02, 16.29it/s]     78%|███████▊  | 116/149 [00:06<00:02, 16.01it/s]     79%|███████▉  | 118/149 [00:07<00:02, 14.97it/s]     81%|████████  | 120/149 [00:07<00:01, 15.48it/s]     82%|████████▏ | 122/149 [00:07<00:01, 15.82it/s]     83%|████████▎ | 124/149 [00:07<00:01, 16.36it/s]     85%|████████▍ | 126/149 [00:07<00:01, 16.47it/s]     86%|████████▌ | 128/149 [00:07<00:01, 16.75it/s]     87%|████████▋ | 130/149 [00:07<00:01, 16.74it/s]     89%|████████▊ | 132/149 [00:07<00:01, 16.85it/s]     90%|████████▉ | 134/149 [00:08<00:00, 16.94it/s]     91%|█████████▏| 136/149 [00:08<00:00, 16.78it/s]     93%|█████████▎| 138/149 [00:08<00:00, 17.11it/s]     94%|█████████▍| 140/149 [00:08<00:00, 17.78it/s]     95%|█████████▌| 142/149 [00:08<00:00, 17.83it/s]     97%|█████████▋| 145/149 [00:08<00:00, 18.37it/s]     99%|█████████▊| 147/149 [00:08<00:00, 18.35it/s]    100%|██████████| 149/149 [00:08<00:00, 18.25it/s]    100%|██████████| 149/149 [00:08<00:00, 16.72it/s]




.. GENERATED FROM PYTHON SOURCE LINES 236-245

We obtain the following posterior sample and trajectory

.. container:: image-col

   .. image-sg-ignore:: /auto_examples/images/posterior_trajectory.gif
      :alt: example of posterior trajectory
      :srcset: /auto_examples/images/posterior_trajectory.gif
      :ignore_missing: true
      :class: custom-gif

.. GENERATED FROM PYTHON SOURCE LINES 248-256

.. note::

    **Reproducibility**: To ensure the reproducibility, if the parameter `rng` is given, the same sample will
    be generated when the same seed is used.
    One can obtain varying samples by using a different seed.

    **Parallel sampling**: one can draw multiple samples in parallel by giving the initial shape, e.g., `x_init = (B, C, H, W)`


.. GENERATED FROM PYTHON SOURCE LINES 258-266

Varying the SDE
---------------

One can also change the underlying SDE for sampling.
For example, we can also use the Variance-Preserving (VP or DDPM) in :class:`deepinv.sampling.VariancePreservingDiffusion`, whose forward drift and diffusion term are defined as:

.. math::
    f(x_t, t) = -\frac{1}{2} \beta(t)x_t \qquad \mbox{ and } \qquad g(t) = \beta(t)  \qquad \mbox{ with } \beta(t) = \beta_{\mathrm{min}}  + t \left( \beta_{\mathrm{max}} - \beta_{\mathrm{min}} \right).

.. GENERATED FROM PYTHON SOURCE LINES 266-308

.. code-block:: Python



    del trajectory

    sde = VariancePreservingDiffusion(alpha=0.01, device=device, dtype=dtype)
    model = PosteriorDiffusion(
        data_fidelity=dps_fidelity,
        denoiser=denoiser,
        sde=sde,
        solver=solver,
        device=device,
        dtype=dtype,
        verbose=True,
    )

    x_hat_vp, trajectory = model(
        y,
        physics,
        seed=111,
        get_trajectory=True,
    )
    x_hat = x
    dinv.utils.plot(
        [x_hat, x_hat_vp],
        titles=[
            "posterior sample with VE",
            "posterior sample with VP",
        ],
        figsize=(figsize * 2, figsize),
    )


    # We can also save the trajectory of the posterior sample
    dinv.utils.save_videos(
        trajectory[::gif_frequency],
        time_dim=0,
        titles=["Posterior sample with VP"],
        save_fn="posterior_trajectory_vp.gif",
        figsize=(figsize, figsize),
    )






.. rst-class:: sphx-glr-script-out

 .. code-block:: none

      0%|          | 0/149 [00:00<?, ?it/s]      1%|▏         | 2/149 [00:00<00:09, 15.73it/s]      3%|▎         | 4/149 [00:00<00:10, 14.09it/s]      4%|▍         | 6/149 [00:00<00:10, 13.83it/s]      5%|▌         | 8/149 [00:00<00:10, 13.04it/s]      7%|▋         | 10/149 [00:00<00:10, 13.01it/s]      8%|▊         | 12/149 [00:00<00:10, 13.44it/s]      9%|▉         | 14/149 [00:01<00:09, 14.14it/s]     11%|█         | 16/149 [00:01<00:09, 14.60it/s]     12%|█▏        | 18/149 [00:01<00:08, 15.03it/s]     13%|█▎        | 20/149 [00:01<00:08, 14.66it/s]     15%|█▍        | 22/149 [00:01<00:08, 14.67it/s]     16%|█▌        | 24/149 [00:01<00:08, 14.76it/s]     17%|█▋        | 26/149 [00:01<00:08, 15.03it/s]     19%|█▉        | 28/149 [00:01<00:07, 15.63it/s]     20%|██        | 30/149 [00:02<00:07, 15.81it/s]     21%|██▏       | 32/149 [00:02<00:07, 15.81it/s]     23%|██▎       | 34/149 [00:02<00:07, 14.90it/s]     24%|██▍       | 36/149 [00:02<00:07, 14.78it/s]     26%|██▌       | 38/149 [00:02<00:07, 15.49it/s]     27%|██▋       | 40/149 [00:02<00:07, 15.15it/s]     28%|██▊       | 42/149 [00:02<00:07, 14.04it/s]     30%|██▉       | 44/149 [00:03<00:07, 13.46it/s]     31%|███       | 46/149 [00:03<00:07, 13.50it/s]     32%|███▏      | 48/149 [00:03<00:07, 13.35it/s]     34%|███▎      | 50/149 [00:03<00:07, 13.74it/s]     35%|███▍      | 52/149 [00:03<00:06, 14.55it/s]     36%|███▌      | 54/149 [00:03<00:06, 14.73it/s]     38%|███▊      | 56/149 [00:03<00:06, 15.44it/s]     39%|███▉      | 58/149 [00:03<00:05, 15.31it/s]     40%|████      | 60/149 [00:04<00:05, 15.09it/s]     42%|████▏     | 62/149 [00:04<00:05, 15.16it/s]     43%|████▎     | 64/149 [00:04<00:05, 14.87it/s]     44%|████▍     | 66/149 [00:04<00:05, 15.40it/s]     46%|████▌     | 68/149 [00:04<00:05, 16.02it/s]     47%|████▋     | 70/149 [00:04<00:05, 15.61it/s]     48%|████▊     | 72/149 [00:04<00:05, 14.62it/s]     50%|████▉     | 74/149 [00:05<00:05, 14.44it/s]     51%|█████     | 76/149 [00:05<00:05, 13.82it/s]     52%|█████▏    | 78/149 [00:05<00:05, 13.70it/s]     54%|█████▎    | 80/149 [00:05<00:04, 14.41it/s]     55%|█████▌    | 82/149 [00:05<00:04, 15.65it/s]     56%|█████▋    | 84/149 [00:05<00:03, 16.42it/s]     58%|█████▊    | 86/149 [00:05<00:03, 17.28it/s]     59%|█████▉    | 88/149 [00:05<00:03, 17.32it/s]     60%|██████    | 90/149 [00:06<00:03, 17.65it/s]     62%|██████▏   | 92/149 [00:06<00:03, 18.25it/s]     63%|██████▎   | 94/149 [00:06<00:03, 18.10it/s]     64%|██████▍   | 96/149 [00:06<00:02, 18.48it/s]     66%|██████▌   | 98/149 [00:06<00:02, 17.97it/s]     67%|██████▋   | 100/149 [00:06<00:02, 18.24it/s]     68%|██████▊   | 102/149 [00:06<00:02, 18.58it/s]     70%|██████▉   | 104/149 [00:06<00:02, 18.61it/s]     71%|███████   | 106/149 [00:06<00:02, 18.07it/s]     72%|███████▏  | 108/149 [00:06<00:02, 18.30it/s]     74%|███████▍  | 110/149 [00:07<00:02, 17.72it/s]     75%|███████▌  | 112/149 [00:07<00:02, 17.18it/s]     77%|███████▋  | 114/149 [00:07<00:02, 16.67it/s]     78%|███████▊  | 116/149 [00:07<00:02, 15.73it/s]     79%|███████▉  | 118/149 [00:07<00:02, 15.34it/s]     81%|████████  | 120/149 [00:07<00:01, 15.70it/s]     82%|████████▏ | 122/149 [00:07<00:01, 15.72it/s]     83%|████████▎ | 124/149 [00:08<00:01, 16.49it/s]     85%|████████▍ | 126/149 [00:08<00:01, 17.38it/s]     86%|████████▌ | 128/149 [00:08<00:01, 17.92it/s]     87%|████████▋ | 130/149 [00:08<00:01, 17.65it/s]     89%|████████▊ | 132/149 [00:08<00:00, 17.48it/s]     90%|████████▉ | 134/149 [00:08<00:00, 16.94it/s]     91%|█████████▏| 136/149 [00:08<00:00, 16.96it/s]     93%|█████████▎| 138/149 [00:08<00:00, 17.55it/s]     94%|█████████▍| 140/149 [00:08<00:00, 18.07it/s]     95%|█████████▌| 142/149 [00:09<00:00, 18.04it/s]     97%|█████████▋| 144/149 [00:09<00:00, 18.18it/s]     98%|█████████▊| 146/149 [00:09<00:00, 18.54it/s]     99%|█████████▉| 148/149 [00:09<00:00, 17.90it/s]    100%|██████████| 149/149 [00:09<00:00, 15.85it/s]




.. GENERATED FROM PYTHON SOURCE LINES 327-344

We can comparing the sampling trajectory depending on the underlying SDE

.. container:: image-col

   .. container:: image-row

      .. image-sg-ignore:: /auto_examples/images/posterior_trajectory.gif
          :alt: posterior trajectory with VE
          :srcset: /auto_examples/images/posterior_trajectory.gif
          :ignore_missing: true
          :class: custom-gif

      .. image-sg-ignore:: /auto_examples/images/posterior_trajectory_vp.gif
          :alt: posterior trajectory with VP
          :srcset: /auto_examples/images/posterior_trajectory_vp.gif
          :ignore_missing: true
          :class: custom-gif

.. GENERATED FROM PYTHON SOURCE LINES 346-352

Plug-and-play Posterior Sampling with arbitrary denoisers
---------------------------------------------------------

The :class:`deepinv.sampling.PosteriorDiffusion` class can be used together with any (well-trained) denoisers for posterior sampling.
For example, we can use the :class:`deepinv.models.DRUNet` for posterior sampling.
We can also change the underlying SDE, for example change the `sigma_max` value.

.. GENERATED FROM PYTHON SOURCE LINES 352-415

.. code-block:: Python


    del trajectory  # clean memory
    sigma_max = 10.0
    rng = torch.Generator(device)
    dtype = torch.float32
    timesteps = torch.linspace(1, 0.001, 250)
    solver = EulerSolver(timesteps=timesteps, rng=rng)
    denoiser = dinv.models.DRUNet(pretrained="download").to(device)

    sde = VarianceExplodingDiffusion(
        sigma_max=sigma_max, alpha=0.75, device=device, dtype=dtype
    )

    x = dinv.utils.load_example(
        "butterfly.png",
        img_size=256,
        resize_mode="resize",
    ).to(device)

    mask = torch.ones_like(x)
    mask[..., 70:150, 120:180] = 0
    physics = dinv.physics.Inpainting(
        mask=mask,
        img_size=x.shape[1:],
        device=device,
    )

    y = physics(x)
    model = PosteriorDiffusion(
        data_fidelity=DPSDataFidelity(denoiser=denoiser, weight=0.3),
        denoiser=denoiser,
        sde=sde,
        solver=solver,
        dtype=dtype,
        device=device,
        verbose=True,
    )

    # To perform posterior sampling, we need to provide the measurements, the physics and the solver.
    x_hat, trajectory = model(
        y=y,
        physics=physics,
        seed=1,
        get_trajectory=True,
    )

    # Here, we plot the original image, the measurement and the posterior sample
    dinv.utils.plot(
        [x, y, x_hat.clip(0, 1)],
        titles=["Original", "Measurement", "Posterior sample DRUNet"],
        figsize=(figsize * 3, figsize),
    )

    # We can also save the trajectory of the posterior sample
    dinv.utils.save_videos(
        trajectory[::gif_frequency].clip(0, 1),
        time_dim=0,
        titles=["Posterior trajectory DRUNet"],
        save_fn="posterior_sample_DRUNet.gif",
        figsize=(figsize, figsize),
    )






.. rst-class:: sphx-glr-script-out

 .. code-block:: none

      0%|          | 0/249 [00:00<?, ?it/s]      2%|▏         | 5/249 [00:00<00:06, 36.16it/s]      4%|▎         | 9/249 [00:00<00:09, 25.80it/s]      5%|▍         | 12/249 [00:00<00:10, 23.65it/s]      6%|▌         | 15/249 [00:00<00:10, 22.52it/s]      7%|▋         | 18/249 [00:00<00:10, 21.87it/s]      8%|▊         | 21/249 [00:00<00:10, 21.46it/s]     10%|▉         | 24/249 [00:01<00:10, 21.19it/s]     11%|█         | 27/249 [00:01<00:10, 21.02it/s]     12%|█▏        | 30/249 [00:01<00:10, 20.90it/s]     13%|█▎        | 33/249 [00:01<00:10, 20.77it/s]     14%|█▍        | 36/249 [00:01<00:10, 20.67it/s]     16%|█▌        | 39/249 [00:01<00:10, 20.65it/s]     17%|█▋        | 42/249 [00:01<00:10, 20.65it/s]     18%|█▊        | 45/249 [00:02<00:09, 20.64it/s]     19%|█▉        | 48/249 [00:02<00:09, 20.64it/s]     20%|██        | 51/249 [00:02<00:09, 20.64it/s]     22%|██▏       | 54/249 [00:02<00:09, 20.63it/s]     23%|██▎       | 57/249 [00:02<00:09, 20.63it/s]     24%|██▍       | 60/249 [00:02<00:09, 20.63it/s]     25%|██▌       | 63/249 [00:02<00:09, 20.63it/s]     27%|██▋       | 66/249 [00:03<00:08, 20.64it/s]     28%|██▊       | 69/249 [00:03<00:08, 20.64it/s]     29%|██▉       | 72/249 [00:03<00:08, 20.63it/s]     30%|███       | 75/249 [00:03<00:08, 20.63it/s]     31%|███▏      | 78/249 [00:03<00:08, 20.62it/s]     33%|███▎      | 81/249 [00:03<00:08, 20.62it/s]     34%|███▎      | 84/249 [00:03<00:08, 20.62it/s]     35%|███▍      | 87/249 [00:04<00:07, 20.63it/s]     36%|███▌      | 90/249 [00:04<00:07, 20.63it/s]     37%|███▋      | 93/249 [00:04<00:07, 20.63it/s]     39%|███▊      | 96/249 [00:04<00:07, 20.63it/s]     40%|███▉      | 99/249 [00:04<00:07, 20.63it/s]     41%|████      | 102/249 [00:04<00:07, 20.63it/s]     42%|████▏     | 105/249 [00:04<00:06, 20.63it/s]     43%|████▎     | 108/249 [00:05<00:06, 20.62it/s]     45%|████▍     | 111/249 [00:05<00:06, 20.63it/s]     46%|████▌     | 114/249 [00:05<00:06, 20.63it/s]     47%|████▋     | 117/249 [00:05<00:06, 20.63it/s]     48%|████▊     | 120/249 [00:05<00:06, 20.63it/s]     49%|████▉     | 123/249 [00:05<00:06, 20.63it/s]     51%|█████     | 126/249 [00:06<00:05, 20.63it/s]     52%|█████▏    | 129/249 [00:06<00:05, 20.63it/s]     53%|█████▎    | 132/249 [00:06<00:05, 20.63it/s]     54%|█████▍    | 135/249 [00:06<00:05, 20.63it/s]     55%|█████▌    | 138/249 [00:06<00:05, 20.63it/s]     57%|█████▋    | 141/249 [00:06<00:05, 20.63it/s]     58%|█████▊    | 144/249 [00:06<00:05, 20.63it/s]     59%|█████▉    | 147/249 [00:07<00:04, 20.63it/s]     60%|██████    | 150/249 [00:07<00:04, 20.63it/s]     61%|██████▏   | 153/249 [00:07<00:04, 20.63it/s]     63%|██████▎   | 156/249 [00:07<00:04, 20.63it/s]     64%|██████▍   | 159/249 [00:07<00:04, 20.63it/s]     65%|██████▌   | 162/249 [00:07<00:04, 20.63it/s]     66%|██████▋   | 165/249 [00:07<00:04, 20.63it/s]     67%|██████▋   | 168/249 [00:08<00:03, 20.63it/s]     69%|██████▊   | 171/249 [00:08<00:03, 20.63it/s]     70%|██████▉   | 174/249 [00:08<00:03, 20.63it/s]     71%|███████   | 177/249 [00:08<00:03, 20.62it/s]     72%|███████▏  | 180/249 [00:08<00:03, 20.62it/s]     73%|███████▎  | 183/249 [00:08<00:03, 20.62it/s]     75%|███████▍  | 186/249 [00:08<00:03, 20.62it/s]     76%|███████▌  | 189/249 [00:09<00:02, 20.62it/s]     77%|███████▋  | 192/249 [00:09<00:02, 20.62it/s]     78%|███████▊  | 195/249 [00:09<00:02, 20.62it/s]     80%|███████▉  | 198/249 [00:09<00:02, 20.62it/s]     81%|████████  | 201/249 [00:09<00:02, 20.62it/s]     82%|████████▏ | 204/249 [00:09<00:02, 20.62it/s]     83%|████████▎ | 207/249 [00:09<00:02, 20.62it/s]     84%|████████▍ | 210/249 [00:10<00:01, 20.62it/s]     86%|████████▌ | 213/249 [00:10<00:01, 20.63it/s]     87%|████████▋ | 216/249 [00:10<00:01, 20.62it/s]     88%|████████▊ | 219/249 [00:10<00:01, 20.62it/s]     89%|████████▉ | 222/249 [00:10<00:01, 20.62it/s]     90%|█████████ | 225/249 [00:10<00:01, 20.62it/s]     92%|█████████▏| 228/249 [00:10<00:01, 20.61it/s]     93%|█████████▎| 231/249 [00:11<00:00, 20.61it/s]     94%|█████████▍| 234/249 [00:11<00:00, 20.62it/s]     95%|█████████▌| 237/249 [00:11<00:00, 20.62it/s]     96%|█████████▋| 240/249 [00:11<00:00, 20.62it/s]     98%|█████████▊| 243/249 [00:11<00:00, 20.62it/s]     99%|█████████▉| 246/249 [00:11<00:00, 20.62it/s]    100%|██████████| 249/249 [00:11<00:00, 20.62it/s]    100%|██████████| 249/249 [00:11<00:00, 20.80it/s]




.. GENERATED FROM PYTHON SOURCE LINES 434-443

We obtain the following posterior trajectory

.. container:: image-col

   .. image-sg-ignore:: /auto_examples/images/posterior_sample_DRUNet.gif
      :alt: posterior trajectory DRUNet
      :srcset: /auto_examples/images/posterior_sample_DRUNet.gif
      :ignore_missing: true
      :class: custom-gif


.. rst-class:: sphx-glr-timing

   **Total running time of the script:** (1 minutes 42.598 seconds)


.. _sphx_glr_download_auto_examples_sampling_demo_diffusion_sde.py:

.. only:: html

  .. container:: sphx-glr-footer sphx-glr-footer-example

    .. container:: sphx-glr-download sphx-glr-download-jupyter

      :download:`Download Jupyter notebook: demo_diffusion_sde.ipynb <demo_diffusion_sde.ipynb>`

    .. container:: sphx-glr-download sphx-glr-download-python

      :download:`Download Python source code: demo_diffusion_sde.py <demo_diffusion_sde.py>`

    .. container:: sphx-glr-download sphx-glr-download-zip

      :download:`Download zipped: demo_diffusion_sde.zip <demo_diffusion_sde.zip>`


.. only:: html

 .. rst-class:: sphx-glr-signature

    `Gallery generated by Sphinx-Gallery <https://sphinx-gallery.github.io>`_
