
.. DO NOT EDIT.
.. THIS FILE WAS AUTOMATICALLY GENERATED BY SPHINX-GALLERY.
.. TO MAKE CHANGES, EDIT THE SOURCE PYTHON FILE:
.. "auto_examples/sampling/demo_flow_matching.py"
.. LINE NUMBERS ARE GIVEN BELOW.

.. only:: html

    .. note::
        :class: sphx-glr-download-link-note

        New to DeepInverse? Get started with the basics with the
        :ref:`5 minute quickstart tutorial <sphx_glr_auto_examples_basics_demo_quickstart.py>`..

.. rst-class:: sphx-glr-example-title

.. _sphx_glr_auto_examples_sampling_demo_flow_matching.py:


Flow-Matching for posterior sampling and unconditional generation
==================================================================

This demo shows you how to perform unconditional image generation and posterior sampling using Flow Matching (FM).

Flow matching consists in building a continuous transportation between a reference distribution :math:`p_1` which is easy to sample from (e.g., a Gaussian distribution) and the data distribution :math:`p_0`.
Sampling is done by solving the following ordinary differential equation (ODE) defined by a time-dependent velocity field :math:`v_\theta(x,t)`:

.. math::
    \frac{dx_t}{dt} = v_\theta(x_t,t), \quad x_0 \sim p_0 \quad t \in [0,1]

The velocity field :math:`v_\theta(x,t)` is typically trained to approximate the conditional expectation:

.. math::
    v_\theta(x_t,t) \approx \mathbb{E}_{x_0 \sim p_0, x_1 \sim p_1}\Big[ \frac{d}{dt} x_t | x_t = a(t) x_0 + b(t) x_1 \Big]

where :math:`a(t)` and :math:`b(t)` are interpolation coefficients such that :math:`x_t` interpolates between :math:`x_0` and :math:`x_1`.
When the reference distribution :math:`p_0` is the standard Gaussian, the velocity field can be expressed as a function of a Gaussian denoiser :math:`D(x, \sigma)` as follows:

.. math::
    v_\theta(x_t,t) = - \frac{b'(t)}{b(t)} x_t + \frac{1}{2}\frac{a(t) b'(t) - a'(t) b(t)}{a(t) b(t)} \left(D\left(\frac{x_t}{a(t)}, \frac{b(t)}{a(t)} \right) - x_t\right)

The most common choice of time schedulers is the linear schedule :math:`a(t) = 1 - t` and :math:`b(t) = t`.

In this demo, we will show how to :

-  Perform unconditional generation using, instead of a trained denoiser, the closed-form MMSE denoiser

.. math::
    D(x, \sigma) = \mathbb{E}_{x_0 \sim p_{data}, \epsilon \sim \mathcal{N}(0, I)} \Big[ x_0 | x = x_0 + \sigma \epsilon \Big]

Given a dataset of clean images, it can be computed by evaluating the distance between the input image and all the points of the dataset (see :class:`deepinv.models.MMSE`).

-  Perform posterior sampling using Flow-Matching combined with a DPS data fidelity term (see :ref:`sphx_glr_auto_examples_sampling_demo_diffusion_sde.py` for more details)

-  Explore different choices of time schedulers :math:`a(t)` and :math:`b(t)`.

.. GENERATED FROM PYTHON SOURCE LINES 42-54

.. code-block:: Python

    import torch
    import deepinv as dinv
    from deepinv.sampling import (
        PosteriorDiffusion,
        DPSDataFidelity,
        EulerSolver,
        FlowMatching,
    )
    import numpy as np
    from torchvision import datasets, transforms
    from deepinv.models import MMSE








.. GENERATED FROM PYTHON SOURCE LINES 55-60

-----------------------------

We start by working with the closed-form MMSE denoser.  It is calculated by computing the distance between the input image and all the points of the dataset.
This can be quite long to compute for large images and large datasets.  In this toy example, we use the validation set of MNIST.
When using this closed-form MMSE denoiser, the sampling is guaranteed to output an image of the dataset.

.. GENERATED FROM PYTHON SOURCE LINES 60-80

.. code-block:: Python


    device = dinv.utils.get_device()
    dtype = torch.float32

    figsize = 2.5

    # We use the closed-form MMSE denoiser defined using as atoms the testset of MNIST.
    # The deepinv MMSE denoiser takes as input a dataloader.
    dataset = datasets.MNIST(
        root=".", train=False, download=True, transform=transforms.ToTensor()
    )
    dataloader = torch.utils.data.DataLoader(dataset, batch_size=1000, shuffle=False)
    n_max = (
        1000  # limit the number of images to speed up the computation of the MMSE denoiser
    )
    tensors = torch.cat([data[0] for data in iter(dataloader)], dim=0)  # (N,1,28,28)
    tensors = tensors[:n_max].to(device)
    denoiser = MMSE(dataloader=tensors, device=device, dtype=dtype)






.. rst-class:: sphx-glr-script-out

 .. code-block:: none

    Selected GPU 0 with 4991.25 MiB free memory
      0%|          | 0.00/9.91M [00:00<?, ?B/s]      1%|          | 98.3k/9.91M [00:00<00:19, 496kB/s]      3%|▎         | 295k/9.91M [00:00<00:08, 1.11MB/s]      6%|▌         | 590k/9.91M [00:00<00:05, 1.80MB/s]     11%|█         | 1.05M/9.91M [00:00<00:03, 2.77MB/s]     20%|█▉        | 1.97M/9.91M [00:00<00:01, 4.89MB/s]     37%|███▋      | 3.64M/9.91M [00:00<00:00, 8.69MB/s]     53%|█████▎    | 5.24M/9.91M [00:00<00:00, 8.41MB/s]     94%|█████████▍| 9.31M/9.91M [00:00<00:00, 16.5MB/s]    100%|██████████| 9.91M/9.91M [00:01<00:00, 9.86MB/s]
      0%|          | 0.00/28.9k [00:00<?, ?B/s]    100%|██████████| 28.9k/28.9k [00:00<00:00, 310kB/s]
      0%|          | 0.00/1.65M [00:00<?, ?B/s]      2%|▏         | 32.8k/1.65M [00:00<00:05, 321kB/s]      4%|▍         | 65.5k/1.65M [00:00<00:04, 318kB/s]     12%|█▏        | 197k/1.65M [00:00<00:01, 754kB/s]      22%|██▏       | 360k/1.65M [00:00<00:01, 1.08MB/s]     46%|████▌     | 754k/1.65M [00:00<00:00, 2.07MB/s]     89%|████████▉ | 1.47M/1.65M [00:00<00:00, 3.74MB/s]    100%|██████████| 1.65M/1.65M [00:00<00:00, 2.66MB/s]
      0%|          | 0.00/4.54k [00:00<?, ?B/s]    100%|██████████| 4.54k/4.54k [00:00<00:00, 12.3MB/s]




.. GENERATED FROM PYTHON SOURCE LINES 81-85

---------------------------------------------------------------------

The FlowMatching module :class:`deepinv.sampling.FlowMatching` uses by default the following schedules: :math:`a_t=1-t`, :math:`b_t=t`.
The module FlowMatching module takes as input the denoiser and the ODE solver.

.. GENERATED FROM PYTHON SOURCE LINES 85-106

.. code-block:: Python


    num_steps = 100
    timesteps = torch.linspace(0.99, 0.0, num_steps)
    rng = torch.Generator(device).manual_seed(5)
    solver = EulerSolver(timesteps=timesteps, rng=rng)
    sde = FlowMatching(denoiser=denoiser, solver=solver, device=device, dtype=dtype)


    sample, trajectory = sde(
        x_init=(1, 1, 28, 28),
        seed=0,
        get_trajectory=True,
    )

    dinv.utils.plot(
        sample,
        titles="Unconditional FM generation",
        save_fn="FM_sample.png",
        figsize=(figsize, figsize),
    )




.. image-sg:: /auto_examples/sampling/images/sphx_glr_demo_flow_matching_001.png
   :alt: Unconditional FM generation
   :srcset: /auto_examples/sampling/images/sphx_glr_demo_flow_matching_001.png
   :class: sphx-glr-single-img





.. GENERATED FROM PYTHON SOURCE LINES 107-113

-----------------------------------------------------------------------

Now, we can use the Flow-Matching model to perform posterior sampling.
We consider the inpainting problem, where we have a masked image and we want to recover the original image.
We use DPS :class:`deepinv.sampling.DPSDataFidelity` as data fidelity term (see :ref:`sphx_glr_auto_examples_sampling_demo_diffusion_sde.py` for more details).
Note that due to the division by :math:`a(t)` in the velocity field, initialization close to t=1 causes instability.

.. GENERATED FROM PYTHON SOURCE LINES 113-151

.. code-block:: Python


    x = next(iter(dataloader))[0][:1].to(device)

    mask = torch.ones_like(x)
    mask[..., 10:20, 10:20] = 0.0
    physics = dinv.physics.Inpainting(
        img_size=x.shape[1:],
        mask=mask,
        device=device,
        noise_model=dinv.physics.GaussianNoise(sigma=0.1),
    )
    y = physics(x)
    dps_fidelity = DPSDataFidelity(denoiser=denoiser, weight=1.0)
    model = PosteriorDiffusion(
        data_fidelity=dps_fidelity,
        sde=sde,
        solver=solver,
        dtype=dtype,
        device=device,
        verbose=True,
    )
    x_hat, trajectory = model(
        y,
        physics,
        x_init=None,
        get_trajectory=True,
        seed=0,
    )

    # Here, we plot the original image, the measurement and the posterior sample
    dinv.utils.plot(
        [x, y, x_hat],
        show=True,
        titles=["Original", "Measurement", "Posterior sample"],
        figsize=(figsize * 3, figsize),
        save_fn="FM_posterior.png",
    )




.. image-sg:: /auto_examples/sampling/images/sphx_glr_demo_flow_matching_002.png
   :alt: Original, Measurement, Posterior sample
   :srcset: /auto_examples/sampling/images/sphx_glr_demo_flow_matching_002.png
   :class: sphx-glr-single-img


.. rst-class:: sphx-glr-script-out

 .. code-block:: none

      0%|          | 0/99 [00:00<?, ?it/s]     23%|██▎       | 23/99 [00:00<00:00, 219.98it/s]     45%|████▌     | 45/99 [00:00<00:00, 195.05it/s]     66%|██████▌   | 65/99 [00:00<00:00, 186.07it/s]     85%|████████▍ | 84/99 [00:00<00:00, 181.64it/s]    100%|██████████| 99/99 [00:00<00:00, 184.67it/s]




.. GENERATED FROM PYTHON SOURCE LINES 152-157

----------------------------------------------------------------

Finally, we show how to use different choices of time schedulers :math:`a_t` and :math:`b_t`.
Here, we use another typical choice of schedulers :math:`a_t = \cos(\frac{\pi}{2} t)` and :math:`b_t = \sin(\frac{\pi}{2} t)` which also satisfy the interpolation condition :math:`a_0 = 1`, :math:`b_0 = 0`, :math:`a_1 = 0`, :math:`b_1 = 1`.
Note that, again, due to the division by :math:`a_t` in the velocity field, initialization close to t=1 causes instability.

.. GENERATED FROM PYTHON SOURCE LINES 157-199

.. code-block:: Python


    a_t = lambda t: torch.cos(np.pi / 2 * t)
    a_prime_t = lambda t: -np.pi / 2 * torch.sin(np.pi / 2 * t)
    b_t = lambda t: torch.sin(np.pi / 2 * t)
    b_prime_t = lambda t: np.pi / 2 * torch.cos(np.pi / 2 * t)

    sde = FlowMatching(
        a_t=a_t,
        a_prime_t=a_prime_t,
        b_t=b_t,
        b_prime_t=b_prime_t,
        denoiser=denoiser,
        solver=solver,
        device=device,
        dtype=dtype,
    )

    model = PosteriorDiffusion(
        data_fidelity=dps_fidelity,
        sde=sde,
        solver=solver,
        dtype=dtype,
        device=device,
        verbose=True,
    )

    x_hat, trajectory = model(
        y,
        physics,
        x_init=None,
        get_trajectory=True,
    )

    # Here, we plot the original image, the measurement and the posterior sample
    dinv.utils.plot(
        [x, y, x_hat],
        show=True,
        titles=["Original", "Measurement", "Posterior sample"],
        figsize=(figsize * 3, figsize),
        save_fn="FM_posterior_new_at_bt.png",
    )




.. image-sg:: /auto_examples/sampling/images/sphx_glr_demo_flow_matching_003.png
   :alt: Original, Measurement, Posterior sample
   :srcset: /auto_examples/sampling/images/sphx_glr_demo_flow_matching_003.png
   :class: sphx-glr-single-img


.. rst-class:: sphx-glr-script-out

 .. code-block:: none

      0%|          | 0/99 [00:00<?, ?it/s]     22%|██▏       | 22/99 [00:00<00:00, 209.64it/s]     43%|████▎     | 43/99 [00:00<00:00, 189.30it/s]     64%|██████▎   | 63/99 [00:00<00:00, 182.55it/s]     83%|████████▎ | 82/99 [00:00<00:00, 176.22it/s]    100%|██████████| 99/99 [00:00<00:00, 180.29it/s]




.. GENERATED FROM PYTHON SOURCE LINES 200-203

:References:

.. footbibliography::


.. rst-class:: sphx-glr-timing

   **Total running time of the script:** (0 minutes 13.205 seconds)


.. _sphx_glr_download_auto_examples_sampling_demo_flow_matching.py:

.. only:: html

  .. container:: sphx-glr-footer sphx-glr-footer-example

    .. container:: sphx-glr-download sphx-glr-download-jupyter

      :download:`Download Jupyter notebook: demo_flow_matching.ipynb <demo_flow_matching.ipynb>`

    .. container:: sphx-glr-download sphx-glr-download-python

      :download:`Download Python source code: demo_flow_matching.py <demo_flow_matching.py>`

    .. container:: sphx-glr-download sphx-glr-download-zip

      :download:`Download zipped: demo_flow_matching.zip <demo_flow_matching.zip>`


.. only:: html

 .. rst-class:: sphx-glr-signature

    `Gallery generated by Sphinx-Gallery <https://sphinx-gallery.github.io>`_
