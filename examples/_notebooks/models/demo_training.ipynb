{
  "cells": [
    {
      "id": "9361fea0",
      "cell_type": "code",
      "metadata": {
        "language": "python"
      },
      "execution_count": null,
      "source": "# Install deepinv (skip if already installed)\n%pip install deepinv",
      "outputs": []
    },
    {
      "id": "eda09914",
      "cell_type": "markdown",
      "source": "<!-- MathJax macro definitions inserted automatically -->\n$$\n\\newcommand{\\forw}[1]{{A\\left({#1}\\right)}}\n\\newcommand{\\noise}[1]{{N\\left({#1}\\right)}}\n\\newcommand{\\inverse}[1]{{R\\left({#1}\\right)}}\n\\newcommand{\\inversef}[2]{{R\\left({#1},{#2}\\right)}}\n\\newcommand{\\inversename}{R}\n\\newcommand{\\reg}[1]{{g_\\sigma\\left({#1}\\right)}}\n\\newcommand{\\regname}{g_\\sigma}\n\\newcommand{\\sensor}[1]{{\\eta\\left({#1}\\right)}}\n\\newcommand{\\datafid}[2]{{f\\left({#1},{#2}\\right)}}\n\\newcommand{\\datafidname}{f}\n\\newcommand{\\distance}[2]{{d\\left({#1},{#2}\\right)}}\n\\newcommand{\\distancename}{d}\n\\newcommand{\\denoiser}[2]{{\\operatorname{D}_{{#2}}\\left({#1}\\right)}}\n\\newcommand{\\denoisername}{\\operatorname{D}_{\\sigma}}\n\\newcommand{\\xset}{\\mathcal{X}}\n\\newcommand{\\yset}{\\mathcal{Y}}\n\\newcommand{\\group}{\\mathcal{G}}\n\\newcommand{\\metric}[2]{{d\\left({#1},{#2}\\right)}}\n\\newcommand{\\loss}[1]{{\\mathcal\\left({#1}\\right)}}\n\\newcommand{\\conj}[1]{{\\overline{#1}^{\\top}}}\n$$",
      "metadata": {
        "language": "markdown"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "language": "markdown"
      },
      "source": "\n# Training a reconstruction model\n\nThis example provides a very simple quick start introduction to training reconstruction networks with\nDeepInverse for solving imaging inverse problems.\n\nTraining requires these components, all of which you can define with DeepInverse:\n\n* A `model` to be trained from reconstructors or define your own.\n* A `physics` from our list of physics. Or, [bring your own physics](https://deepinv.github.io/deepinv/auto_examples/basics/demo_custom_dataset.html#sphx-glr-auto-examples-basics-demo-custom-dataset-py).\n* A `dataset` of images and/or measurements from datasets. Or, [bring your own dataset](https://deepinv.github.io/deepinv/auto_examples/basics/demo_custom_dataset.html#sphx-glr-auto-examples-basics-demo-custom-dataset-py).\n* A `loss` from our loss functions.\n* A `metric` from our metrics.\n\nHere, we demonstrate a simple experiment of training a UNet\non an inpainting task on the Urban100 dataset of natural images."
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "import deepinv as dinv\nimport torch\n\ndevice = dinv.utils.get_freer_gpu() if torch.cuda.is_available() else \"cpu\"\nrng = torch.Generator(device=device).manual_seed(0)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "language": "markdown"
      },
      "source": "## Setup\n\nFirst, define the physics that we want to train on.\n\n"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "physics = dinv.physics.Inpainting((1, 64, 64), mask=0.8, device=device, rng=rng)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "language": "markdown"
      },
      "source": "Then define the dataset. Here we simulate a dataset of measurements from Urban100.\n\n> **Tip**\n>\n> See datasets for types of datasets DeepInverse supports: e.g. paired, ground-truth-free,\n> single-image...\n>\n>\n"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "from torchvision.transforms import Compose, ToTensor, Resize, CenterCrop, Grayscale\n\ndataset = dinv.datasets.Urban100HR(\n    \".\",\n    download=True,\n    transform=Compose([ToTensor(), Grayscale(), Resize(256), CenterCrop(64)]),\n)\n\ntrain_dataset, test_dataset = torch.utils.data.random_split(\n    torch.utils.data.Subset(dataset, range(50)), (0.8, 0.2)\n)\n\ndataset_path = dinv.datasets.generate_dataset(\n    train_dataset=train_dataset,\n    test_dataset=test_dataset,\n    physics=physics,\n    device=device,\n    save_dir=\".\",\n    batch_size=1,\n)\n\ntrain_dataloader = torch.utils.data.DataLoader(\n    dinv.datasets.HDF5Dataset(dataset_path, train=True), shuffle=True\n)\ntest_dataloader = torch.utils.data.DataLoader(\n    dinv.datasets.HDF5Dataset(dataset_path, train=False), shuffle=False\n)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "language": "markdown"
      },
      "source": "Visualize a data sample:\n\n"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "x, y = next(iter(test_dataloader))\ndinv.utils.plot({\"Ground truth\": x, \"Measurement\": y, \"Mask\": physics.mask})"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "language": "markdown"
      },
      "source": "For the model we use an artifact removal model, where\n$\\phi_{\\theta}$ is a U-Net\n\n\\begin{align}f_{\\theta}(y) = \\phi_{\\theta}(A^{\\top}(y))\\end{align}\n\n"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "model = dinv.models.ArtifactRemoval(\n    dinv.models.UNet(1, 1, scales=2, batch_norm=False).to(device)\n)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "language": "markdown"
      },
      "source": "## Train the model\nWe train the model using the [`deepinv.Trainer`](https://deepinv.github.io/deepinv/api/stubs/deepinv.Trainer.html) class,\nwhich cleanly handles all steps for training.\n\nWe perform supervised learning and use the mean squared error as loss function.\nSee losses for all supported state-of-the-art loss functions.\n\nWe evaluate using the PSNR metric.\nSee metrics for all supported metrics.\n\n<div class=\"alert alert-info\"><h4>Note</h4><p>In this example, we only train for a few epochs to keep the training time short.\n      For a good reconstruction quality, we recommend to train for at least 100 epochs.</p></div>\n\n"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "trainer = dinv.Trainer(\n    model=model,\n    physics=physics,\n    optimizer=torch.optim.Adam(model.parameters(), lr=1e-3),\n    train_dataloader=train_dataloader,\n    eval_dataloader=test_dataloader,\n    epochs=5,\n    losses=dinv.loss.SupLoss(metric=dinv.metric.MSE()),\n    metrics=dinv.metric.PSNR(),\n    device=device,\n    plot_images=True,\n    show_progress_bar=False,\n)\n\n_ = trainer.train()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "language": "markdown"
      },
      "source": "## Test the network\nWe can now test the trained network using the [`deepinv.test`](https://deepinv.github.io/deepinv/api/stubs/deepinv.test.html) function.\n\nThe testing function will compute metrics and plot and save the results.\n"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "trainer.test(test_dataloader)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}