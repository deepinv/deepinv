{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3b88970",
   "metadata": {},
   "outputs": [],
   "source": [
    "r\"\"\"\n",
    "Benchmarking pretrained denoisers\n",
    "===================================================\n",
    "\n",
    "This example provides a tour of the denoisers in DeepInverse.\n",
    "A denoiser is a model that takes in a noisy image and outputs a denoised version of it.\n",
    "Basically, it solves the following problem:\n",
    "\n",
    ".. math::\n",
    "\n",
    "    \\underset{x}{\\min}\\|x -  \\denoiser{x + \\sigma \\epsilon}{\\sigma}\\|_2^2.\n",
    "\n",
    "The denoisers in DeepInverse comes with different flavors, depending on whether they are derived from\n",
    "analytical image processing techniques or learned from data.\n",
    "This example will show how to use the different denoisers in DeepInverse, compare their performances,\n",
    "and highlights the different tradeoffs they offer.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ac81be2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "import torch\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import deepinv as dinv\n",
    "from deepinv.utils import plot_inset, load_example, zip_strict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f0114d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load test images\n",
    "# ----------------\n",
    "#\n",
    "# First, let's load a test image to illustrate the denoisers.\n",
    "\n",
    "dtype = torch.float32\n",
    "device = \"cpu\"\n",
    "img_size = (173, 125)\n",
    "\n",
    "image = load_example(\n",
    "    \"CBSD_0010.png\", grayscale=False, device=device, dtype=dtype, img_size=img_size\n",
    ")\n",
    "\n",
    "# Next, set the global random seed from pytorch to ensure reproducibility of the example.\n",
    "torch.manual_seed(0)\n",
    "torch.cuda.manual_seed(0)\n",
    "\n",
    "# Finally, create a noisy version of the image with a fixed noise level sigma.\n",
    "sigma = 0.2\n",
    "noisy_image = image + sigma * torch.randn_like(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d445b804",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "outputs": [],
   "source": [
    "# We are now ready to explore the different denoisers.\n",
    "#\n",
    "# Classical Denoisers\n",
    "# -------------------\n",
    "#\n",
    "# DeepInverse provides a set of classical denoisers such as :class:`deepinv.models.BM3D`,\n",
    "# :class:`deepinv.models.TGVDenoiser`, or :class:`deepinv.models.WaveletDictDenoiser`.\n",
    "#\n",
    "# They can be easily used simply by instanciating their corresponding class,\n",
    "# and calling them with the noisy image and the noise level.\n",
    "#\n",
    "bm3d = dinv.models.BM3D()\n",
    "tgv = dinv.models.TGVDenoiser()\n",
    "wavelet = dinv.models.WaveletDictDenoiser()\n",
    "\n",
    "imgs = [\n",
    "    image,\n",
    "    noisy_image,\n",
    "    bm3d(noisy_image, sigma),\n",
    "    tgv(noisy_image, sigma),\n",
    "    wavelet(noisy_image, sigma),\n",
    "]\n",
    "psnr = [dinv.metric.cal_psnr(image, im).item() for im in imgs[1:]]\n",
    "titles = [\"Original\", \"Noisy\", \"BM3D\", \"TGV\", \"Wavelet\"]\n",
    "subtitles = [\"PSNR:\"] + [f\"{p:.2f} dB\" for p in psnr]\n",
    "\n",
    "plot_inset(\n",
    "    img_list=imgs,\n",
    "    titles=titles,\n",
    "    subtitles=subtitles,\n",
    "    suptitle=rf\"Noise level $\\sigma={sigma:.2f}$\",\n",
    "    extract_size=0.2,\n",
    "    extract_loc=(0.5, 0.0),\n",
    "    inset_size=0.5,\n",
    "    figsize=(len(imgs) * 1.5, 2.5),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81d5c5bb",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "outputs": [],
   "source": [
    "# Deep Denoisers\n",
    "# --------------\n",
    "#\n",
    "# DeepInverse also provides a set of deep denoisers.\n",
    "# Most of these denoisers are available with pretrained weights, so they can be used readily.\n",
    "# To instantiate them, you can simply call their corresponding class with default\n",
    "# parameters and ``pretrained=\"download\"`` to load their weights.\n",
    "# You can then apply them by calling the model with the noisy image and the noise level.\n",
    "dncnn = dinv.models.DnCNN()\n",
    "drunet = dinv.models.DRUNet()\n",
    "swinir = dinv.models.SwinIR()\n",
    "scunet = dinv.models.SCUNet()\n",
    "\n",
    "imgs = [\n",
    "    image,\n",
    "    noisy_image,\n",
    "    dncnn(noisy_image, sigma),\n",
    "    drunet(noisy_image, sigma),\n",
    "    scunet(noisy_image, sigma),\n",
    "    swinir(noisy_image, sigma),\n",
    "]\n",
    "titles = [\n",
    "    \"Original\",\n",
    "    \"Noisy\",\n",
    "    \"DnCNN\",\n",
    "    \"DRUNet\",\n",
    "    \"SCUNet\",\n",
    "    \"SwinIR\",\n",
    "]\n",
    "psnr = [dinv.metric.cal_psnr(image, im).item() for im in imgs[1:]]\n",
    "subtitles = [\"PSNR:\"] + [f\"{p:.2f} dB\" for p in psnr]\n",
    "\n",
    "plot_inset(\n",
    "    img_list=imgs,\n",
    "    titles=titles,\n",
    "    subtitles=subtitles,\n",
    "    suptitle=rf\"Noise level $\\sigma={sigma:.2f}$\",\n",
    "    extract_size=0.2,\n",
    "    extract_loc=(0.5, 0.0),\n",
    "    inset_size=0.5,\n",
    "    figsize=(len(imgs) * 1.5, 2.5),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e836c76",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comparing denoisers\n",
    "# -------------------\n",
    "#\n",
    "# As we have seen, these denoisers don't have the same training or expected behavior depending on\n",
    "# the noise level. Indeed, there are three classes of denoisers:\n",
    "#\n",
    "# - *Fixed-noise level denoisers:* Some denoisers are trained to be able to recover\n",
    "#   images from noisy input with a fixed noise levels. Typically, this is the case\n",
    "#   of :class:`deepinv.models.DnCNN` or :class:`deepinv.models.SwinIR`.\n",
    "# - *Adaptive-level denoisers:* These denoisers are able to adapt to the noise level\n",
    "#   of a given image. Basically, these denoisers' performance vary strognly with the\n",
    "#   value ``sigma`` given as an input. This is typically the case for :class:`deepinv.models.BM3D`,\n",
    "#   :class:`deepinv.models.SCUNet`, or :class:`deepinv.models.DRUNet`, but also for denoisers based on regularisations\n",
    "#   like :class:`deepinv.models.WaveletDictDenoiser`.\n",
    "#   A typical caveat of regularisation-based denoisers is that the second parameter doesn't\n",
    "#   correspond to ``sigma`` but to a threshold value, which needs to be adapted to the noise level.\n",
    "# - *Blind denoisers:* These denoisers estimate the level of noise in the input image\n",
    "#   to output the cleanest image possible. Example of blind denoisers are :class:`deepinv.models.SCUNet`\n",
    "#   or :class:`deepinv.models.Restormer`.\n",
    "#\n",
    "# Let us generate a set of noisy images with varying noise levels.\n",
    "\n",
    "noise_levels = torch.logspace(-2, 0, 9)\n",
    "noise = torch.randn((len(noise_levels), *image.shape[1:]))\n",
    "noisy_images = image + noise_levels[:, None, None, None] * noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1623e319",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We first record the PSNR of the noisy images.\n",
    "\n",
    "psnr = dinv.loss.metric.PSNR()\n",
    "psnr_x = psnr(noisy_images, image)\n",
    "res = [\n",
    "    {\"sigma\": sig.item(), \"denoiser\": \"Noisy\", \"psnr\": v.item(), \"time\": 0.0}\n",
    "    for sig, v in zip_strict(noise_levels, psnr_x)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b43c0caa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Then, we evaluate the various denoisers with our set of varying noise level.\n",
    "# Note that to minimize the computation time, we evaluate the performances in\n",
    "# batch, by passing all the noisy images at once to the denoiser, with varying\n",
    "# noise levels for each entry in the batch.\n",
    "#\n",
    "# We also store the runtime of each denoiser to evaluate the tradeoff between computation\n",
    "# time and performances.\n",
    "\n",
    "denoisers = {\n",
    "    \"DRUNet\": drunet,\n",
    "    # 'SwinIR': sinwir, # SwinIR is slow for this example, skipping it in the doc\n",
    "    \"SCUNet\": scunet,\n",
    "    \"DnCNN\": dncnn,\n",
    "    \"BM3D\": bm3d,\n",
    "    \"Wavelet\": wavelet,\n",
    "}\n",
    "\n",
    "for name, d in denoisers.items():\n",
    "    print(f\"Denoiser {name}...\", end=\"\", flush=True)\n",
    "    t_start = time.perf_counter()\n",
    "    with torch.no_grad():\n",
    "        clean_images = d(noisy_images, noise_levels)\n",
    "        psnr_x = psnr(clean_images, image)\n",
    "    runtime = time.perf_counter() - t_start\n",
    "    res.extend(\n",
    "        [\n",
    "            {\"sigma\": sig.item(), \"denoiser\": name, \"psnr\": v.item(), \"time\": runtime}\n",
    "            for sig, v in zip_strict(noise_levels, psnr_x)\n",
    "        ]\n",
    "    )\n",
    "    print(f\" done ({runtime:.2f}s)\")\n",
    "df = pd.DataFrame(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab478675",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "# We can now compare the performances of the different denoisers.\n",
    "# We plot the PSNR of the denoised images as a function of the noise level\n",
    "# for each denoiser.\n",
    "\n",
    "styles = {\n",
    "    \"Noisy\": dict(ls=\"--\", color=\"black\"),\n",
    "}\n",
    "groups = df.groupby(\"denoiser\")\n",
    "_, ax = plt.subplots(figsize=(6, 4))\n",
    "for name, g in groups:\n",
    "    g.plot(x=r\"sigma\", y=\"psnr\", label=name, ax=ax, **styles.get(name, {}))\n",
    "ax.set_xscale(\"log\")\n",
    "ax.set_xlabel(r\"$\\sigma$\")\n",
    "ax.set_ylabel(\"PSNR\")\n",
    "plt.legend(bbox_to_anchor=(1.02, 1), loc=\"upper left\", borderaxespad=0)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "311c1640",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We see that overall :class:`deepinv.models.DRUNet` achieves the best performances for all\n",
    "# noise levels. It also achieves a good tradeoff between computation time and performances.\n",
    "#\n",
    "# Tuning regularisation-based denoisers\n",
    "# -------------------------------------\n",
    "#\n",
    "# Note that the performances of denoisers that are based on regularisation,\n",
    "# like :class:`deepinv.models.WaveletDictDenoiser`, are not well adapted to the noise level.\n",
    "# Indeed, the second parameter of these denoisers is ``th``, which does not directly match the\n",
    "# noise level ``sigma``. We will now show how to tune the threshold to match the noise level.\n",
    "#\n",
    "# First we start by evaluating the performances of the wavelet denoiser for a grid of threshold\n",
    "# values on the noisy images.\n",
    "wavelets = dinv.models.WaveletDictDenoiser()\n",
    "thresholds = torch.logspace(-3, 1, 13)\n",
    "\n",
    "res = []\n",
    "for th in thresholds:\n",
    "    t_start = time.perf_counter()\n",
    "    clean_images = wavelets(noisy_images, th.item())\n",
    "    runtime = time.perf_counter() - t_start\n",
    "    res.extend(\n",
    "        {\n",
    "            \"psnr\": psnr(clean_img[None], image).item(),\n",
    "            \"sigma\": sig.item(),\n",
    "            \"th\": th.item(),\n",
    "            \"time\": runtime,\n",
    "        }\n",
    "        for sig, clean_img in zip_strict(noise_levels, clean_images)\n",
    "    )\n",
    "df_wavelet = pd.DataFrame(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "201759f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can now display how the performances vary with the value of the threshold,\n",
    "# and what is the best threshold for each noise level.\n",
    "# sphinx_gallery_thumbnail_number = 3\n",
    "groups = df_wavelet.groupby(\"sigma\")[[\"sigma\", \"psnr\", \"th\"]]\n",
    "best_th_psnr = groups.apply(lambda g: g.loc[g[\"psnr\"].idxmax()])\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(15, 4))\n",
    "cmap = plt.get_cmap(\"viridis\")\n",
    "norm = plt.cm.colors.LogNorm(\n",
    "    vmin=df_wavelet[\"sigma\"].min(), vmax=df_wavelet[\"sigma\"].max()\n",
    ")\n",
    "for sig, group in groups:\n",
    "    group.plot(x=\"th\", y=\"psnr\", ax=axes[0], color=cmap(norm(sig)), label=None)\n",
    "axes[0].set_xscale(\"log\")\n",
    "axes[0].set_ylabel(\"Threshold\")\n",
    "axes[0].set_ylabel(\"PSNR\")\n",
    "axes[0].legend([])\n",
    "fig.colorbar(\n",
    "    plt.cm.ScalarMappable(norm=norm, cmap=cmap),\n",
    "    label=r\"$\\sigma$\",\n",
    "    location=\"top\",\n",
    "    ax=axes[0],\n",
    ")\n",
    "\n",
    "axes[1].set_title(\"Best threshold for each noise level\")\n",
    "axes[1].loglog(best_th_psnr[\"sigma\"], best_th_psnr[\"th\"], marker=\"o\")\n",
    "axes[1].set_xlabel(r\"$\\sigma$\")\n",
    "axes[1].set_ylabel(r\"Best threshold\")\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f8a57c9",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "outputs": [],
   "source": [
    "# With this tuning, we can update our comparison of the different denoisers to account for\n",
    "# the performances of :class:`deepinv.models.WaveletDictDenoiser` once the threshold have been tuned\n",
    "\n",
    "merge_df = best_th_psnr.reset_index(drop=True).drop(columns=\"th\")\n",
    "merge_df[\"denoiser\"] = \"Wavelet (tuned)\"\n",
    "merge_df = pd.concat([df.query(\"denoiser != 'Wavelet'\"), merge_df])\n",
    "\n",
    "_, ax = plt.subplots(figsize=(6, 4))\n",
    "for name, g in merge_df.groupby(\"denoiser\"):\n",
    "    g.plot(x=r\"sigma\", y=\"psnr\", label=name, ax=ax, **styles.get(name, {}))\n",
    "ax.set_xscale(\"log\")\n",
    "ax.set_xlabel(r\"$\\sigma$\")\n",
    "ax.set_ylabel(\"PSNR\")\n",
    "plt.legend(bbox_to_anchor=(1.02, 1), loc=\"upper left\", borderaxespad=0)\n",
    "plt.tight_layout()\n",
    "\n",
    "# %%#\n",
    "# Adapting fixed-noise level denoisers\n",
    "# ------------------------------------\n",
    "#\n",
    "# For fixed-noise level denoiser, we also see poor performances, since these models were trained\n",
    "# for a given noise level which does not correspond to the noise level of the input image. See\n",
    "# :ref:`pretrained-weights <pretrained-weights>` for more details on the chose noise level.\n",
    "# A way to improve the performance of these models is to artificially rescale the input image\n",
    "# to match the training noise level.\n",
    "# We can define a wrapper that automatically applies this rescaling.\n",
    "\n",
    "\n",
    "class AdaptedDenoiser:\n",
    "    r\"\"\"\n",
    "    This function rescales the input image to match the noise level of the model,\n",
    "    applies the denoiser, and then rescales the output to the original noise level.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, model, sigma_train):\n",
    "        self.model = model\n",
    "        self.sigma_train = sigma_train\n",
    "\n",
    "    def __call__(self, image, sigma):\n",
    "        if isinstance(sigma, torch.Tensor):\n",
    "            # If sigma is a tensor, we assume it is one value per element in the batch\n",
    "            assert len(sigma) == image.shape[0]\n",
    "            sigma = sigma[:, None, None, None]\n",
    "\n",
    "        # Rescale the output to match the original noise level\n",
    "        rescaled_image = image / sigma * self.sigma_train\n",
    "        with torch.no_grad():\n",
    "            output = self.model(rescaled_image, self.sigma_train)\n",
    "        output = output * sigma / self.sigma_train\n",
    "        return output\n",
    "\n",
    "\n",
    "# Apply to DnCNN and SwinIR\n",
    "sigma_train_dncnn = 2.0 / 255.0\n",
    "adapted_dncnn = AdaptedDenoiser(dncnn, sigma_train_dncnn)\n",
    "\n",
    "# Apply SwinIR\n",
    "# sigma_train_swinir = 15.0 / 255.0\n",
    "# adapted_swinir = AdaptedDenoiser(swinir, sigma_train_swinir)\n",
    "\n",
    "# sphinx_gallery_multi_image = \"single\"\n",
    "imgs = [\n",
    "    image,\n",
    "    noisy_image,\n",
    "    dncnn(noisy_image, sigma),\n",
    "    adapted_dncnn(noisy_image, sigma),\n",
    "]\n",
    "titles = [\"Original\", \"Noisy\", \"DnCNN\", \"DnCNN \\n(adapted)\"]\n",
    "psnr_list = [dinv.metric.cal_psnr(image, im).item() for im in imgs[1:]]\n",
    "subtitles = [\"PSNR:\"] + [f\"{p:.2f} dB\" for p in psnr_list]\n",
    "\n",
    "plot_inset(\n",
    "    img_list=imgs,\n",
    "    titles=titles,\n",
    "    subtitles=subtitles,\n",
    "    suptitle=rf\"Noise level $\\sigma={sigma:.2f}$\",\n",
    "    extract_size=0.2,\n",
    "    extract_loc=(0.5, 0.0),\n",
    "    inset_size=0.5,\n",
    "    figsize=(len(imgs) * 1.5, 2.5),\n",
    ")\n",
    "\n",
    "imgs = [drunet(noisy_image, sigma), scunet(noisy_image, sigma)]\n",
    "titles = [\"DRUNet\", \"SCUNet\"]\n",
    "psnr_list = [dinv.metric.cal_psnr(image, im).item() for im in imgs]\n",
    "subtitles = [f\"{p:.2f} dB\" for p in psnr_list]\n",
    "\n",
    "plot_inset(\n",
    "    img_list=imgs,\n",
    "    titles=titles,\n",
    "    subtitles=subtitles,\n",
    "    suptitle=rf\"Noise level $\\sigma={sigma:.2f}$\",\n",
    "    extract_size=0.2,\n",
    "    extract_loc=(0.5, 0.0),\n",
    "    inset_size=0.5,\n",
    "    tight=False,\n",
    "    figsize=(len(imgs) * 1.75, 2.5),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f993636e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can finally update our comparison with the adapted denoisers for DnCNN and SwinIR.\n",
    "\n",
    "adapted_denoisers = {\n",
    "    # \"SwinIR\": adapted_swinir, # SwinIR is slow for this example, skipping it in the doc\n",
    "    \"DnCNN (adapted)\": adapted_dncnn,\n",
    "}\n",
    "res = []\n",
    "for name, d in adapted_denoisers.items():\n",
    "    print(f\"Denoiser {name}...\", end=\"\", flush=True)\n",
    "    t_start = time.perf_counter()\n",
    "    with torch.no_grad():\n",
    "        clean_images = d(noisy_images, noise_levels)\n",
    "        psnr_x = psnr(clean_images, image)\n",
    "    runtime = time.perf_counter() - t_start\n",
    "    res.extend(\n",
    "        [\n",
    "            {\"sigma\": sig.item(), \"denoiser\": name, \"psnr\": v.item(), \"time\": runtime}\n",
    "            for sig, v in zip_strict(noise_levels, psnr_x)\n",
    "        ]\n",
    "    )\n",
    "    print(f\" done ({runtime:.2f}s)\")\n",
    "df_adapted = pd.DataFrame(res)\n",
    "merge_df = pd.concat(\n",
    "    [merge_df.query(\"~denoiser.isin(['DnCNN', 'SwinIR'])\"), df_adapted]\n",
    ")\n",
    "\n",
    "_, ax = plt.subplots(figsize=(6, 4))\n",
    "for name, g in merge_df.groupby(\"denoiser\"):\n",
    "    g.plot(x=r\"sigma\", y=\"psnr\", label=name, ax=ax, **styles.get(name, {}))\n",
    "ax.set_xscale(\"log\")\n",
    "ax.set_xlabel(r\"$\\sigma$\")\n",
    "ax.set_ylabel(\"PSNR\")\n",
    "plt.legend(bbox_to_anchor=(1.02, 1), loc=\"upper left\", borderaxespad=0)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acf78338",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can see that the adapted denoisers achieve better performances than the original ones,\n",
    "# but they are still not as good as DRUNet which is trained for a wide range of noise levels.\n",
    "#\n",
    "# Finally, we can also compare the tradeoff between computation time and performances of the different denoisers.\n",
    "fig = plt.figure(figsize=(12, 6))\n",
    "grid = plt.GridSpec(2, 2, height_ratios=[0.25, 0.75])\n",
    "for i, sig in enumerate(noise_levels[[0, 4]]):\n",
    "    ax = fig.add_subplot(grid[1, i])\n",
    "    to_plot = merge_df.query(f\"sigma == {sig}\")\n",
    "    handles = []\n",
    "    for name, g in to_plot.groupby(\"denoiser\"):\n",
    "        handles.append(ax.scatter(g[\"time\"], g[\"psnr\"], label=name))\n",
    "    ax.set_title(rf\"$\\sigma={sig:.2f}$\")\n",
    "    ax.set_xscale(\"log\")\n",
    "    ax.set_xlabel(\"Time (s)\")\n",
    "    ax.set_ylabel(\"PSNR\")\n",
    "\n",
    "ax_legend = fig.add_subplot(grid[0, :])\n",
    "ax_legend.legend(handles=handles, ncol=3, loc=\"center\")\n",
    "ax_legend.set_axis_off()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "256c8876",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We see that depending on the noise-level, the tadeoff between computation time\n",
    "# and performances changes, with the deep denoisers performing the best"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
