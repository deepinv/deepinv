{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66c85f4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "r\"\"\"\n",
    "Self-supervised denoising with the UNSURE loss.\n",
    "====================================================================================================\n",
    "\n",
    "This example shows you how to train a denoiser network in a fully self-supervised way,\n",
    "i.e., using noisy images with unknown noise level only via the UNSURE loss, which is introduced by :footcite:t:`tachella2024unsure`.\n",
    "\n",
    "The UNSURE optimization problem for Gaussian denoising with unknown noise level is defined as:\n",
    "\n",
    ".. math::\n",
    "\n",
    "    \\min_{R} \\max_{\\sigma^2} \\frac{1}{m}\\|y-\\inverse{y}\\|_2^2 +\\frac{2\\sigma^2}{m\\tau}b^{\\top} \\left(\\inverse{y+\\tau b}-\\inverse{y}\\right)\n",
    "\n",
    "where :math:`R` is the trainable network, :math:`y` is the noisy image with :math:`m` pixels,\n",
    ":math:`b\\sim \\mathcal{N}(0,1)` is a Gaussian random variable,\n",
    ":math:`\\tau` is a small positive number, and :math:`\\odot` is an elementwise multiplication.\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "from pathlib import Path\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import transforms, datasets\n",
    "\n",
    "import deepinv as dinv\n",
    "from deepinv.utils import get_data_home"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e34f1a40",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup paths for data loading and results.\n",
    "# ---------------------------------------------------------------\n",
    "#\n",
    "\n",
    "BASE_DIR = Path(\".\")\n",
    "DATA_DIR = BASE_DIR / \"measurements\"\n",
    "CKPT_DIR = BASE_DIR / \"ckpts\"\n",
    "ORIGINAL_DATA_DIR = get_data_home()\n",
    "\n",
    "# Set the global random seed from pytorch to ensure reproducibility of the example.\n",
    "torch.manual_seed(0)\n",
    "\n",
    "device = dinv.utils.get_freer_gpu() if torch.cuda.is_available() else \"cpu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10f7b794",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load base image datasets\n",
    "# ----------------------------------------------------------------------------------\n",
    "# In this example, we use the MNIST dataset as the base image dataset.\n",
    "#\n",
    "\n",
    "operation = \"denoising\"\n",
    "train_dataset_name = \"MNIST\"\n",
    "\n",
    "transform = transforms.Compose([transforms.ToTensor()])\n",
    "\n",
    "train_dataset = datasets.MNIST(\n",
    "    root=ORIGINAL_DATA_DIR, train=True, transform=transform, download=True\n",
    ")\n",
    "test_dataset = datasets.MNIST(\n",
    "    root=ORIGINAL_DATA_DIR, train=False, transform=transform, download=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cb9d992",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate a dataset of noisy images\n",
    "# ----------------------------------------------------------------------------------\n",
    "#\n",
    "# We generate a dataset of noisy images corrupted by Gaussian noise.\n",
    "#\n",
    "# .. note::\n",
    "#\n",
    "#       We use a subset of the whole training set to reduce the computational load of the example.\n",
    "#       We recommend to use the whole set by setting ``n_images_max=None`` to get the best results.\n",
    "\n",
    "true_sigma = 0.1\n",
    "\n",
    "# defined physics\n",
    "physics = dinv.physics.Denoising(dinv.physics.GaussianNoise(sigma=true_sigma))\n",
    "\n",
    "# Use parallel dataloader if using a GPU to speed up training,\n",
    "# otherwise, as all computes are on CPU, use synchronous data loading.\n",
    "num_workers = 4 if torch.cuda.is_available() else 0\n",
    "\n",
    "n_images_max = (\n",
    "    100 if torch.cuda.is_available() else 5\n",
    ")  # number of images used for training\n",
    "\n",
    "measurement_dir = DATA_DIR / train_dataset_name / operation\n",
    "deepinv_datasets_path = dinv.datasets.generate_dataset(\n",
    "    train_dataset=train_dataset,\n",
    "    test_dataset=test_dataset,\n",
    "    physics=physics,\n",
    "    device=device,\n",
    "    save_dir=measurement_dir,\n",
    "    train_datapoints=n_images_max,\n",
    "    test_datapoints=n_images_max,\n",
    "    num_workers=num_workers,\n",
    "    dataset_filename=\"demo_sure\",\n",
    ")\n",
    "\n",
    "train_dataset = dinv.datasets.HDF5Dataset(path=deepinv_datasets_path, train=True)\n",
    "test_dataset = dinv.datasets.HDF5Dataset(path=deepinv_datasets_path, train=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ff39ea1",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "# Set up the denoiser network\n",
    "# ---------------------------------------------------------------\n",
    "#\n",
    "# We use a simple U-Net architecture with 2 scales as the denoiser network.\n",
    "\n",
    "model = dinv.models.ArtifactRemoval(\n",
    "    dinv.models.UNet(in_channels=1, out_channels=1, scales=2).to(device)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4df68f31",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up the training parameters\n",
    "# --------------------------------------------\n",
    "# We set :class:`deepinv.loss.SureGaussianLoss` as the training loss with the ``unsure=True`` option.\n",
    "# The optimization with respect to the noise level is done by stochastic gradient descent with momentum\n",
    "# inside the loss class, so it is seamlessly integrated into the training process.\n",
    "#\n",
    "# .. note::\n",
    "#\n",
    "#       There are (UN)SURE losses for various noise distributions. See also :class:`deepinv.loss.SurePGLoss` for mixed Poisson-Gaussian noise.\n",
    "#\n",
    "# .. note::\n",
    "#\n",
    "#       We train for only 10 epochs to reduce the computational load of the example. We recommend to train for more epochs to get the best results.\n",
    "#\n",
    "\n",
    "epochs = 10  # choose training epochs\n",
    "learning_rate = 5e-4\n",
    "batch_size = 32 if torch.cuda.is_available() else 1\n",
    "\n",
    "sigma_init = 0.05  # initial guess for the noise level\n",
    "step_size = 1e-4  # step size for the optimization of the noise level\n",
    "momentum = 0.9  # momentum for the optimization of the noise level\n",
    "\n",
    "# choose self-supervised training loss\n",
    "loss = dinv.loss.SureGaussianLoss(\n",
    "    sigma=sigma_init, unsure=True, step_size=step_size, momentum=momentum\n",
    ")\n",
    "\n",
    "# choose optimizer and scheduler\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate, weight_decay=1e-8)\n",
    "\n",
    "print(f\"INIT. noise level {loss.sigma2.sqrt().item():.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "897086b9",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "# Train the network\n",
    "# --------------------------------------------\n",
    "# We train the network using the :class:`deepinv.Trainer` class.\n",
    "#\n",
    "# To simulate a realistic self-supervised learning scenario, we do not use any supervised metrics for training,\n",
    "# such as PSNR or SSIM, which require clean ground truth images.\n",
    "#\n",
    "# .. tip::\n",
    "#\n",
    "#       We can use the same self-supervised loss for evaluation (without updating the noise level, which is equivalent to SURE with the estimated noise level),\n",
    "#       as it does not require clean images,\n",
    "#       to monitor the training process (e.g. for early stopping). This is done automatically when `metrics=None` and `early_stop>0` in the trainer.\n",
    "\n",
    "train_dataloader = DataLoader(\n",
    "    train_dataset, batch_size=batch_size, num_workers=num_workers, shuffle=True\n",
    ")\n",
    "\n",
    "# Initialize the trainer\n",
    "trainer = dinv.Trainer(\n",
    "    model=model,\n",
    "    physics=physics,\n",
    "    epochs=epochs,\n",
    "    losses=loss,\n",
    "    compute_eval_losses=True,  # use self-supervised loss for evaluation\n",
    "    early_stop_on_losses=True,  # stop using self-supervised eval loss\n",
    "    metrics=None,  # no supervised metrics\n",
    "    early_stop=2,  # early stop using the self-supervised loss on the test set\n",
    "    optimizer=optimizer,\n",
    "    device=device,\n",
    "    train_dataloader=train_dataloader,\n",
    "    eval_dataloader=train_dataloader,\n",
    "    plot_images=False,\n",
    "    save_path=str(CKPT_DIR / operation),\n",
    "    verbose=True,  # print training information\n",
    "    show_progress_bar=False,  # disable progress bar for better vis in sphinx gallery.\n",
    ")\n",
    "\n",
    "# Train the network\n",
    "model = trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce22c6ba",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "# Check learned noise level\n",
    "# --------------------------------------------\n",
    "# We can verify the learned noise level by checking the estimated noise level from the loss function.\n",
    "#\n",
    "\n",
    "est_sigma = loss.sigma2.sqrt().item()\n",
    "\n",
    "print(f\"LEARNED noise level {est_sigma:.3f}\")\n",
    "print(f\"Estimation error noise level {abs(est_sigma-true_sigma):.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6665de36",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test the network\n",
    "# --------------------------------------------\n",
    "#\n",
    "\n",
    "test_dataloader = DataLoader(\n",
    "    test_dataset, batch_size=batch_size, num_workers=num_workers, shuffle=False\n",
    ")\n",
    "\n",
    "trainer.plot_images = True\n",
    "trainer.test(test_dataloader=test_dataloader, metrics=dinv.metric.PSNR())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04f5c5a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# :References:\n",
    "#\n",
    "# .. footbibliography::"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
