{
  "cells": [
    {
      "id": "b5d3563e",
      "cell_type": "code",
      "metadata": {
        "language": "python"
      },
      "execution_count": null,
      "source": "# Install deepinv (skip if already installed)\n%pip install deepinv",
      "outputs": []
    },
    {
      "id": "f04dfa0d",
      "cell_type": "markdown",
      "source": "<!-- MathJax macro definitions inserted automatically -->\n$$\n\\newcommand{\\forw}[1]{{A\\left({#1}\\right)}}\n\\newcommand{\\noise}[1]{{N\\left({#1}\\right)}}\n\\newcommand{\\inverse}[1]{{R\\left({#1}\\right)}}\n\\newcommand{\\inversef}[2]{{R\\left({#1},{#2}\\right)}}\n\\newcommand{\\inversename}{R}\n\\newcommand{\\reg}[1]{{g_\\sigma\\left({#1}\\right)}}\n\\newcommand{\\regname}{g_\\sigma}\n\\newcommand{\\sensor}[1]{{\\eta\\left({#1}\\right)}}\n\\newcommand{\\datafid}[2]{{f\\left({#1},{#2}\\right)}}\n\\newcommand{\\datafidname}{f}\n\\newcommand{\\distance}[2]{{d\\left({#1},{#2}\\right)}}\n\\newcommand{\\distancename}{d}\n\\newcommand{\\denoiser}[2]{{\\operatorname{D}_{{#2}}\\left({#1}\\right)}}\n\\newcommand{\\denoisername}{\\operatorname{D}_{\\sigma}}\n\\newcommand{\\xset}{\\mathcal{X}}\n\\newcommand{\\yset}{\\mathcal{Y}}\n\\newcommand{\\group}{\\mathcal{G}}\n\\newcommand{\\metric}[2]{{d\\left({#1},{#2}\\right)}}\n\\newcommand{\\loss}[1]{{\\mathcal\\left({#1}\\right)}}\n\\newcommand{\\conj}[1]{{\\overline{#1}^{\\top}}}\n$$",
      "metadata": {
        "language": "markdown"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "language": "markdown"
      },
      "source": "\n# Self-supervised denoising with the UNSURE loss.\n\nThis example shows you how to train a denoiser network in a fully self-supervised way,\ni.e., using noisy images with unknown noise level only via the UNSURE loss, which is introduced by :footcite:t:`tachella2024unsure`.\n\nThe UNSURE optimization problem for Gaussian denoising with unknown noise level is defined as:\n\n\\begin{align}\\min_{R} \\max_{\\sigma^2} \\frac{1}{m}\\|y-\\inverse{y}\\|_2^2 +\\frac{2\\sigma^2}{m\\tau}b^{\\top} \\left(\\inverse{y+\\tau b}-\\inverse{y}\\right)\\end{align}\n\nwhere $R$ is the trainable network, $y$ is the noisy image with $m$ pixels,\n$b\\sim \\mathcal{N}(0,1)$ is a Gaussian random variable,\n$\\tau$ is a small positive number, and $\\odot$ is an elementwise multiplication."
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "from pathlib import Path\n\nimport torch\nfrom torch.utils.data import DataLoader\nfrom torchvision import transforms, datasets\n\nimport deepinv as dinv\nfrom deepinv.utils import get_data_home"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "language": "markdown"
      },
      "source": "## Setup paths for data loading and results.\n\n"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "BASE_DIR = Path(\".\")\nDATA_DIR = BASE_DIR / \"measurements\"\nCKPT_DIR = BASE_DIR / \"ckpts\"\nORIGINAL_DATA_DIR = get_data_home()\n\n# Set the global random seed from pytorch to ensure reproducibility of the example.\ntorch.manual_seed(0)\n\ndevice = dinv.utils.get_freer_gpu() if torch.cuda.is_available() else \"cpu\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "language": "markdown"
      },
      "source": "## Load base image datasets\nIn this example, we use the MNIST dataset as the base image dataset.\n\n"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "operation = \"denoising\"\ntrain_dataset_name = \"MNIST\"\n\ntransform = transforms.Compose([transforms.ToTensor()])\n\ntrain_dataset = datasets.MNIST(\n    root=ORIGINAL_DATA_DIR, train=True, transform=transform, download=True\n)\ntest_dataset = datasets.MNIST(\n    root=ORIGINAL_DATA_DIR, train=False, transform=transform, download=True\n)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "language": "markdown"
      },
      "source": "## Generate a dataset of noisy images\n\nWe generate a dataset of noisy images corrupted by Gaussian noise.\n\n<div class=\"alert alert-info\"><h4>Note</h4><p>We use a subset of the whole training set to reduce the computational load of the example.\n      We recommend to use the whole set by setting ``n_images_max=None`` to get the best results.</p></div>\n"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "true_sigma = 0.1\n\n# defined physics\nphysics = dinv.physics.Denoising(dinv.physics.GaussianNoise(sigma=true_sigma))\n\n# Use parallel dataloader if using a GPU to speed up training,\n# otherwise, as all computes are on CPU, use synchronous data loading.\nnum_workers = 4 if torch.cuda.is_available() else 0\n\nn_images_max = (\n    100 if torch.cuda.is_available() else 5\n)  # number of images used for training\n\nmeasurement_dir = DATA_DIR / train_dataset_name / operation\ndeepinv_datasets_path = dinv.datasets.generate_dataset(\n    train_dataset=train_dataset,\n    test_dataset=test_dataset,\n    physics=physics,\n    device=device,\n    save_dir=measurement_dir,\n    train_datapoints=n_images_max,\n    test_datapoints=n_images_max,\n    num_workers=num_workers,\n    dataset_filename=\"demo_sure\",\n)\n\ntrain_dataset = dinv.datasets.HDF5Dataset(path=deepinv_datasets_path, train=True)\ntest_dataset = dinv.datasets.HDF5Dataset(path=deepinv_datasets_path, train=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "language": "markdown"
      },
      "source": "## Set up the denoiser network\n\nWe use a simple U-Net architecture with 2 scales as the denoiser network.\n"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "model = dinv.models.ArtifactRemoval(\n    dinv.models.UNet(in_channels=1, out_channels=1, scales=2).to(device)\n)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "language": "markdown"
      },
      "source": "## Set up the training parameters\nWe set [`deepinv.loss.SureGaussianLoss`](https://deepinv.github.io/deepinv/api/stubs/deepinv.loss.SureGaussianLoss.html) as the training loss with the ``unsure=True`` option.\nThe optimization with respect to the noise level is done by stochastic gradient descent with momentum\ninside the loss class, so it is seamlessly integrated into the training process.\n\n<div class=\"alert alert-info\"><h4>Note</h4><p>There are (UN)SURE losses for various noise distributions. See also [`deepinv.loss.SurePGLoss`](https://deepinv.github.io/deepinv/api/stubs/deepinv.loss.SurePGLoss.html) for mixed Poisson-Gaussian noise.</p></div>\n\n<div class=\"alert alert-info\"><h4>Note</h4><p>We train for only 10 epochs to reduce the computational load of the example. We recommend to train for more epochs to get the best results.</p></div>\n\n"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "epochs = 10  # choose training epochs\nlearning_rate = 5e-4\nbatch_size = 32 if torch.cuda.is_available() else 1\n\nsigma_init = 0.05  # initial guess for the noise level\nstep_size = 1e-4  # step size for the optimization of the noise level\nmomentum = 0.9  # momentum for the optimization of the noise level\n\n# choose self-supervised training loss\nloss = dinv.loss.SureGaussianLoss(\n    sigma=sigma_init, unsure=True, step_size=step_size, momentum=momentum\n)\n\n# choose optimizer and scheduler\noptimizer = torch.optim.Adam(model.parameters(), lr=learning_rate, weight_decay=1e-8)\n\nprint(f\"INIT. noise level {loss.sigma2.sqrt().item():.3f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "language": "markdown"
      },
      "source": "## Train the network\nWe train the network using the [`deepinv.Trainer`](https://deepinv.github.io/deepinv/api/stubs/deepinv.Trainer.html) class.\n\nTo simulate a realistic self-supervised learning scenario, we do not use any supervised metrics for training,\nsuch as PSNR or SSIM, which require clean ground truth images.\n\n> **Tip**\n>\n>\n> We can use the same self-supervised loss for evaluation (without updating the noise level, which is equivalent to SURE with the estimated noise level),\n> as it does not require clean images,\n> to monitor the training process (e.g. for early stopping). This is done automatically when `metrics=None` and `early_stop>0` in the trainer.\n>\n"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "train_dataloader = DataLoader(\n    train_dataset, batch_size=batch_size, num_workers=num_workers, shuffle=True\n)\n\n# Initialize the trainer\ntrainer = dinv.Trainer(\n    model=model,\n    physics=physics,\n    epochs=epochs,\n    losses=loss,\n    compute_eval_losses=True,  # use self-supervised loss for evaluation\n    early_stop_on_losses=True,  # stop using self-supervised eval loss\n    metrics=None,  # no supervised metrics\n    early_stop=2,  # early stop using the self-supervised loss on the test set\n    optimizer=optimizer,\n    device=device,\n    train_dataloader=train_dataloader,\n    eval_dataloader=train_dataloader,\n    plot_images=False,\n    save_path=str(CKPT_DIR / operation),\n    verbose=True,  # print training information\n    show_progress_bar=False,  # disable progress bar for better vis in sphinx gallery.\n)\n\n# Train the network\nmodel = trainer.train()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "language": "markdown"
      },
      "source": "## Check learned noise level\nWe can verify the learned noise level by checking the estimated noise level from the loss function.\n\n"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "est_sigma = loss.sigma2.sqrt().item()\n\nprint(f\"LEARNED noise level {est_sigma:.3f}\")\nprint(f\"Estimation error noise level {abs(est_sigma-true_sigma):.3f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "language": "markdown"
      },
      "source": "## Test the network\n\n"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "test_dataloader = DataLoader(\n    test_dataset, batch_size=batch_size, num_workers=num_workers, shuffle=False\n)\n\ntrainer.plot_images = True\ntrainer.test(test_dataloader=test_dataloader, metrics=dinv.metric.PSNR())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "language": "markdown"
      },
      "source": ":References:\n\n> **Footbibliography**\n>\n>\n"
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}