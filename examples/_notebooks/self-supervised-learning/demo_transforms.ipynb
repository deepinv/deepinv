{
  "cells": [
    {
      "id": "c5e28240",
      "cell_type": "code",
      "metadata": {
        "language": "python"
      },
      "execution_count": null,
      "source": "# Install deepinv (skip if already installed)\n%pip install deepinv",
      "outputs": []
    },
    {
      "id": "3f9c5216",
      "cell_type": "markdown",
      "source": "<!-- MathJax macro definitions inserted automatically -->\n$$\n\\newcommand{\\forw}[1]{{A\\left({#1}\\right)}}\n\\newcommand{\\noise}[1]{{N\\left({#1}\\right)}}\n\\newcommand{\\inverse}[1]{{R\\left({#1}\\right)}}\n\\newcommand{\\inversef}[2]{{R\\left({#1},{#2}\\right)}}\n\\newcommand{\\inversename}{R}\n\\newcommand{\\reg}[1]{{g_\\sigma\\left({#1}\\right)}}\n\\newcommand{\\regname}{g_\\sigma}\n\\newcommand{\\sensor}[1]{{\\eta\\left({#1}\\right)}}\n\\newcommand{\\datafid}[2]{{f\\left({#1},{#2}\\right)}}\n\\newcommand{\\datafidname}{f}\n\\newcommand{\\distance}[2]{{d\\left({#1},{#2}\\right)}}\n\\newcommand{\\distancename}{d}\n\\newcommand{\\denoiser}[2]{{\\operatorname{D}_{{#2}}\\left({#1}\\right)}}\n\\newcommand{\\denoisername}{\\operatorname{D}_{\\sigma}}\n\\newcommand{\\xset}{\\mathcal{X}}\n\\newcommand{\\yset}{\\mathcal{Y}}\n\\newcommand{\\group}{\\mathcal{G}}\n\\newcommand{\\metric}[2]{{d\\left({#1},{#2}\\right)}}\n\\newcommand{\\loss}[1]{{\\mathcal\\left({#1}\\right)}}\n\\newcommand{\\conj}[1]{{\\overline{#1}^{\\top}}}\n$$",
      "metadata": {
        "language": "markdown"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "language": "markdown"
      },
      "source": "\n# Image transforms for equivariance & augmentations\n\nWe demonstrate the use of our ``deepinv.transform`` module for use in\nsolving imaging problems. These can be used for:\n\n1. Data augmentation (similar to ``torchvision.transforms``)\n2. Building equivariant denoisers\n   ([`deepinv.models.EquivariantDenoiser`](https://deepinv.github.io/deepinv/api/stubs/deepinv.models.EquivariantDenoiser.html)) for robust denoising\n   (e.g from :footcite:t:`terris2024equivariant`)\n3. Self-supervised learning using Equivariant Imaging from :footcite:t:`chen2021equivariant`. See\n   [`self-supervised-learning/demo_ei_transforms.py`](https://deepinv.github.io/deepinv/auto_examples/self-supervised-learning/demo_ei_transforms.html#sphx-glr-auto-examples-self-supervised-learning-demo-ei-transforms-py),\n   [`self-supervised-learning/demo_equivariant_imaging.py`](https://deepinv.github.io/deepinv/auto_examples/self-supervised-learning/demo_equivariant_imaging.html#sphx-glr-auto-examples-self-supervised-learning-demo-equivariant-imaging-py)\n   for thorough examples.\n\nSee docs for full list of implemented transforms.\n\n## 1. Data augmentation\n\nWe can use ``deepinv`` transforms in the same way as ``torchvision``\ntransforms, and chain them together for data augmentation. Our\ntransforms are customisable and offer some group-theoretic properties.\n\nWe demonstrate a random roto-scale combined with a random masking, and a\nconstrained pixel-shift with a random color jitter.\nNote that all our transforms can easily be inverted using the method ``transform.inverse()``.\n\nFirst, load a sample image."
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "import deepinv as dinv\nfrom torchvision.transforms import Compose, ColorJitter, RandomErasing, Resize\n\nx = dinv.utils.load_example(\"celeba_example.jpg\")\n\n# Random roto-scale with random masking\ntransform = Compose(\n    [\n        dinv.transform.Rotate() * dinv.transform.Scale(),\n        RandomErasing(),\n    ]\n)\n\n# Constrained pixel-shift with a random color jitter\ntransform2 = Compose(\n    [\n        dinv.transform.Shift(shift_max=0.2),\n        ColorJitter(hue=0.5),\n    ]\n)\n\n# Random diffeomorphism\ntransform3 = dinv.transform.CPABDiffeomorphism()\n\ndinv.utils.plot(\n    [x, transform(x), transform2(x), transform3(x)],\n    titles=[\"Orig\", \"Transform 1\", \"Transform 2\", \"Transform 3\"],\n)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "language": "markdown"
      },
      "source": "By letting ``n_trans`` be equal to the full group size, all transforms\nare recovered:\n\n"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "reflect = dinv.transform.Reflect(dim=[-2, -1], n_trans=4)\nrotate = dinv.transform.Rotate(multiples=90, positive=True, n_trans=4)\ndinv.utils.plot(\n    [reflect(x), rotate(x)], titles=[\"Full 2D reflect group\", \"Full rotate group\"]\n)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "language": "markdown"
      },
      "source": "## 2. Equivariant denoiser or plug-and-play\n\nSuppose we want to make a denoiser equivariant to the rotoreflect group,\ntaken as the group product of the 90 degree rotations (order 4) and 1D reflects (order 2).\nWe can do this with our transform arithmetic (note this results in the full dihedral group\n$\\text{Dih}_4$ of order 8):\n\n"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "transform = rotate * dinv.transform.Reflect(dim=[-1], n_trans=2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "language": "markdown"
      },
      "source": "Let's simulate some Gaussian noise and turn a simple (median filter)\ndenoiser into an equivariant denoiser\n([`deepinv.models.EquivariantDenoiser`](https://deepinv.github.io/deepinv/api/stubs/deepinv.models.EquivariantDenoiser.html)):\n\n"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "sigma = 0.1\nphysics = dinv.physics.Denoising(noise_model=dinv.physics.GaussianNoise(sigma=sigma))\ny = physics(Resize(128)(x))\n\nmodel = dinv.models.MedianFilter()\nmodel_eq = dinv.models.EquivariantDenoiser(model, transform=transform)\n\ndinv.utils.plot([x, y, model(y, sigma=sigma), model_eq(y, sigma=sigma)])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "language": "markdown"
      },
      "source": "What's going on under the hood? We use the ``transform.symmetrize``\nmethod to symmetrize the function $f$ with respect to a projective\ntransform (with a Monte Carlo approach of ``n_trans=2`` transforms per call):\n\n"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# Example non-equivariant function\nf = lambda x: x[..., [0]] * x\n\n# Example non-linear transform with n=2\nt = dinv.transform.projective.PanTiltRotate(n_trans=2, theta_max=10, theta_z_max=0)\n\n# Symmetrize function with respect to transform\nf_s = t.symmetrize(f, average=True)\ndinv.utils.plot(\n    [x, f(x), f_s(x)], titles=[\"Orig\", \"$f(x)$\", \"$\\\\sum_i T_i^{-1}f(T_ix)$\"]\n)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "language": "markdown"
      },
      "source": "## 3. Equivariant imaging\n\nWe can also use our transforms to create the self-supervised equivariant\nimaging loss. See\n[`self-supervised-learning/demo_ei_transforms.py`](https://deepinv.github.io/deepinv/auto_examples/self-supervised-learning/demo_ei_transforms.html#sphx-glr-auto-examples-self-supervised-learning-demo-ei-transforms-py),\n[`self-supervised-learning/demo_equivariant_imaging.py`](https://deepinv.github.io/deepinv/auto_examples/self-supervised-learning/demo_equivariant_imaging.html#sphx-glr-auto-examples-self-supervised-learning-demo-equivariant-imaging-py)\nfor examples of self-supervised learning for MRI and inpainting. For\nexample, the EI loss can easily be defined using any combination of\ntransforms:\n\n"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "loss = dinv.loss.EILoss(\n    transform=dinv.transform.projective.Affine() | dinv.transform.projective.Euclidean()\n)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "language": "markdown"
      },
      "source": ":References:\n\n> **Footbibliography**\n>\n>\n"
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}