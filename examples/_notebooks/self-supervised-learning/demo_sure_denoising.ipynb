{
  "cells": [
    {
      "id": "064e744e",
      "cell_type": "code",
      "metadata": {
        "language": "python"
      },
      "execution_count": null,
      "source": "# Install deepinv (skip if already installed)\n%pip install deepinv",
      "outputs": []
    },
    {
      "id": "efcbd2f4",
      "cell_type": "markdown",
      "source": "<!-- MathJax macro definitions inserted automatically -->\n$$\n\\newcommand{\\forw}[1]{{A\\left({#1}\\right)}}\n\\newcommand{\\noise}[1]{{N\\left({#1}\\right)}}\n\\newcommand{\\inverse}[1]{{R\\left({#1}\\right)}}\n\\newcommand{\\inversef}[2]{{R\\left({#1},{#2}\\right)}}\n\\newcommand{\\inversename}{R}\n\\newcommand{\\reg}[1]{{g_\\sigma\\left({#1}\\right)}}\n\\newcommand{\\regname}{g_\\sigma}\n\\newcommand{\\sensor}[1]{{\\eta\\left({#1}\\right)}}\n\\newcommand{\\datafid}[2]{{f\\left({#1},{#2}\\right)}}\n\\newcommand{\\datafidname}{f}\n\\newcommand{\\distance}[2]{{d\\left({#1},{#2}\\right)}}\n\\newcommand{\\distancename}{d}\n\\newcommand{\\denoiser}[2]{{\\operatorname{D}_{{#2}}\\left({#1}\\right)}}\n\\newcommand{\\denoisername}{\\operatorname{D}_{\\sigma}}\n\\newcommand{\\xset}{\\mathcal{X}}\n\\newcommand{\\yset}{\\mathcal{Y}}\n\\newcommand{\\group}{\\mathcal{G}}\n\\newcommand{\\metric}[2]{{d\\left({#1},{#2}\\right)}}\n\\newcommand{\\loss}[1]{{\\mathcal\\left({#1}\\right)}}\n\\newcommand{\\conj}[1]{{\\overline{#1}^{\\top}}}\n$$",
      "metadata": {
        "language": "markdown"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "language": "markdown"
      },
      "source": "\n# Self-supervised denoising with the SURE loss.\n\nThis example shows you how to train a denoiser network in a fully self-supervised way,\ni.e., using noisy images only via the SURE loss, which exploits knowledge about the noise distribution.\n\nThe SURE loss for Poisson denoising acts as an unbiased estimator of the supervised loss and is computed as:\n\n\n\\begin{align}\\frac{1}{m}\\|y-\\inverse{y}\\|_2^2-\\frac{\\gamma}{m} 1^{\\top}y\n    +\\frac{2\\gamma}{m\\tau}(b\\odot y)^{\\top} \\left(\\inverse{y+\\tau b}-\\inverse{y}\\right)\\end{align}\n\nwhere $R$ is the trainable network, $y$ is the noisy image with $m$ pixels,\n$b$ is a Bernoulli random variable taking values of -1 and 1 each with a probability of 0.5,\n$\\tau$ is a small positive number, and $\\odot$ is an elementwise multiplication."
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "from pathlib import Path\n\nimport torch\nfrom torch.utils.data import DataLoader\nfrom torchvision import transforms, datasets\n\nimport deepinv as dinv\nfrom deepinv.utils import get_data_home\nfrom deepinv.models.utils import get_weights_url"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "language": "markdown"
      },
      "source": "## Setup paths for data loading and results.\n\n"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "BASE_DIR = Path(\".\")\nDATA_DIR = BASE_DIR / \"measurements\"\nCKPT_DIR = BASE_DIR / \"ckpts\"\nORIGINAL_DATA_DIR = get_data_home()\n\n# Set the global random seed from pytorch to ensure reproducibility of the example.\ntorch.manual_seed(0)\n\ndevice = dinv.utils.get_freer_gpu() if torch.cuda.is_available() else \"cpu\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "language": "markdown"
      },
      "source": "## Load base image datasets\nIn this example, we use the MNIST dataset as the base image dataset.\n\n"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "operation = \"denoising\"\ntrain_dataset_name = \"MNIST\"\n\ntransform = transforms.Compose([transforms.ToTensor()])\n\ntrain_dataset = datasets.MNIST(\n    root=ORIGINAL_DATA_DIR, train=True, transform=transform, download=True\n)\ntest_dataset = datasets.MNIST(\n    root=ORIGINAL_DATA_DIR, train=False, transform=transform, download=True\n)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "language": "markdown"
      },
      "source": "## Generate a dataset of noisy images\n\nWe generate a dataset of noisy images corrupted by Poisson noise.\n\n<div class=\"alert alert-info\"><h4>Note</h4><p>We use a subset of the whole training set to reduce the computational load of the example.\n      We recommend to use the whole set by setting ``n_images_max=None`` to get the best results.</p></div>\n"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# defined physics\nphysics = dinv.physics.Denoising(dinv.physics.PoissonNoise(0.1))\n\n# Use parallel dataloader if using a GPU to speed up training,\n# otherwise, as all computes are on CPU, use synchronous data loading.\nnum_workers = 4 if torch.cuda.is_available() else 0\n\nn_images_max = (\n    100 if torch.cuda.is_available() else 5\n)  # number of images used for training\n\nmeasurement_dir = DATA_DIR / train_dataset_name / operation\ndeepinv_datasets_path = dinv.datasets.generate_dataset(\n    train_dataset=train_dataset,\n    test_dataset=test_dataset,\n    physics=physics,\n    device=device,\n    save_dir=measurement_dir,\n    train_datapoints=n_images_max,\n    test_datapoints=n_images_max,\n    num_workers=num_workers,\n    dataset_filename=\"demo_sure\",\n)\n\ntrain_dataset = dinv.datasets.HDF5Dataset(path=deepinv_datasets_path, train=True)\ntest_dataset = dinv.datasets.HDF5Dataset(path=deepinv_datasets_path, train=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "language": "markdown"
      },
      "source": "## Set up the denoiser network\n\nWe use a simple U-Net architecture with 2 scales as the denoiser network.\n"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "model = dinv.models.ArtifactRemoval(\n    dinv.models.UNet(in_channels=1, out_channels=1, scales=2).to(device)\n)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "language": "markdown"
      },
      "source": "## Set up the training parameters\nWe set [`deepinv.loss.SurePoissonLoss`](https://deepinv.github.io/deepinv/api/stubs/deepinv.loss.SurePoissonLoss.html) as the training loss.\n\n<div class=\"alert alert-info\"><h4>Note</h4><p>There are SURE losses for various noise distributions. See also [`deepinv.loss.SureGaussianLoss`](https://deepinv.github.io/deepinv/api/stubs/deepinv.loss.SureGaussianLoss.html)\n      for Gaussian noise and [`deepinv.loss.SurePGLoss`](https://deepinv.github.io/deepinv/api/stubs/deepinv.loss.SurePGLoss.html) for mixed Poisson-Gaussian noise.</p></div>\n\n<div class=\"alert alert-info\"><h4>Note</h4><p>We use a pretrained model to reduce training time. You can get the same results by training from scratch\n      for 10 epochs.</p></div>\n"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "epochs = 1  # choose training epochs\nlearning_rate = 5e-4\nbatch_size = 32 if torch.cuda.is_available() else 1\n\n# choose self-supervised training loss\nloss = dinv.loss.SurePoissonLoss(gain=0.1)\n\n# choose optimizer and scheduler\noptimizer = torch.optim.Adam(model.parameters(), lr=learning_rate, weight_decay=1e-8)\nscheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=int(epochs * 0.8) + 1)\n\n# start with a pretrained model to reduce training time\nfile_name = \"ckp_10_demo_sure.pth\"\nurl = get_weights_url(model_name=\"demo\", file_name=file_name)\nckpt = torch.hub.load_state_dict_from_url(\n    url, map_location=lambda storage, loc: storage, file_name=file_name\n)\n# load a checkpoint to reduce training time\nmodel.load_state_dict(ckpt[\"state_dict\"])\noptimizer.load_state_dict(ckpt[\"optimizer\"])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "language": "markdown"
      },
      "source": "## Train the network\n\nTo simulate a realistic self-supervised learning scenario, we do not use any supervised metrics for training,\nsuch as PSNR or SSIM, which require clean ground truth images.\n\n> **Tip**\n>\n>\n> We can use the same self-supervised loss for evaluation, as it does not require clean images,\n> to monitor the training process (e.g. for early stopping). This is done automatically when `metrics=None` and `early_stop>0` in the trainer.\n>\n"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "verbose = True  # print training information\n\ntrain_dataloader = DataLoader(\n    train_dataset, batch_size=batch_size, num_workers=num_workers, shuffle=True\n)\ntest_dataloader = DataLoader(\n    test_dataset, batch_size=batch_size, num_workers=num_workers, shuffle=False\n)\n\n# Initialize the trainer\ntrainer = dinv.Trainer(\n    model=model,\n    physics=physics,\n    epochs=epochs,\n    scheduler=scheduler,\n    losses=loss,\n    optimizer=optimizer,\n    device=device,\n    train_dataloader=train_dataloader,\n    eval_dataloader=test_dataloader,\n    compute_eval_losses=True,  # use self-supervised loss for evaluation\n    early_stop_on_losses=True,  # stop using self-supervised eval loss\n    metrics=None,  # no supervised metrics\n    early_stop=2,  # early stop using the self-supervised loss on the test set\n    plot_images=True,\n    save_path=str(CKPT_DIR / operation),\n    verbose=verbose,\n    show_progress_bar=False,  # disable progress bar for better vis in sphinx gallery.\n)\n\n# Train the network\nmodel = trainer.train()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "language": "markdown"
      },
      "source": "## Test the network\nWe now assume that we have access to a small test set of clean images to evaluate the performance of the trained network.\nand we compute the PSNR between the denoised images and the clean ground truth images.\n\n"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "trainer.test(test_dataloader, metrics=dinv.metric.PSNR())"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}