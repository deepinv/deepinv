{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43bb1fb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "r\"\"\"\n",
    "Self-supervised learning from incomplete measurements of multiple operators.\n",
    "====================================================================================================\n",
    "\n",
    "This example shows you how to train a reconstruction network for an inpainting\n",
    "inverse problem on a fully self-supervised way, i.e., using measurement data only.\n",
    "\n",
    "The dataset consists of pairs :math:`(y_i,A_{g_i})` where :math:`y_i` are the measurements and :math:`A_{g_i}` is a\n",
    "binary sampling operator out of :math:`G` (i.e., :math:`g_i\\in \\{1,\\dots,G\\}`).\n",
    "\n",
    "This self-supervised learning approach is presented in :footcite:t:`tachella2022unsupervised` and minimizes the loss function:\n",
    "\n",
    ".. math::\n",
    "\n",
    "    \\mathcal{L}(\\theta) = \\sum_{i=1}^{N} \\left\\|A_{g_i} \\hat{x}_{i,\\theta} - y_i \\right\\|_2^2 + \\sum_{s=1}^{G}\n",
    "    \\left\\|\\hat{x}_{i,\\theta} - R_{\\theta}(A_s\\hat{x}_{i,\\theta},A_s) \\right\\|_2^2\n",
    "\n",
    "where :math:`R_{\\theta}` is a reconstruction network with parameters :math:`\\theta`, :math:`y_i` are the measurements,\n",
    ":math:`A_s` is a binary sampling operator, and :math:`\\hat{x}_{i,\\theta} = R_{\\theta}(y_i,A_{g_i})`.\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "from pathlib import Path\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "import deepinv as dinv\n",
    "from deepinv.utils import get_data_home\n",
    "from deepinv.models.utils import get_weights_url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66dc4206",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup paths for data loading and results.\n",
    "# ---------------------------------------------------------------\n",
    "#\n",
    "\n",
    "BASE_DIR = Path(\".\")\n",
    "DATA_DIR = BASE_DIR / \"measurements\"\n",
    "CKPT_DIR = BASE_DIR / \"ckpts\"\n",
    "ORIGINAL_DATA_DIR = get_data_home()\n",
    "\n",
    "# Set the global random seed from pytorch to ensure reproducibility of the example.\n",
    "torch.manual_seed(0)\n",
    "\n",
    "device = dinv.utils.get_freer_gpu() if torch.cuda.is_available() else \"cpu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "037267aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load base image datasets and degradation operators.\n",
    "# ----------------------------------------------------------------------------------\n",
    "# In this example, we use the MNIST dataset for training and testing.\n",
    "#\n",
    "\n",
    "transform = transforms.Compose([transforms.ToTensor()])\n",
    "\n",
    "train_base_dataset = datasets.MNIST(\n",
    "    root=ORIGINAL_DATA_DIR, train=True, transform=transform, download=True\n",
    ")\n",
    "test_base_dataset = datasets.MNIST(\n",
    "    root=ORIGINAL_DATA_DIR, train=False, transform=transform, download=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4474336d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate a dataset of subsampled images and load it.\n",
    "# ----------------------------------------------------------------------------------\n",
    "# We generate 10 different inpainting operators, each one with a different random mask.\n",
    "# If the :func:`deepinv.datasets.generate_dataset` receives a list of physics operators, it\n",
    "# generates a dataset for each operator and returns a list of paths to the generated datasets.\n",
    "#\n",
    "# .. note::\n",
    "#\n",
    "#   We only use 10 training images per operator to reduce the computational time of this example. You can use the whole\n",
    "#   dataset by setting ``n_images_max = None``.\n",
    "\n",
    "number_of_operators = 10\n",
    "\n",
    "# defined physics\n",
    "physics = [\n",
    "    dinv.physics.Inpainting(mask=0.5, img_size=(1, 28, 28), device=device)\n",
    "    for _ in range(number_of_operators)\n",
    "]\n",
    "\n",
    "# Use parallel dataloader if using a GPU to reduce training time,\n",
    "# otherwise, as all computes are on CPU, use synchronous data loading.\n",
    "num_workers = 4 if torch.cuda.is_available() else 0\n",
    "n_images_max = (\n",
    "    None if torch.cuda.is_available() else 50\n",
    ")  # number of images used for training (uses the whole dataset if you have a gpu)\n",
    "\n",
    "operation = \"inpainting\"\n",
    "my_dataset_name = \"demo_multioperator_imaging\"\n",
    "measurement_dir = DATA_DIR / \"MNIST\" / operation\n",
    "deepinv_datasets_path = dinv.datasets.generate_dataset(\n",
    "    train_dataset=train_base_dataset,\n",
    "    test_dataset=test_base_dataset,\n",
    "    physics=physics,\n",
    "    device=device,\n",
    "    save_dir=measurement_dir,\n",
    "    train_datapoints=n_images_max,\n",
    "    test_datapoints=10,\n",
    "    num_workers=num_workers,\n",
    "    dataset_filename=str(my_dataset_name),\n",
    ")\n",
    "\n",
    "train_dataset = [\n",
    "    dinv.datasets.HDF5Dataset(path=path, train=True) for path in deepinv_datasets_path\n",
    "]\n",
    "test_dataset = [\n",
    "    dinv.datasets.HDF5Dataset(path=path, train=False) for path in deepinv_datasets_path\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6935ef6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up the reconstruction network\n",
    "# ---------------------------------------------------------------\n",
    "#\n",
    "# As a reconstruction network, we use a simple artifact removal network based on a U-Net.\n",
    "# The network is defined as a :math:`R_{\\theta}(y,A)=\\phi_{\\theta}(A^{\\top}y)` where :math:`\\phi` is the U-Net.\n",
    "\n",
    "# Define the unfolded trainable model.\n",
    "model = dinv.models.ArtifactRemoval(\n",
    "    backbone_net=dinv.models.UNet(in_channels=1, out_channels=1, scales=3)\n",
    ")\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e39411d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up the training parameters\n",
    "# --------------------------------------------\n",
    "# We choose a self-supervised training scheme with two losses: the measurement consistency loss (MC)\n",
    "# and the multi-operator imaging loss (MOI).\n",
    "# Necessary and sufficient conditions on the number of operators and measurements are described in :footcite:t:`tachella2023sensing`.\n",
    "#\n",
    "# .. note::\n",
    "#\n",
    "#       We use a pretrained model to reduce training time. You can get the same results by training from scratch\n",
    "#       for 100 epochs.\n",
    "\n",
    "epochs = 1\n",
    "learning_rate = 5e-4\n",
    "batch_size = 64 if torch.cuda.is_available() else 1\n",
    "\n",
    "# choose self-supervised training losses\n",
    "# generates 4 random rotations per image in the batch\n",
    "losses = [dinv.loss.MCLoss(), dinv.loss.MOILoss(physics)]\n",
    "\n",
    "# choose optimizer and scheduler\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate, weight_decay=1e-8)\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=int(epochs * 0.8) + 1)\n",
    "\n",
    "# start with a pretrained model to reduce training time\n",
    "file_name = \"demo_moi_ckp_10.pth\"\n",
    "url = get_weights_url(model_name=\"demo\", file_name=file_name)\n",
    "ckpt = torch.hub.load_state_dict_from_url(\n",
    "    url, map_location=lambda storage, loc: storage, file_name=file_name\n",
    ")\n",
    "# load a checkpoint to reduce training time\n",
    "model.load_state_dict(ckpt[\"state_dict\"])\n",
    "optimizer.load_state_dict(ckpt[\"optimizer\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ee58e88",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the network\n",
    "# --------------------------------------------\n",
    "# To simulate a realistic self-supervised learning scenario, we do not use any supervised metrics for training,\n",
    "# such as PSNR or SSIM, which require clean ground truth images.\n",
    "#\n",
    "# .. tip::\n",
    "#\n",
    "#       We can use the same self-supervised loss for evaluation, as it does not require clean images,\n",
    "#       to monitor the training process (e.g. for early stopping). This is done automatically when `metrics=None` and `early_stop>0` in the trainer.\n",
    "\n",
    "\n",
    "verbose = True  # print training information\n",
    "\n",
    "train_dataloader = [\n",
    "    DataLoader(dataset, batch_size=batch_size, num_workers=num_workers, shuffle=True)\n",
    "    for dataset in train_dataset\n",
    "]\n",
    "test_dataloader = [\n",
    "    DataLoader(dataset, batch_size=batch_size, num_workers=num_workers, shuffle=False)\n",
    "    for dataset in test_dataset\n",
    "]\n",
    "\n",
    "# Initialize the trainer\n",
    "trainer = dinv.Trainer(\n",
    "    model=model,\n",
    "    epochs=epochs,\n",
    "    scheduler=scheduler,\n",
    "    losses=losses,\n",
    "    optimizer=optimizer,\n",
    "    physics=physics,\n",
    "    device=device,\n",
    "    train_dataloader=train_dataloader,\n",
    "    eval_dataloader=test_dataloader,\n",
    "    metrics=None,  # no supervised metrics\n",
    "    early_stop=2,  # early stop using the self-supervised loss on the test set\n",
    "    save_path=str(CKPT_DIR / operation),\n",
    "    compute_eval_losses=True,  # use self-supervised loss for evaluation\n",
    "    early_stop_on_losses=True,  # stop using self-supervised eval loss\n",
    "    verbose=verbose,\n",
    "    plot_images=True,\n",
    "    show_progress_bar=False,  # disable progress bar for better vis in sphinx gallery.\n",
    "    ckp_interval=10,\n",
    ")\n",
    "\n",
    "# Train the network\n",
    "model = trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe2d636d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test the network\n",
    "# --------------------------------------------\n",
    "# We now assume that we have access to a small test set of ground-truth images to evaluate the performance of the trained network.\n",
    "# and we compute the PSNR between the denoised images and the clean ground truth images.\n",
    "#\n",
    "\n",
    "trainer.test(test_dataloader, metrics=dinv.metric.PSNR())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c03d359f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# :References:\n",
    "#\n",
    "# .. footbibliography::"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
