{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c79cd74",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "r\"\"\"\n",
    "Self-supervised learning with measurement splitting\n",
    "===================================================\n",
    "\n",
    "We demonstrate self-supervised learning with measurement splitting, to\n",
    "train a denoiser network on the MNIST dataset. The physics here is noisy\n",
    "computed tomography, as is the case in Noise2Inverse :footcite:t:`hendriksen2020noise2inverse`. Note this example\n",
    "can also be easily applied to undersampled multicoil MRI as is the case\n",
    "in SSDU :footcite:t:`yaman2020self`.\n",
    "\n",
    "Measurement splitting constructs a ground-truth free loss\n",
    ":math:`\\frac{m}{m_2}\\| y_2 - A_2 \\inversef{y_1}{A_1}\\|^2` by splitting\n",
    "the measurement and the forward operator using a randomly generated\n",
    "mask.\n",
    "\n",
    "See :class:`deepinv.loss.SplittingLoss` for full details.\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "from pathlib import Path\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import transforms, datasets\n",
    "\n",
    "import deepinv as dinv\n",
    "from deepinv.utils import get_data_home\n",
    "from deepinv.models.utils import get_weights_url\n",
    "\n",
    "torch.manual_seed(0)\n",
    "device = dinv.utils.get_freer_gpu() if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "BASE_DIR = Path(\".\")\n",
    "DATA_DIR = BASE_DIR / \"measurements\"\n",
    "ORIGINAL_DATA_HOME = get_data_home()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7c2fbfa",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "# Define loss\n",
    "# ~~~~~~~~~~~\n",
    "#\n",
    "# Our implementation has multiple optional parameters that control how the\n",
    "# splitting is to be achieved. For example, you can:\n",
    "#\n",
    "# -  Use ``split_ratio`` to set the ratio of pixels used in the forward\n",
    "#    pass vs the loss;\n",
    "# -  Define custom masking methods using a ``mask_generator`` such as\n",
    "#    :class:`deepinv.physics.generator.BernoulliSplittingMaskGenerator`\n",
    "#    or :class:`deepinv.physics.generator.GaussianSplittingMaskGenerator`;\n",
    "# -  Use ``eval_n_samples`` to set how many realisations of the random\n",
    "#    mask is used at evaluation time;\n",
    "# -  Optionally disable measurement splitting at evaluation time using\n",
    "#    ``eval_split_input`` (as is the case in SSDU :footcite:t:`yaman2020self`).\n",
    "# -  Average over both input and output masks at evaluation time using\n",
    "#    ``eval_split_output``. See :class:`deepinv.loss.SplittingLoss` for\n",
    "#    details.\n",
    "#\n",
    "# Note that after the model has been defined, the loss must also \"adapt\"\n",
    "# the model.\n",
    "#\n",
    "\n",
    "loss = dinv.loss.SplittingLoss(split_ratio=0.6, eval_split_input=True, eval_n_samples=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3956729",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "# Prepare data\n",
    "# ~~~~~~~~~~~~\n",
    "#\n",
    "# We use the ``torchvision`` MNIST dataset, and use noisy tomography\n",
    "# physics (with number of angles equal to the image size) for the forward\n",
    "# operator.\n",
    "#\n",
    "# .. note::\n",
    "#\n",
    "#      We use a subset of the whole training set to reduce the computational load of the example.\n",
    "#      We recommend to use the whole set by setting ``train_datapoints=test_datapoints=None`` to get the best results.\n",
    "#\n",
    "\n",
    "transform = transforms.Compose([transforms.ToTensor()])\n",
    "\n",
    "train_dataset = datasets.MNIST(\n",
    "    root=ORIGINAL_DATA_HOME, train=True, transform=transform, download=True\n",
    ")\n",
    "test_dataset = datasets.MNIST(\n",
    "    root=ORIGINAL_DATA_HOME, train=False, transform=transform, download=True\n",
    ")\n",
    "\n",
    "physics = dinv.physics.Tomography(\n",
    "    angles=28,\n",
    "    img_width=28,\n",
    "    noise_model=dinv.physics.noise.GaussianNoise(0.1),\n",
    "    device=device,\n",
    ")\n",
    "\n",
    "deepinv_datasets_path = dinv.datasets.generate_dataset(\n",
    "    train_dataset=train_dataset,\n",
    "    test_dataset=test_dataset,\n",
    "    physics=physics,\n",
    "    device=device,\n",
    "    save_dir=DATA_DIR,\n",
    "    train_datapoints=100,\n",
    "    test_datapoints=10,\n",
    ")\n",
    "\n",
    "train_dataset = dinv.datasets.HDF5Dataset(path=deepinv_datasets_path, train=True)\n",
    "test_dataset = dinv.datasets.HDF5Dataset(path=deepinv_datasets_path, train=False)\n",
    "\n",
    "train_dataloader = DataLoader(train_dataset, shuffle=True)\n",
    "test_dataloader = DataLoader(test_dataset, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85bee407",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "# Define model\n",
    "# ~~~~~~~~~~~~\n",
    "#\n",
    "# We use a simple U-Net architecture with 2 scales as the denoiser\n",
    "# network.\n",
    "#\n",
    "# To reduce training time, we use a pretrained model. Here we demonstrate\n",
    "# training with 100 images for 1 epoch, after having loaded a pretrained\n",
    "# model trained that was with 1000 images for 20 epochs.\n",
    "#\n",
    "# .. note::\n",
    "#\n",
    "#      When using the splitting loss, the model must be \"adapted\" by the loss, as its forward pass takes only a subset of the pixels, not the full image.\n",
    "#\n",
    "\n",
    "model = dinv.models.ArtifactRemoval(\n",
    "    dinv.models.UNet(in_channels=1, out_channels=1, scales=2).to(device), pinv=True\n",
    ")\n",
    "model = loss.adapt_model(model)\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3, weight_decay=1e-8)\n",
    "\n",
    "# Load pretrained model\n",
    "file_name = \"demo_measplit_mnist_tomography.pth\"\n",
    "url = get_weights_url(model_name=\"measplit\", file_name=file_name)\n",
    "ckpt = torch.hub.load_state_dict_from_url(\n",
    "    url, map_location=lambda storage, loc: storage, file_name=file_name\n",
    ")\n",
    "\n",
    "model.load_state_dict(ckpt[\"state_dict\"])\n",
    "optimizer.load_state_dict(ckpt[\"optimizer\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4eff816",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "# Train and test network\n",
    "# ----------------------\n",
    "# To simulate a realistic self-supervised learning scenario, we do not use any supervised metrics for training,\n",
    "# such as PSNR or SSIM, which require clean ground truth images.\n",
    "#\n",
    "# .. tip::\n",
    "#\n",
    "#       We can use the same self-supervised loss for evaluation, as it does not require clean images,\n",
    "#       to monitor the training process (e.g. for early stopping). This is done automatically when `metrics=None` and `early_stop>0` in the trainer.\n",
    "\n",
    "trainer = dinv.Trainer(\n",
    "    model=model,\n",
    "    physics=physics,\n",
    "    epochs=1,\n",
    "    losses=loss,\n",
    "    optimizer=optimizer,\n",
    "    device=device,\n",
    "    train_dataloader=train_dataloader,\n",
    "    eval_dataloader=test_dataloader,\n",
    "    metrics=None,  # no supervised metrics\n",
    "    early_stop=2,  # we can use early stopping as we have a validation loss\n",
    "    compute_eval_losses=True,  # use self-supervised loss for evaluation\n",
    "    early_stop_on_losses=True,  # stop using self-supervised eval loss\n",
    "    plot_images=False,\n",
    "    save_path=None,\n",
    "    verbose=True,\n",
    "    show_progress_bar=False,\n",
    "    no_learning_method=\"A_dagger\",  # use pseudo-inverse as no-learning baseline\n",
    ")\n",
    "\n",
    "model = trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85453ce9",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "# Test and visualize the model outputs using a small test set. We set the\n",
    "# output to average over 5 iterations of random mask realisations. The\n",
    "# trained model improves on the no-learning reconstruction by ~7dB.\n",
    "#\n",
    "\n",
    "trainer.plot_images = True\n",
    "trainer.test(test_dataloader, metrics=dinv.metric.PSNR())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "add3bbcc",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "# Demonstrate the effect of not averaging over multiple realisations of\n",
    "# the splitting mask at evaluation time, by setting ``eval_n_samples=1``.\n",
    "# We have a worse performance:\n",
    "#\n",
    "\n",
    "model.eval_n_samples = 1\n",
    "trainer.test(test_dataloader, metrics=dinv.metric.PSNR())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "508f4708",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Furthermore, we can disable measurement splitting at evaluation\n",
    "# altogether by setting ``eval_split_input`` to False (this is done in\n",
    "# SSDU :footcite:t:`yaman2020self`). This generally is\n",
    "# worse than MC averaging:\n",
    "#\n",
    "\n",
    "model.eval_split_input = False\n",
    "trainer.test(test_dataloader, metrics=dinv.metric.PSNR())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ae8b900",
   "metadata": {},
   "outputs": [],
   "source": [
    "# :References:\n",
    "#\n",
    "# .. footbibliography::"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
