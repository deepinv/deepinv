{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82115530",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "r\"\"\"\n",
    "Deep Equilibrium (DEQ) algorithms for image deblurring\n",
    "====================================================================================================\n",
    "\n",
    "This a toy example to show you how to use DEQ to solve a deblurring problem.\n",
    "Note that this is a small dataset for training. For optimal results, use a larger dataset.\n",
    "\n",
    "For now DEQ is only possible with PGD, HQS and GD optimization algorithms.\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "import deepinv as dinv\n",
    "from pathlib import Path\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from deepinv.optim.data_fidelity import L2\n",
    "from deepinv.optim.prior import PnP\n",
    "from deepinv.unfolded import DEQ_builder\n",
    "from torchvision import transforms\n",
    "from deepinv.utils import load_dataset, load_degradation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f0b9865",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup paths for data loading and results.\n",
    "# ----------------------------------------------------------------------------------------\n",
    "#\n",
    "\n",
    "BASE_DIR = Path(\".\")\n",
    "DATA_DIR = BASE_DIR / \"measurements\"\n",
    "RESULTS_DIR = BASE_DIR / \"results\"\n",
    "CKPT_DIR = BASE_DIR / \"ckpts\"\n",
    "DEG_DIR = BASE_DIR / \"degradations\"\n",
    "\n",
    "# Set the global random seed from pytorch to ensure reproducibility of the example.\n",
    "torch.manual_seed(0)\n",
    "\n",
    "device = dinv.utils.get_freer_gpu() if torch.cuda.is_available() else \"cpu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc82f270",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "# Load base image datasets and degradation operators.\n",
    "# ----------------------------------------------------------------------------------------\n",
    "# In this example, we use the CBSD500 dataset and the Set3C dataset for testing.\n",
    "\n",
    "img_size = 32\n",
    "n_channels = 3  # 3 for color images, 1 for gray-scale images\n",
    "operation = \"deblurring\"\n",
    "# For simplicity, we use a small dataset for training.\n",
    "# To be replaced for optimal results. For example, you can use the larger \"drunet\" dataset.\n",
    "train_dataset_name = \"CBSD500\"\n",
    "test_dataset_name = \"set3c\"\n",
    "# Generate training and evaluation datasets in HDF5 folders and load them.\n",
    "test_transform = transforms.Compose(\n",
    "    [transforms.CenterCrop(img_size), transforms.ToTensor()]\n",
    ")\n",
    "train_transform = transforms.Compose(\n",
    "    [transforms.RandomCrop(img_size), transforms.ToTensor()]\n",
    ")\n",
    "train_base_dataset = load_dataset(train_dataset_name, transform=train_transform)\n",
    "test_base_dataset = load_dataset(test_dataset_name, transform=test_transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3661cfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate a dataset of low resolution images and load it.\n",
    "# ----------------------------------------------------------------------------------------\n",
    "# We use the Downsampling class from the physics module to generate a dataset of low resolution images.\n",
    "\n",
    "\n",
    "# Use parallel dataloader if using a GPU to speed up training, otherwise, as all computes are on CPU, use synchronous\n",
    "# dataloading.\n",
    "num_workers = 4 if torch.cuda.is_available() else 0\n",
    "\n",
    "# Degradation parameters\n",
    "noise_level_img = 0.03\n",
    "\n",
    "# Generate a motion blur operator.\n",
    "kernel_index = 1  # which kernel to chose among the 8 motion kernels from 'Levin09.mat'\n",
    "kernel_torch = load_degradation(\"Levin09.npy\", DEG_DIR / \"kernels\", index=kernel_index)\n",
    "kernel_torch = kernel_torch.unsqueeze(0).unsqueeze(\n",
    "    0\n",
    ")  # add batch and channel dimensions\n",
    "\n",
    "# Generate the gaussian blur downsampling operator.\n",
    "physics = dinv.physics.BlurFFT(\n",
    "    img_size=(n_channels, img_size, img_size),\n",
    "    filter=kernel_torch,\n",
    "    device=device,\n",
    "    noise_model=dinv.physics.GaussianNoise(sigma=noise_level_img),\n",
    ")\n",
    "\n",
    "my_dataset_name = \"demo_DEQ\"\n",
    "n_images_max = (\n",
    "    1000 if torch.cuda.is_available() else 10\n",
    ")  # maximal number of images used for training\n",
    "measurement_dir = DATA_DIR / train_dataset_name / operation\n",
    "generated_datasets_path = dinv.datasets.generate_dataset(\n",
    "    train_dataset=train_base_dataset,\n",
    "    test_dataset=test_base_dataset,\n",
    "    physics=physics,\n",
    "    device=device,\n",
    "    save_dir=measurement_dir,\n",
    "    train_datapoints=n_images_max,\n",
    "    num_workers=num_workers,\n",
    "    dataset_filename=str(my_dataset_name),\n",
    ")\n",
    "\n",
    "train_dataset = dinv.datasets.HDF5Dataset(path=generated_datasets_path, train=True)\n",
    "test_dataset = dinv.datasets.HDF5Dataset(path=generated_datasets_path, train=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "250e2d48",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the  DEQ algorithm.\n",
    "# ----------------------------------------------------------------------------------------\n",
    "# We use the helper function :func:`deepinv.unfolded.DEQ_builder` to defined the DEQ architecture.\n",
    "# The chosen algorithm is here HQS (Half Quadratic Splitting).\n",
    "# Note for DEQ, the prior and regularization parameters should be common for all iterations\n",
    "# to keep a constant fixed-point operator.\n",
    "\n",
    "\n",
    "# Select the data fidelity term\n",
    "data_fidelity = L2()\n",
    "\n",
    "# Set up the trainable denoising prior. Here the prior model is common for all iterations. We use here a pretrained denoiser.\n",
    "prior = PnP(denoiser=dinv.models.DnCNN(depth=20, pretrained=\"download\").to(device))\n",
    "\n",
    "# Unrolled optimization algorithm parameters\n",
    "max_iter = 20 if torch.cuda.is_available() else 10\n",
    "stepsize = [1.0]  # stepsize of the algorithm\n",
    "sigma_denoiser = [0.03]  # noise level parameter of the denoiser\n",
    "jacobian_free = False  # does not perform Jacobian inversion.\n",
    "\n",
    "params_algo = {  # wrap all the restoration parameters in a 'params_algo' dictionary\n",
    "    \"stepsize\": stepsize,\n",
    "    \"g_param\": sigma_denoiser,\n",
    "}\n",
    "trainable_params = [\n",
    "    \"stepsize\",\n",
    "    \"g_param\",\n",
    "]  # define which parameters from 'params_algo' are trainable\n",
    "\n",
    "# Define the unfolded trainable model.\n",
    "model = DEQ_builder(\n",
    "    iteration=\"PGD\",  # For now DEQ is only possible with PGD, HQS and GD optimization algorithms.\n",
    "    params_algo=params_algo.copy(),\n",
    "    trainable_params=trainable_params,\n",
    "    data_fidelity=data_fidelity,\n",
    "    max_iter=max_iter,\n",
    "    prior=prior,\n",
    "    anderson_acceleration=True,\n",
    "    anderson_acceleration_backward=True,\n",
    "    history_size_backward=3,\n",
    "    history_size=3,\n",
    "    max_iter_backward=20,\n",
    "    jacobian_free=jacobian_free,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ca5d606",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the training parameters.\n",
    "# -------------------------------\n",
    "# We use the Adam optimizer and the StepLR scheduler.\n",
    "\n",
    "\n",
    "# training parameters\n",
    "epochs = 10 if torch.cuda.is_available() else 2\n",
    "learning_rate = 1e-4\n",
    "train_batch_size = 32 if torch.cuda.is_available() else 1\n",
    "test_batch_size = 3\n",
    "\n",
    "\n",
    "# choose optimizer and scheduler\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate, weight_decay=1e-8)\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=int(epochs * 0.8))\n",
    "\n",
    "# choose supervised training loss\n",
    "losses = [dinv.loss.SupLoss(metric=dinv.metric.MSE())]\n",
    "\n",
    "# Logging parameters\n",
    "verbose = True\n",
    "\n",
    "train_dataloader = DataLoader(\n",
    "    train_dataset, batch_size=train_batch_size, num_workers=num_workers, shuffle=True\n",
    ")\n",
    "test_dataloader = DataLoader(\n",
    "    test_dataset, batch_size=test_batch_size, num_workers=num_workers, shuffle=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f79f71eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the network\n",
    "# -----------------\n",
    "# We train the network using the library's train function.\n",
    "\n",
    "trainer = dinv.Trainer(\n",
    "    model=model,\n",
    "    physics=physics,\n",
    "    epochs=epochs,\n",
    "    scheduler=scheduler,\n",
    "    device=device,\n",
    "    losses=losses,\n",
    "    optimizer=optimizer,\n",
    "    train_dataloader=train_dataloader,\n",
    "    eval_dataloader=test_dataloader,\n",
    "    save_path=str(CKPT_DIR / operation),\n",
    "    verbose=verbose,\n",
    "    show_progress_bar=True,  # disable progress bar for better vis in sphinx gallery.\n",
    ")\n",
    "\n",
    "trainer.train()\n",
    "model = trainer.load_best_model()  # load model with best validation PSNR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dc5d500",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test the network\n",
    "# --------------------------------------------\n",
    "#\n",
    "#\n",
    "\n",
    "trainer.test(test_dataloader)\n",
    "\n",
    "test_sample, _ = next(iter(test_dataloader))\n",
    "model.eval()\n",
    "test_sample = test_sample.to(device)\n",
    "\n",
    "# Get the measurements and the ground truth\n",
    "y = physics(test_sample)\n",
    "with torch.no_grad():\n",
    "    rec = model(y, physics=physics)\n",
    "\n",
    "backprojected = physics.A_adjoint(y)\n",
    "\n",
    "dinv.utils.plot(\n",
    "    [backprojected, rec, test_sample],\n",
    "    titles=[\"Linear\", \"Reconstruction\", \"Ground truth\"],\n",
    "    suptitle=\"Reconstruction results\",\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
