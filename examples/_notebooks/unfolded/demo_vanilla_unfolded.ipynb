{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f77e50a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "r\"\"\"\n",
    "Vanilla Unfolded algorithm for super-resolution\n",
    "====================================================================================================\n",
    "\n",
    "This is a simple example to show how to use vanilla unfolded Plug-and-Play.\n",
    "The DnCNN denoiser and the algorithm parameters (stepsize, regularization parameters) are trained jointly.\n",
    "For simplicity, we show how to train the algorithm on a  small dataset. For optimal results, use a larger dataset.\n",
    "\"\"\"\n",
    "\n",
    "import deepinv as dinv\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from deepinv.optim.data_fidelity import L2\n",
    "from deepinv.optim.prior import PnP\n",
    "from deepinv.unfolded import unfolded_builder\n",
    "from torchvision import transforms\n",
    "from deepinv.utils import get_data_home\n",
    "from deepinv.datasets import BSDS500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a2c09d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup paths for data loading and results.\n",
    "# ----------------------------------------------------------------------------------------\n",
    "#\n",
    "\n",
    "BASE_DIR = get_data_home()\n",
    "DATA_DIR = BASE_DIR / \"measurements\"\n",
    "RESULTS_DIR = BASE_DIR / \"results\"\n",
    "CKPT_DIR = BASE_DIR / \"ckpts\"\n",
    "\n",
    "# Set the global random seed from pytorch to ensure reproducibility of the example.\n",
    "torch.manual_seed(0)\n",
    "\n",
    "device = dinv.utils.get_freer_gpu() if torch.cuda.is_available() else \"cpu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83e502f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load base image datasets and degradation operators.\n",
    "# ----------------------------------------------------------------------------------------\n",
    "# In this example, we use the CBSD500 dataset for training and the Set3C dataset for testing.\n",
    "\n",
    "img_size = 64 if torch.cuda.is_available() else 32\n",
    "n_channels = 3  # 3 for color images, 1 for gray-scale images\n",
    "operation = \"super-resolution\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "965785ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate a dataset of low resolution images and load it.\n",
    "# ----------------------------------------------------------------------------------------\n",
    "# We use the Downsampling class from the physics module to generate a dataset of low resolution images.\n",
    "\n",
    "# For simplicity, we use a small dataset for training.\n",
    "# To be replaced for optimal results. For example, you can use the larger DIV2K or LSDIR datasets (also provided in the library).\n",
    "\n",
    "# Specify the  train and test transforms to be applied to the input images.\n",
    "test_transform = transforms.Compose(\n",
    "    [transforms.CenterCrop(img_size), transforms.ToTensor()]\n",
    ")\n",
    "train_transform = transforms.Compose(\n",
    "    [transforms.RandomCrop(img_size), transforms.ToTensor()]\n",
    ")\n",
    "# Define the base train and test datasets of clean images.\n",
    "train_base_dataset = BSDS500(\n",
    "    BASE_DIR, download=True, train=True, transform=train_transform\n",
    ")\n",
    "test_base_dataset = BSDS500(\n",
    "    BASE_DIR, download=False, train=False, transform=test_transform\n",
    ")\n",
    "\n",
    "# Use parallel dataloader if using a GPU to speed up training, otherwise, as all computes are on CPU, use synchronous\n",
    "# dataloading.\n",
    "num_workers = 4 if torch.cuda.is_available() else 0\n",
    "\n",
    "# Degradation parameters\n",
    "factor = 2\n",
    "noise_level_img = 0.03\n",
    "\n",
    "# Generate the gaussian blur downsampling operator.\n",
    "physics = dinv.physics.Downsampling(\n",
    "    filter=\"gaussian\",\n",
    "    img_size=(n_channels, img_size, img_size),\n",
    "    factor=factor,\n",
    "    device=device,\n",
    "    noise_model=dinv.physics.GaussianNoise(sigma=noise_level_img),\n",
    ")\n",
    "my_dataset_name = \"demo_unfolded_sr\"\n",
    "n_images_max = (\n",
    "    None if torch.cuda.is_available() else 10\n",
    ")  # max number of images used for training (use all if you have a GPU)\n",
    "measurement_dir = DATA_DIR / \"BSDS500\" / operation\n",
    "generated_datasets_path = dinv.datasets.generate_dataset(\n",
    "    train_dataset=train_base_dataset,\n",
    "    test_dataset=test_base_dataset,\n",
    "    physics=physics,\n",
    "    device=device,\n",
    "    save_dir=measurement_dir,\n",
    "    train_datapoints=n_images_max,\n",
    "    num_workers=num_workers,\n",
    "    dataset_filename=str(my_dataset_name),\n",
    ")\n",
    "\n",
    "train_dataset = dinv.datasets.HDF5Dataset(path=generated_datasets_path, train=True)\n",
    "test_dataset = dinv.datasets.HDF5Dataset(path=generated_datasets_path, train=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ee90698",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the unfolded PnP algorithm.\n",
    "# ----------------------------------------------------------------------------------------\n",
    "# We use the helper function :func:`deepinv.unfolded.unfolded_builder` to define the Unfolded architecture.\n",
    "# The chosen algorithm is here DRS (Douglas-Rachford Splitting).\n",
    "# Note that if the prior (resp. a parameter) is initialized with a list of length max_iter,\n",
    "# then a distinct model (resp. parameter) is trained for each iteration.\n",
    "# For fixed trained model prior (resp. parameter) across iterations, initialize with a single element.\n",
    "\n",
    "# Unrolled optimization algorithm parameters\n",
    "max_iter = 5  # number of unfolded layers\n",
    "\n",
    "# Select the data fidelity term\n",
    "data_fidelity = L2()\n",
    "\n",
    "# Set up the trainable denoising prior\n",
    "# Here the prior model is common for all iterations\n",
    "prior = PnP(denoiser=dinv.models.DnCNN(depth=7, pretrained=None).to(device))\n",
    "\n",
    "# The parameters are initialized with a list of length max_iter, so that a distinct parameter is trained for each iteration.\n",
    "stepsize = [1.0] * max_iter  # stepsize of the algorithm\n",
    "sigma_denoiser = [\n",
    "    1.0\n",
    "] * max_iter  # noise level parameter of the denoiser (not used by DnCNN)\n",
    "beta = 1.0  # relaxation parameter of the Douglas-Rachford splitting\n",
    "params_algo = {  # wrap all the restoration parameters in a 'params_algo' dictionary\n",
    "    \"stepsize\": stepsize,\n",
    "    \"g_param\": sigma_denoiser,\n",
    "    \"beta\": beta,\n",
    "}\n",
    "trainable_params = [\n",
    "    \"stepsize\",\n",
    "    \"beta\",\n",
    "]  # define which parameters from 'params_algo' are trainable\n",
    "\n",
    "# Logging parameters\n",
    "verbose = True\n",
    "\n",
    "# Define the unfolded trainable model.\n",
    "model = unfolded_builder(\n",
    "    iteration=\"DRS\",\n",
    "    params_algo=params_algo.copy(),\n",
    "    trainable_params=trainable_params,\n",
    "    data_fidelity=data_fidelity,\n",
    "    max_iter=max_iter,\n",
    "    prior=prior,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad035d5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the training parameters.\n",
    "# ----------------------------------------------------------------------------------------\n",
    "# We use the Adam optimizer and the StepLR scheduler.\n",
    "\n",
    "\n",
    "# training parameters\n",
    "epochs = 5 if torch.cuda.is_available() else 2\n",
    "learning_rate = 5e-4\n",
    "train_batch_size = 32 if torch.cuda.is_available() else 1\n",
    "test_batch_size = 3\n",
    "\n",
    "# choose optimizer and scheduler\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate, weight_decay=1e-8)\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=int(epochs * 0.8))\n",
    "\n",
    "# choose supervised training loss\n",
    "losses = [dinv.loss.SupLoss(metric=dinv.metric.MSE())]\n",
    "\n",
    "train_dataloader = DataLoader(\n",
    "    train_dataset, batch_size=train_batch_size, num_workers=num_workers, shuffle=True\n",
    ")\n",
    "test_dataloader = DataLoader(\n",
    "    test_dataset, batch_size=test_batch_size, num_workers=num_workers, shuffle=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbfaa164",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "# Train the network\n",
    "# ----------------------------------------------------------------------------------------\n",
    "# We train the network using the :class:`deepinv.Trainer` class.\n",
    "\n",
    "trainer = dinv.Trainer(\n",
    "    model,\n",
    "    physics=physics,\n",
    "    train_dataloader=train_dataloader,\n",
    "    eval_dataloader=test_dataloader,\n",
    "    epochs=epochs,\n",
    "    scheduler=scheduler,\n",
    "    losses=losses,\n",
    "    optimizer=optimizer,\n",
    "    device=device,\n",
    "    early_stop=True,  # set to None to disable early stopping\n",
    "    save_path=str(CKPT_DIR / operation),\n",
    "    verbose=verbose,\n",
    "    show_progress_bar=False,  # disable progress bar for better vis in sphinx gallery.\n",
    ")\n",
    "\n",
    "model = trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f3c1151",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test the network\n",
    "# --------------------------------------------\n",
    "#\n",
    "#\n",
    "trainer.test(test_dataloader)\n",
    "\n",
    "test_sample, _ = next(iter(test_dataloader))\n",
    "model.eval()\n",
    "test_sample = test_sample.to(device)\n",
    "\n",
    "# Get the measurements and the ground truth\n",
    "y = physics(test_sample)\n",
    "with torch.no_grad():\n",
    "    rec = model(y, physics=physics)\n",
    "\n",
    "backprojected = physics.A_adjoint(y)\n",
    "\n",
    "dinv.utils.plot(\n",
    "    [backprojected, rec, test_sample],\n",
    "    titles=[\"Linear\", \"Reconstruction\", \"Ground truth\"],\n",
    "    suptitle=\"Reconstruction results\",\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
