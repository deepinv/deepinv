{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f12cca8",
   "metadata": {},
   "outputs": [],
   "source": [
    "r\"\"\"\n",
    "Unfolded Chambolle-Pock for constrained image inpainting\n",
    "====================================================================================================\n",
    "\n",
    "Image inpainting consists in solving :math:`y = Ax` where :math:`A` is a mask operator.\n",
    "This problem can be reformulated as the following minimization problem:\n",
    "\n",
    ".. math::\n",
    "\n",
    "    \\begin{equation*}\n",
    "    \\underset{x}{\\operatorname{min}} \\,\\, \\iota_{\\mathcal{B}_2(y, r)}(Ax) + \\regname(x)\n",
    "    \\end{equation*}\n",
    "\n",
    "\n",
    "where :math:`\\iota_{\\mathcal{B}_2(y, r)}` is the indicator function of the ball of radius :math:`r` centered at\n",
    ":math:`y` for the :math:`\\ell_2` norm, and :math:`\\regname` is a regularisation. Recall that the indicator function of\n",
    "a convex set :math:`\\mathcal{C}` is defined as :math:`\\iota_{\\mathcal{C}}(x) = 0` if :math:`x \\in \\mathcal{C}` and\n",
    ":math:`\\iota_{\\mathcal{C}}(x) = +\\infty` otherwise.\n",
    "\n",
    "In this example, we unfold the Chambolle-Pock algorithm to solve this problem, and learn the thresholding parameters of\n",
    "a wavelet denoiser in a LISTA fashion.\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "from pathlib import Path\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import transforms\n",
    "import deepinv as dinv\n",
    "from deepinv.utils import load_dataset\n",
    "from deepinv.optim.data_fidelity import IndicatorL2\n",
    "from deepinv.optim.prior import PnP\n",
    "from deepinv.unfolded import unfolded_builder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1e0057a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup paths for data loading and results.\n",
    "# --------------------------------------------\n",
    "#\n",
    "\n",
    "BASE_DIR = Path(\".\")\n",
    "DATA_DIR = BASE_DIR / \"measurements\"\n",
    "CKPT_DIR = BASE_DIR / \"ckpts\"\n",
    "\n",
    "# Set the global random seed from pytorch to ensure reproducibility of the example.\n",
    "torch.manual_seed(0)\n",
    "\n",
    "device = dinv.utils.get_freer_gpu() if torch.cuda.is_available() else \"cpu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "753a00b3",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "# Load base image datasets and degradation operators.\n",
    "# --------------------------------------------------------------------------------------------\n",
    "# In this example, we use the CBSD68 dataset for training and the set3c dataset for testing.\n",
    "# We work with images of size 32x32 if no GPU is available, else 128x128.\n",
    "\n",
    "\n",
    "operation = \"inpainting\"\n",
    "train_dataset_name = \"CBSD68\"\n",
    "test_dataset_name = \"set3c\"\n",
    "img_size = 128 if torch.cuda.is_available() else 32\n",
    "\n",
    "test_transform = transforms.Compose(\n",
    "    [transforms.CenterCrop(img_size), transforms.ToTensor()]\n",
    ")\n",
    "train_transform = transforms.Compose(\n",
    "    [transforms.RandomCrop(img_size), transforms.ToTensor()]\n",
    ")\n",
    "\n",
    "train_base_dataset = load_dataset(train_dataset_name, transform=train_transform)\n",
    "test_base_dataset = load_dataset(test_dataset_name, transform=test_transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "249224b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define forward operator and generate dataset\n",
    "# --------------------------------------------------------------------------------------------\n",
    "# We define an inpainting operator that randomly masks pixels with probability 0.5.\n",
    "#\n",
    "# A dataset of pairs of measurements and ground truth images is then generated using the\n",
    "# :func:`deepinv.datasets.generate_dataset` function.\n",
    "#\n",
    "# Once the dataset is generated, we can load it using the :class:`deepinv.datasets.HDF5Dataset` class.\n",
    "\n",
    "n_channels = 3  # 3 for color images, 1 for gray-scale images\n",
    "probability_mask = 0.5  # probability to mask pixel\n",
    "\n",
    "# Generate inpainting operator\n",
    "physics = dinv.physics.Inpainting(\n",
    "    img_size=(n_channels, img_size, img_size), mask=probability_mask, device=device\n",
    ")\n",
    "\n",
    "\n",
    "# Use parallel dataloader if using a GPU to speed up training,\n",
    "# otherwise, as all computes are on CPU, use synchronous data loading.\n",
    "num_workers = 4 if torch.cuda.is_available() else 0\n",
    "n_images_max = (\n",
    "    100 if torch.cuda.is_available() else 50\n",
    ")  # maximal number of images used for training\n",
    "my_dataset_name = \"demo_training_inpainting\"\n",
    "measurement_dir = DATA_DIR / train_dataset_name / operation\n",
    "deepinv_datasets_path = dinv.datasets.generate_dataset(\n",
    "    train_dataset=train_base_dataset,\n",
    "    test_dataset=test_base_dataset,\n",
    "    physics=physics,\n",
    "    device=device,\n",
    "    save_dir=measurement_dir,\n",
    "    train_datapoints=n_images_max,\n",
    "    num_workers=num_workers,\n",
    "    dataset_filename=str(my_dataset_name),\n",
    ")\n",
    "\n",
    "train_dataset = dinv.datasets.HDF5Dataset(path=deepinv_datasets_path, train=True)\n",
    "test_dataset = dinv.datasets.HDF5Dataset(path=deepinv_datasets_path, train=False)\n",
    "\n",
    "\n",
    "train_batch_size = 32 if torch.cuda.is_available() else 3\n",
    "test_batch_size = 32 if torch.cuda.is_available() else 3\n",
    "\n",
    "train_dataloader = DataLoader(\n",
    "    train_dataset, batch_size=train_batch_size, num_workers=num_workers, shuffle=True\n",
    ")\n",
    "test_dataloader = DataLoader(\n",
    "    test_dataset, batch_size=test_batch_size, num_workers=num_workers, shuffle=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a003e7d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up the reconstruction network\n",
    "# --------------------------------------------------------\n",
    "# We unfold the Chambolle-Pock algorithm as follows:\n",
    "#\n",
    "#      .. math::\n",
    "#          \\begin{equation*}\n",
    "#          \\begin{aligned}\n",
    "#          u_{k+1} &= \\operatorname{prox}_{\\sigma d^*}(u_k + \\sigma A z_k) \\\\\n",
    "#          x_{k+1} &= \\operatorname{D_{\\sigma}}(x_k-\\tau A^\\top u_{k+1}) \\\\\n",
    "#          z_{k+1} &= 2x_{k+1} -x_k \\\\\n",
    "#          \\end{aligned}\n",
    "#          \\end{equation*}\n",
    "#\n",
    "# where :math:`\\operatorname{D_{\\sigma}}` is a wavelet denoiser with thresholding parameters :math:`\\sigma`.\n",
    "#\n",
    "# The learnable parameters of our network are :math:`\\tau` and :math:`\\sigma`.\n",
    "\n",
    "# Select the data fidelity term\n",
    "data_fidelity = IndicatorL2(radius=0.0)\n",
    "\n",
    "# Set up the trainable denoising prior; here, the soft-threshold in a wavelet basis.\n",
    "# If the prior is initialized with a list of length max_iter,\n",
    "# then a distinct weight is trained for each CP iteration.\n",
    "# For fixed trained model prior across iterations, initialize with a single model.\n",
    "max_iter = 30 if torch.cuda.is_available() else 20  # Number of unrolled iterations\n",
    "level = 3\n",
    "prior = [\n",
    "    PnP(denoiser=dinv.models.WaveletDenoiser(wv=\"db8\", level=level, device=device))\n",
    "    for i in range(max_iter)\n",
    "]\n",
    "\n",
    "# Unrolled optimization algorithm parameters\n",
    "stepsize = [\n",
    "    1.0\n",
    "] * max_iter  # initialization of the stepsizes. A distinct stepsize is trained for each iteration.\n",
    "sigma_denoiser = [\n",
    "    0.01 * torch.ones(1, level, 3)\n",
    "] * max_iter  # thresholding parameters \\sigma\n",
    "\n",
    "stepsize_dual = 1.0  # dual stepsize for Chambolle-Pock\n",
    "\n",
    "# Define the parameters of the unfolded Primal-Dual Chambolle-Pock algorithm\n",
    "# The CP algorithm requires to specify `params_algo`` the linear operator and its adjoint on which splitting is performed.\n",
    "# See the documentation of the CP algorithm :class:`deepinv.optim.optim_iterators.CPIteration` for more details.\n",
    "params_algo = {\n",
    "    \"stepsize\": stepsize,  # Stepsize for the primal update.\n",
    "    \"g_param\": sigma_denoiser,  # prior parameter.\n",
    "    \"stepsize_dual\": stepsize_dual,  # The CP algorithm requires a second stepsize ``sigma`` for the dual update.\n",
    "    \"K\": physics.A,\n",
    "    \"K_adjoint\": physics.A_adjoint,\n",
    "}\n",
    "\n",
    "# define which parameters from 'params_algo' are trainable\n",
    "trainable_params = [\"g_param\", \"stepsize\"]\n",
    "\n",
    "\n",
    "# Because the CP algorithm uses more than 2 variables, we need to define a custom initialization.\n",
    "def custom_init_CP(y, physics):\n",
    "    x_init = physics.A_adjoint(y)\n",
    "    u_init = y\n",
    "    return {\"est\": (x_init, x_init, u_init)}\n",
    "\n",
    "\n",
    "# Define the unfolded trainable model.\n",
    "model = unfolded_builder(\n",
    "    iteration=\"CP\",\n",
    "    trainable_params=trainable_params,\n",
    "    params_algo=params_algo.copy(),\n",
    "    data_fidelity=data_fidelity,\n",
    "    max_iter=max_iter,\n",
    "    prior=prior,\n",
    "    g_first=False,\n",
    "    custom_init=custom_init_CP,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "844a6f0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model\n",
    "# ---------------\n",
    "# We train the model using the :class:`deepinv.Trainer` class.\n",
    "#\n",
    "# We perform supervised learning and use the mean squared error as loss function. This can be easily done using the\n",
    "# :class:`deepinv.loss.SupLoss` class.\n",
    "#\n",
    "# .. note::\n",
    "#\n",
    "#       In this example, we only train for a few epochs to keep the training time short on CPU.\n",
    "#       For a good reconstruction quality, we recommend to train for at least 50 epochs.\n",
    "#\n",
    "\n",
    "epochs = 10 if torch.cuda.is_available() else 5  # choose training epochs\n",
    "learning_rate = 1e-3\n",
    "\n",
    "verbose = True  # print training information\n",
    "\n",
    "# choose training losses\n",
    "losses = dinv.loss.SupLoss(metric=dinv.metric.MSE())\n",
    "\n",
    "# choose optimizer and scheduler\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate, weight_decay=1e-8)\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=int(epochs * 0.8))\n",
    "\n",
    "trainer = dinv.Trainer(\n",
    "    model=model,\n",
    "    scheduler=scheduler,\n",
    "    losses=losses,\n",
    "    device=device,\n",
    "    optimizer=optimizer,\n",
    "    physics=physics,\n",
    "    train_dataloader=train_dataloader,\n",
    "    save_path=str(CKPT_DIR / operation),\n",
    "    verbose=verbose,\n",
    "    show_progress_bar=False,  # disable progress bar for better vis in sphinx gallery.\n",
    "    epochs=epochs,\n",
    ")\n",
    "\n",
    "model = trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf717cc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test the network\n",
    "# --------------------------------------------\n",
    "# We can now test the trained network using the :func:`deepinv.test` function.\n",
    "#\n",
    "# The testing function will compute test_psnr metrics and plot and save the results.\n",
    "\n",
    "plot_images = True\n",
    "method = \"artifact_removal\"\n",
    "\n",
    "trainer.test(test_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46b236d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving the model\n",
    "# ----------------\n",
    "# We can save the trained model following the standard PyTorch procedure.\n",
    "\n",
    "# Save the model\n",
    "torch.save(model.state_dict(), CKPT_DIR / operation / \"model.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dc0372c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading the model\n",
    "# -----------------\n",
    "# Similarly, we can load our trained unfolded architecture following the standard PyTorch procedure.\n",
    "# To check that the loading is performed correctly, we use new variables for the initialization of the model.\n",
    "\n",
    "# Set up the trainable denoising prior; here, the soft-threshold in a wavelet basis.\n",
    "level = 3\n",
    "model_spec = {\n",
    "    \"name\": \"waveletprior\",\n",
    "    \"args\": {\"wv\": \"db8\", \"level\": level, \"device\": device},\n",
    "}\n",
    "# If the prior is initialized with a list of length max_iter,\n",
    "# then a distinct weight is trained for each PGD iteration.\n",
    "# For fixed trained model prior across iterations, initialize with a single model.\n",
    "max_iter = 30 if torch.cuda.is_available() else 20  # Number of unrolled iterations\n",
    "prior_new = [\n",
    "    PnP(denoiser=dinv.models.WaveletDenoiser(wv=\"db8\", level=level, device=device))\n",
    "    for i in range(max_iter)\n",
    "]\n",
    "\n",
    "# Unrolled optimization algorithm parameters\n",
    "stepsize = [\n",
    "    1.0\n",
    "] * max_iter  # initialization of the stepsizes. A distinct stepsize is trained for each iteration.\n",
    "sigma_denoiser = [0.01 * torch.ones(1, level, 3)] * max_iter\n",
    "stepsize_dual = 1.0  # stepsize for Chambolle-Pock\n",
    "\n",
    "params_algo_new = {\n",
    "    \"stepsize\": stepsize,\n",
    "    \"g_param\": sigma_denoiser,\n",
    "    \"stepsize_dual\": stepsize_dual,\n",
    "    \"K\": physics.A,\n",
    "    \"K_adjoint\": physics.A_adjoint,\n",
    "}\n",
    "\n",
    "model_new = unfolded_builder(\n",
    "    \"CP\",\n",
    "    trainable_params=trainable_params,\n",
    "    params_algo=params_algo_new,\n",
    "    data_fidelity=data_fidelity,\n",
    "    max_iter=max_iter,\n",
    "    prior=prior_new,\n",
    "    g_first=False,\n",
    "    custom_init=custom_init_CP,\n",
    ")\n",
    "model_new.load_state_dict(torch.load(CKPT_DIR / operation / \"model.pth\"))\n",
    "model_new.eval()\n",
    "\n",
    "# Test the model and check that the results are the same as before saving\n",
    "dinv.training.test(\n",
    "    model_new, test_dataloader, physics=physics, device=device, show_progress_bar=False\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
