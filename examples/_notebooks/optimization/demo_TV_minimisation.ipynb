{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20aa889f",
   "metadata": {},
   "outputs": [],
   "source": [
    "r\"\"\"\n",
    "Image deblurring with Total-Variation (TV) prior\n",
    "====================================================================================================\n",
    "\n",
    "This example shows how to use a standard TV prior for image deblurring. The problem writes as :math:`y = Ax + \\epsilon`\n",
    "where :math:`A` is a convolutional operator and :math:`\\epsilon` is the realization of some Gaussian noise. The goal is\n",
    "to recover the original image :math:`x` from the blurred and noisy image :math:`y`. The TV prior is used to regularize\n",
    "the problem.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f1381d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import deepinv as dinv\n",
    "from pathlib import Path\n",
    "import torch\n",
    "from torchvision import transforms\n",
    "\n",
    "from deepinv.optim.data_fidelity import L2\n",
    "from deepinv.optim.optimizers import optim_builder\n",
    "from deepinv.utils import load_dataset, load_degradation\n",
    "from deepinv.utils.plotting import plot, plot_curves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b470f100",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "# Setup paths for data loading and results.\n",
    "# ----------------------------------------------------------------------------------------\n",
    "#\n",
    "\n",
    "BASE_DIR = Path(\".\")\n",
    "DATA_DIR = BASE_DIR / \"measurements\"\n",
    "RESULTS_DIR = BASE_DIR / \"results\"\n",
    "DEG_DIR = BASE_DIR / \"degradations\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df25a633",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "# Load base image datasets and degradation operators.\n",
    "# ----------------------------------------------------------------------------------------\n",
    "# In this example, we use the Set3C dataset and a motion blur kernel from :footcite:t:`levin2009understanding`.\n",
    "#\n",
    "\n",
    "# Set the global random seed from pytorch to ensure reproducibility of the example.\n",
    "torch.manual_seed(0)\n",
    "\n",
    "device = dinv.utils.get_freer_gpu() if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "# Set up the variable to fetch dataset and operators.\n",
    "dataset_name = \"set3c\"\n",
    "img_size = 256 if torch.cuda.is_available() else 64\n",
    "val_transform = transforms.Compose(\n",
    "    [transforms.CenterCrop(img_size), transforms.ToTensor()]\n",
    ")\n",
    "\n",
    "# Generate a motion blur operator.\n",
    "kernel_index = 1  # which kernel to chose among the 8 motion kernels from 'Levin09.mat'\n",
    "kernel_torch = load_degradation(\"Levin09.npy\", DEG_DIR / \"kernels\", index=kernel_index)\n",
    "kernel_torch = kernel_torch.unsqueeze(0).unsqueeze(\n",
    "    0\n",
    ")  # add batch and channel dimensions\n",
    "dataset = load_dataset(dataset_name, transform=val_transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12d60859",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate a dataset of blurred images and load it.\n",
    "# --------------------------------------------------------------------------------\n",
    "# We use the BlurFFT class from the physics module to generate a dataset of blurred images.\n",
    "\n",
    "\n",
    "noise_level_img = 0.05  # Gaussian Noise standard deviation for the degradation\n",
    "n_channels = 3  # 3 for color images, 1 for gray-scale images\n",
    "physics = dinv.physics.BlurFFT(\n",
    "    img_size=(n_channels, img_size, img_size),\n",
    "    filter=kernel_torch,\n",
    "    device=device,\n",
    "    noise_model=dinv.physics.GaussianNoise(sigma=noise_level_img),\n",
    ")\n",
    "\n",
    "# Select the first image from the dataset\n",
    "x = dataset[0].unsqueeze(0).to(device)\n",
    "\n",
    "# Apply the degradation to the image\n",
    "y = physics(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "beb00d65",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exploring the total variation prior.\n",
    "# ------------------------------------\n",
    "#\n",
    "# In this example, we will use the total variation prior, which can be done with the :class:`deepinv.optim.prior.Prior`\n",
    "# class. The prior object represents the cost function of the prior (TV in this case), as well as convenient methods,\n",
    "# such as its proximal operator :math:`\\text{prox}_{\\tau g}`.\n",
    "\n",
    "# Set up the total variation prior\n",
    "prior = dinv.optim.prior.TVPrior(n_it_max=2000)\n",
    "\n",
    "# Compute the total variation prior cost\n",
    "cost_tv = prior(y).item()\n",
    "print(f\"Cost TV: g(y) = {cost_tv:.2f}\")\n",
    "\n",
    "# Apply the proximal operator of the TV prior\n",
    "x_tv = prior.prox(y, gamma=0.1)\n",
    "cost_tv_prox = prior(x_tv).item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f317ca2",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "# .. note::\n",
    "#           The output of the proximity operator of TV is **not** the solution to our deblurring problem. It is only a\n",
    "#           step towards the solution and is used in the proximal gradient descent algorithm to solve the inverse\n",
    "#           problem.\n",
    "#\n",
    "\n",
    "# Plot the input and the output of the TV proximal operator\n",
    "imgs = [y, x_tv]\n",
    "plot(\n",
    "    {\"Input\": y, \"Output\": x_tv},\n",
    "    subtitles=[\n",
    "        f\"TV cost: {int(cost_tv)}\",\n",
    "        f\"TV cost: {int(cost_tv_prox)}\",\n",
    "    ],\n",
    "    tight=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4ec7738",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up the optimization algorithm to solve the inverse problem.\n",
    "# --------------------------------------------------------------------------------\n",
    "# The problem we want to minimize is the following:\n",
    "#\n",
    "# .. math::\n",
    "#\n",
    "#     \\begin{equation*}\n",
    "#     \\underset{x}{\\operatorname{min}} \\,\\, \\frac{1}{2} \\|Ax-y\\|_2^2 + \\lambda \\|Dx\\|_{1,2}(x),\n",
    "#     \\end{equation*}\n",
    "#\n",
    "#\n",
    "# where :math:`1/2 \\|A(x)-y\\|_2^2` is the a data-fidelity term, :math:`\\lambda \\|Dx\\|_{2,1}(x)` is the total variation (TV)\n",
    "# norm of the image :math:`x`, and :math:`\\lambda>0` is a regularisation parameters.\n",
    "#\n",
    "# We use a Proximal Gradient Descent (PGD) algorithm to solve the inverse problem.\n",
    "\n",
    "# Select the data fidelity term\n",
    "data_fidelity = L2()\n",
    "\n",
    "# Specify the prior (we redefine it with a smaller number of iteration for faster computation)\n",
    "prior = dinv.optim.prior.TVPrior(n_it_max=20)\n",
    "\n",
    "# Logging parameters\n",
    "verbose = True\n",
    "plot_convergence_metrics = (\n",
    "    True  # compute performance and convergence metrics along the algorithm.\n",
    ")\n",
    "\n",
    "# Algorithm parameters\n",
    "stepsize = 1.0\n",
    "lamb = 1e-2  # TV regularisation parameter\n",
    "params_algo = {\"stepsize\": stepsize, \"lambda\": lamb}\n",
    "max_iter = 300\n",
    "early_stop = True\n",
    "\n",
    "# Instantiate the algorithm class to solve the problem.\n",
    "model = optim_builder(\n",
    "    iteration=\"PGD\",\n",
    "    prior=prior,\n",
    "    data_fidelity=data_fidelity,\n",
    "    early_stop=early_stop,\n",
    "    max_iter=max_iter,\n",
    "    verbose=verbose,\n",
    "    params_algo=params_algo,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed65cb42",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the model on the problem and plot the results.\n",
    "# --------------------------------------------------------------------\n",
    "#\n",
    "# The model returns the output and the metrics computed along the iterations.\n",
    "# For computing PSNR, the ground truth image ``x_gt`` must be provided.\n",
    "\n",
    "\n",
    "x_lin = physics.A_adjoint(y)  # linear reconstruction with the adjoint operator\n",
    "\n",
    "# run the model on the problem.\n",
    "x_model, metrics = model(\n",
    "    y, physics, x_gt=x, compute_metrics=True\n",
    ")  # reconstruction with PGD algorithm\n",
    "\n",
    "# compute PSNR\n",
    "psnr_input = dinv.metric.PSNR()(x, y)\n",
    "psnr_lin = dinv.metric.PSNR()(x, x_lin)\n",
    "psnr_model = dinv.metric.PSNR()(x, x_model)\n",
    "\n",
    "# plot images. Images are saved in RESULTS_DIR.\n",
    "imgs = [x, y, x_lin, x_model]\n",
    "plot(\n",
    "    {\"Ground Truth\": x, \"Input\": y, \"Linear Recon\": x_lin, \"Recons\": x_model},\n",
    "    subtitles=[\n",
    "        \"PSNR:\",\n",
    "        f\"{psnr_input.item():.2f} dB\",\n",
    "        f\"{psnr_lin.item():.2f} dB\",\n",
    "        f\"{psnr_model.item():.2f} dB\",\n",
    "    ],\n",
    ")\n",
    "\n",
    "# plot convergence curves\n",
    "if plot_convergence_metrics:\n",
    "    plot_curves(metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8410981",
   "metadata": {},
   "outputs": [],
   "source": [
    "# :References:\n",
    "#\n",
    "# .. footbibliography::"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
