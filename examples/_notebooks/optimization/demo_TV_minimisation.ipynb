{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n# Image deblurring with Total-Variation (TV) prior\n\nThis example shows how to use a standard TV prior for image deblurring. The problem writes as $y = Ax + \\epsilon$\nwhere $A$ is a convolutional operator and $\\epsilon$ is the realization of some Gaussian noise. The goal is\nto recover the original image $x$ from the blurred and noisy image $y$. The TV prior is used to regularize\nthe problem.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "import deepinv as dinv\nfrom pathlib import Path\nimport torch\nfrom torchvision import transforms\n\nfrom deepinv.optim.data_fidelity import L2\nfrom deepinv.optim.optimizers import optim_builder\nfrom deepinv.utils import load_dataset, load_degradation\nfrom deepinv.utils.plotting import plot, plot_curves"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Setup paths for data loading and results.\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "BASE_DIR = Path(\".\")\nDATA_DIR = BASE_DIR / \"measurements\"\nRESULTS_DIR = BASE_DIR / \"results\"\nDEG_DIR = BASE_DIR / \"degradations\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Load base image datasets and degradation operators.\nIn this example, we use the Set3C dataset and a motion blur kernel from :footcite:t:`levin2009understanding`.\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# Set the global random seed from pytorch to ensure reproducibility of the example.\ntorch.manual_seed(0)\n\ndevice = dinv.utils.get_freer_gpu() if torch.cuda.is_available() else \"cpu\"\n\n# Set up the variable to fetch dataset and operators.\ndataset_name = \"set3c\"\nimg_size = 256 if torch.cuda.is_available() else 64\nval_transform = transforms.Compose(\n    [transforms.CenterCrop(img_size), transforms.ToTensor()]\n)\n\n# Generate a motion blur operator.\nkernel_index = 1  # which kernel to chose among the 8 motion kernels from 'Levin09.mat'\nkernel_torch = load_degradation(\"Levin09.npy\", DEG_DIR / \"kernels\", index=kernel_index)\nkernel_torch = kernel_torch.unsqueeze(0).unsqueeze(\n    0\n)  # add batch and channel dimensions\ndataset = load_dataset(dataset_name, transform=val_transform)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Generate a dataset of blurred images and load it.\nWe use the BlurFFT class from the physics module to generate a dataset of blurred images.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "noise_level_img = 0.05  # Gaussian Noise standard deviation for the degradation\nn_channels = 3  # 3 for color images, 1 for gray-scale images\nphysics = dinv.physics.BlurFFT(\n    img_size=(n_channels, img_size, img_size),\n    filter=kernel_torch,\n    device=device,\n    noise_model=dinv.physics.GaussianNoise(sigma=noise_level_img),\n)\n\n# Select the first image from the dataset\nx = dataset[0].unsqueeze(0).to(device)\n\n# Apply the degradation to the image\ny = physics(x)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Exploring the total variation prior.\n\nIn this example, we will use the total variation prior, which can be done with the :class:`deepinv.optim.prior.Prior`\nclass. The prior object represents the cost function of the prior (TV in this case), as well as convenient methods,\nsuch as its proximal operator $\\text{prox}_{\\tau g}$.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# Set up the total variation prior\nprior = dinv.optim.prior.TVPrior(n_it_max=2000)\n\n# Compute the total variation prior cost\ncost_tv = prior(y).item()\nprint(f\"Cost TV: g(y) = {cost_tv:.2f}\")\n\n# Apply the proximal operator of the TV prior\nx_tv = prior.prox(y, gamma=0.1)\ncost_tv_prox = prior(x_tv).item()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<div class=\"alert alert-info\"><h4>Note</h4><p>The output of the proximity operator of TV is **not** the solution to our deblurring problem. It is only a\n          step towards the solution and is used in the proximal gradient descent algorithm to solve the inverse\n          problem.</p></div>\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# Plot the input and the output of the TV proximal operator\nimgs = [y, x_tv]\nplot(\n    {\"Input\": y, \"Output\": x_tv},\n    subtitles=[\n        f\"TV cost: {int(cost_tv)}\",\n        f\"TV cost: {int(cost_tv_prox)}\",\n    ],\n    tight=False,\n)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Set up the optimization algorithm to solve the inverse problem.\nThe problem we want to minimize is the following:\n\n\\begin{align}\\begin{equation*}\n    \\underset{x}{\\operatorname{min}} \\,\\, \\frac{1}{2} \\|Ax-y\\|_2^2 + \\lambda \\|Dx\\|_{1,2}(x),\n    \\end{equation*}\\end{align}\n\n\nwhere $1/2 \\|A(x)-y\\|_2^2$ is the a data-fidelity term, $\\lambda \\|Dx\\|_{2,1}(x)$ is the total variation (TV)\nnorm of the image $x$, and $\\lambda>0$ is a regularisation parameters.\n\nWe use a Proximal Gradient Descent (PGD) algorithm to solve the inverse problem.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# Select the data fidelity term\ndata_fidelity = L2()\n\n# Specify the prior (we redefine it with a smaller number of iteration for faster computation)\nprior = dinv.optim.prior.TVPrior(n_it_max=20)\n\n# Logging parameters\nverbose = True\nplot_convergence_metrics = (\n    True  # compute performance and convergence metrics along the algorithm.\n)\n\n# Algorithm parameters\nstepsize = 1.0\nlamb = 1e-2  # TV regularisation parameter\nparams_algo = {\"stepsize\": stepsize, \"lambda\": lamb}\nmax_iter = 300\nearly_stop = True\n\n# Instantiate the algorithm class to solve the problem.\nmodel = optim_builder(\n    iteration=\"PGD\",\n    prior=prior,\n    data_fidelity=data_fidelity,\n    early_stop=early_stop,\n    max_iter=max_iter,\n    verbose=verbose,\n    params_algo=params_algo,\n)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Evaluate the model on the problem and plot the results.\n\nThe model returns the output and the metrics computed along the iterations.\nFor computing PSNR, the ground truth image ``x_gt`` must be provided.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "x_lin = physics.A_adjoint(y)  # linear reconstruction with the adjoint operator\n\n# run the model on the problem.\nx_model, metrics = model(\n    y, physics, x_gt=x, compute_metrics=True\n)  # reconstruction with PGD algorithm\n\n# compute PSNR\npsnr_input = dinv.metric.PSNR()(x, y)\npsnr_lin = dinv.metric.PSNR()(x, x_lin)\npsnr_model = dinv.metric.PSNR()(x, x_model)\n\n# plot images. Images are saved in RESULTS_DIR.\nimgs = [x, y, x_lin, x_model]\nplot(\n    {\"Ground Truth\": x, \"Input\": y, \"Linear Recon\": x_lin, \"Recons\": x_model},\n    subtitles=[\n        \"PSNR:\",\n        f\"{psnr_input.item():.2f} dB\",\n        f\"{psnr_lin.item():.2f} dB\",\n        f\"{psnr_model.item():.2f} dB\",\n    ],\n)\n\n# plot convergence curves\nif plot_convergence_metrics:\n    plot_curves(metrics)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        ":References:\n\n.. footbibliography::\n\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}