{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n# 3D denoising\n\nThis example shows how to use variational 3D denoisers for denoising a 3D image. We first apply a standard soft-thresholding\nwavelet denoiser to a 3D brain MRI volume, as well as a 3D TV denoiser.\nWe then extend the wavelet denoiser objective to a redundant dictionary of wavelet\nbases, which does not admit a closed-form solution. We solve the denoising problem using the Dykstra-like algorithm.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "import deepinv as dinv\nfrom pathlib import Path\n\nimport torch\nimport torch.nn as nn"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Setup paths for data loading and results.\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "BASE_DIR = Path(\".\")\nDATA_DIR = BASE_DIR / \"measurements\"\nRESULTS_DIR = BASE_DIR / \"results\"\nDEG_DIR = BASE_DIR / \"degradations\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Load base volume image and denoising operators.\nIn this example, we use a T1-weighted brain MRI volume from the BrainWeb dataset (subject id 4) and we add\nGaussian random noise to it. Following the torch convention, the volume is of shape (C, D, H, W), where C is the\nnumber of channels, D is the depth, H is the height, and W is the width. We use a single channel volume in this\nexample.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# Set the global random seed from pytorch to ensure reproducibility of the example.\ntorch.manual_seed(0)\n\ndevice = dinv.utils.get_freer_gpu() if torch.cuda.is_available() else \"cpu\"\n\nvolume_data = (\n    dinv.utils.load_np_url(\n        \"https://huggingface.co/datasets/deepinv/images/resolve/main/brainweb_t1_ICBM_1mm_subject_0.npy?download=true\"\n    )\n    .flip(0)\n    .unsqueeze(0)\n    .unsqueeze(0)\n)\nx = volume_data / volume_data.max()\n\nnoise_level_img = 0.1  # Gaussian Noise standard deviation for the degradation\nphysics = dinv.physics.Denoising(\n    noise_model=dinv.physics.GaussianNoise(sigma=noise_level_img)\n)\n\n# Apply the degradation to the image\ny = physics(x)\n\n# Compute the PSNR\npsnr = dinv.metric.PSNR()(y, x).item()\n\n# Plot the input and the output of the degradation\nlist_images = [x[0, :, 90, :, :], x[0, :, :, 108, :], x[0, :, :, :, 90]]\ndinv.utils.plot(\n    list_images,\n    figsize=(6, 2),\n    suptitle=\"groundtruth brain volume\",\n    cmap=\"viridis\",\n    tight=False,\n    fontsize=12,\n)\nlist_images = [y[0, :, 90, :, :], y[0, :, :, 108, :], y[0, :, :, :, 90]]\ndinv.utils.plot(\n    list_images,\n    figsize=(6, 2),\n    suptitle=f\"noisy brain volume, PSNR = {psnr:.2f}dB\",\n    cmap=\"viridis\",\n    tight=False,\n    fontsize=12,\n)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Create the denoising operator and solve the problem.\nWe use the WaveletPrior class from the models module to solve the problem. This class implements the proximal operator\nof the wavelet prior and can be used as a denoiser. More precisely it solves the following problem\n\n\\begin{align}\\widehat{x} = \\arg\\min_{x} \\frac{1}{2} \\|y - x\\|_2^2 + \\lambda \\|\\Psi x\\|_1 = \\operatorname{prox}_{\\lambda \\|\\Psi \\cdot\\|_1}(y)\\end{align}\n\nwhere $\\Psi$ is the wavelet transform and $\\lambda$ is the thresholding parameter. The solution to\nthis problem is given by the proximal operator of the wavelet prior.\n\n<div class=\"alert alert-info\"><h4>Note</h4><p>The computational complexity of the wavelet transform in 3D grows cubically with the size of the support. For this\n    reason, we use a wavelets with small support (e.g. db1 to db4) in this example, which limits the performance\n    of the denoiser.</p></div>\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# Create the wavelet denoiser\nwv = \"db4\"\ndenoiser = dinv.models.wavdict.WaveletDenoiser(\n    wv=wv,\n    wvdim=3,\n    level=3,\n)\n\n# Apply the denoiser to the volume\nths = noise_level_img * 2  # thresholding parameter\nwith torch.no_grad():\n    x_hat = denoiser(y, ths)  # denoised volume\npsnr = dinv.metric.PSNR()(x_hat, x).item()  # compute PSNR\n\n# Plot\nlist_images = [x_hat[0, :, 90, :, :], x_hat[0, :, :, 108, :], x_hat[0, :, :, :, 90]]\ndinv.utils.plot(\n    list_images,\n    figsize=(6, 2),\n    suptitle=f\"Denoised brain volume, wavelet prior. PSNR = {psnr:.2f}dB\",\n    cmap=\"viridis\",\n    tight=False,\n    fontsize=12,\n)\n\n# sphinx_gallery_start_ignore\nassert psnr > 29.0\n# sphinx_gallery_end_ignore"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Other variational priors do also support 3D implementation. For instance, this is the case with TV or TGV priors.\nBelow, we illustrate the use of a TV denoiser, that solves the problem\n\n\\begin{align}\\widehat{x} = \\arg\\min_{x} \\frac{1}{2} \\|y - x\\|_2^2 + \\lambda \\|x\\|_\\text{TV} = \\operatorname{prox}_{\\lambda \\|\\cdot\\|_{\\text{TV}}}(y)\\end{align}\n\nwhere $\\|\\cdot\\|_\\text{TV}$ is the total variation norm and $\\lambda$ is a regularization parameter.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "denoiser_tv = dinv.models.TVDenoiser(n_it_max=10)\n\n# Apply the denoiser to the volume\nths_tv = noise_level_img * 5.0  # thresholding parameter\nwith torch.no_grad():\n    x_hat_tv = denoiser_tv(y, ths_tv)  # denoised volume\n\npsnr_tv = dinv.metric.PSNR()(x_hat_tv, x).item()\n\n# Plot\nlist_images = [\n    x_hat_tv[0, :, 90, :, :],\n    x_hat_tv[0, :, :, 108, :],\n    x_hat_tv[0, :, :, :, 90],\n]\ndinv.utils.plot(\n    list_images,\n    figsize=(6, 2),\n    suptitle=f\"Denoised brain volume, TV prior. PSNR = {psnr_tv:.2f}dB\",\n    cmap=\"viridis\",\n    tight=False,\n    fontsize=12,\n)\n\n# sphinx_gallery_start_ignore\nassert psnr_tv > 29.5\n# sphinx_gallery_end_ignore"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "One can extend the above denoisers to more general denoisers.\nFor instance, we can extend the wavelet denoiser to a redundant dictionary of wavelet bases.\nThis is the purpose of the next section.\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Extension to multiple wavelet bases.\nInstead of solving the problem in a single wavelet basis, one can seek for sparsity in a redundant dictionary of\nwavelet bases. Formally,\n\n\\begin{align}\\widehat{x} = \\arg\\min_{x} \\frac{1}{2} \\|y - x\\|_2^2 + \\sum_{\\ell=1}^{L}\\lambda_{\\ell} \\|\\Psi_{\\ell} x\\|_1,\\end{align}\n\nwhere $\\Psi_{\\ell}$ is the wavelet transform in the $\\ell$-th basis and $\\lambda_{\\ell}$ is the regularization\nparameter for the $\\ell$-th basis. As previously, the solution to this problem is given by the proximal operator of\n$\\sum_{\\ell=1}^{L}\\lambda_i \\|\\Psi_{\\ell} x\\|_1$. In this case however, the proximal operator is not available in closed\nform but can be computed numerically.\n\nA convenient algorithm in this situation is the Dykstra-like algorithm proposed by :footcite:t:`combettes2009iterative`, writing\n\n\\begin{align}\\begin{equation}\n    \\begin{aligned}\n    &\\text{For}\\;n=0,1,\\ldots \\\\\n    &\\quad x_{n+1} = \\sum_{\\ell=1}^L \\omega_{\\ell} \\operatorname{prox}_{g_\\ell}z_{\\ell,n}, \\\\\n    &\\quad \\text{For}\\;\\ell=1,\\ldots,L \\\\\n    &\\quad \\quad z_{\\ell,n+1} = x_{n+1} + z_{\\ell,n} - \\operatorname{prox}_{g_\\ell}z_{\\ell,n},\n    \\end{aligned}\n    \\end{equation}\\end{align}\n\n\nwhere $\\omega_{\\ell} = 1/L$ for all $\\ell$ and $g_{\\ell} = \\lambda_{\\ell} \\|\\Psi_{\\ell} \\cdot\\|_1$.\nIn turn, the sequence $(x_n)_{n\\in \\mathbb{N}}$ converges to the solution of the original problem.\nWe can implement it as follows. First, let's define the several proximity operators we'll need.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "list_wv = [\"haar\", \"db2\", \"db3\", \"db4\"]\nnon_linearity = \"soft\"\nlist_prox = nn.ModuleList(\n    [\n        dinv.models.wavdict.WaveletDenoiser(\n            level=3, wv=wv, non_linearity=non_linearity, wvdim=3\n        )\n        for wv in list_wv\n    ]\n)\n\n# Initialize the first element\nz_p = y.repeat(len(list_prox), *([1] * (len(y.shape))))\np_p = torch.zeros_like(z_p)\nx_cur = p_p.clone()\n\n# Average proximal step\nx_prev = x.clone()\nfor p in range(len(list_prox)):\n    p_p[p, ...] = list_prox[p](z_p[p, ...], ths)\nx_cur = torch.mean(p_p.clone(), axis=0)\n\n# Reflective step\nfor p in range(len(list_prox)):\n    z_p[p, ...] = x_cur + z_p[p, ...].clone() - p_p[p, ...]\n\n\n# Plot after one step\nlist_images = [x_cur[0, :, 90, :, :], x_cur[0, :, :, 108, :], x_cur[0, :, :, :, 90]]\ndinv.utils.plot(\n    list_images,\n    figsize=(6, 2),\n    suptitle=\"Denoised brain volume after one step\",\n    cmap=\"viridis\",\n    tight=False,\n    fontsize=12,\n)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Iterating the Dykstra-like algorithm.\nWe are now ready to iterate this algorithm.\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# Algorithm parameters\nmax_iter = 5  # Increase this number for better results\nths = noise_level_img * 2.0\n\n# Initialize the first element\nz_p = y.repeat(len(list_prox), *([1] * (len(y.shape))))\np_p = torch.zeros_like(z_p)\nx_cur = p_p.clone()\n\nfor it in range(max_iter):\n    # Average proximal step\n    x_prev = x_cur.clone()\n    for p in range(len(list_prox)):\n        p_p[p, ...] = list_prox[p](z_p[p, ...], ths)\n    x_cur = torch.mean(p_p.clone(), axis=0)\n\n    # Reflective step\n    for p in range(len(list_prox)):\n        z_p[p, ...] = x_cur + z_p[p, ...].clone() - p_p[p, ...]\n\n    # Relative criterion for convergence\n    rel_crit = torch.linalg.norm((x_cur - x_prev).flatten()) / torch.linalg.norm(\n        x_cur.flatten() + 1e-6\n    )\n\n\n# Compute the PSNR\npsnr = dinv.metric.PSNR()(x_cur, x).item()\n\n# Plot the output\nlist_images = [x_cur[0, :, 90, :, :], x_cur[0, :, :, 108, :], x_cur[0, :, :, :, 90]]\ndinv.utils.plot(\n    list_images,\n    figsize=(6, 2),\n    suptitle=f\"Denoised brain volume after 10 steps. PSNR = {psnr:.2f}dB\",\n    cmap=\"viridis\",\n    tight=False,\n    fontsize=12,\n)\n\n# sphinx_gallery_start_ignore\nassert psnr > 29.4\n# sphinx_gallery_end_ignore"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Using the Dykstra-like algorithm for wavelet denoising.\nYou can readily use this algorithm via the :class:`deepinv.models.WaveletDictDenoiser` class.\n\n::\n\n      y = physics(x)\n      model = dinv.models.WaveletDictDenoiser(list_wv=[\"db8\", \"db4\"], max_iter=10, non_linearity=\"soft\", wvdim=3)\n      xhat = model(y, ths)\n\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        ":References:\n\n.. footbibliography::\n\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}