{
  "cells": [
    {
      "id": "18efa1ec",
      "cell_type": "code",
      "metadata": {
        "language": "python"
      },
      "execution_count": null,
      "source": "# Install deepinv (skip if already installed)\n%pip install deepinv",
      "outputs": []
    },
    {
      "id": "d8989c00",
      "cell_type": "markdown",
      "source": "<!-- MathJax macro definitions inserted automatically -->\n$$\n\\newcommand{\\forw}[1]{{A\\left({#1}\\right)}}\n\\newcommand{\\noise}[1]{{N\\left({#1}\\right)}}\n\\newcommand{\\inverse}[1]{{R\\left({#1}\\right)}}\n\\newcommand{\\inversef}[2]{{R\\left({#1},{#2}\\right)}}\n\\newcommand{\\inversename}{R}\n\\newcommand{\\reg}[1]{{g_\\sigma\\left({#1}\\right)}}\n\\newcommand{\\regname}{g_\\sigma}\n\\newcommand{\\sensor}[1]{{\\eta\\left({#1}\\right)}}\n\\newcommand{\\datafid}[2]{{f\\left({#1},{#2}\\right)}}\n\\newcommand{\\datafidname}{f}\n\\newcommand{\\distance}[2]{{d\\left({#1},{#2}\\right)}}\n\\newcommand{\\distancename}{d}\n\\newcommand{\\denoiser}[2]{{\\operatorname{D}_{{#2}}\\left({#1}\\right)}}\n\\newcommand{\\denoisername}{\\operatorname{D}_{\\sigma}}\n\\newcommand{\\xset}{\\mathcal{X}}\n\\newcommand{\\yset}{\\mathcal{Y}}\n\\newcommand{\\group}{\\mathcal{G}}\n\\newcommand{\\metric}[2]{{d\\left({#1},{#2}\\right)}}\n\\newcommand{\\loss}[1]{{\\mathcal\\left({#1}\\right)}}\n\\newcommand{\\conj}[1]{{\\overline{#1}^{\\top}}}\n$$",
      "metadata": {
        "language": "markdown"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "language": "markdown"
      },
      "source": "\n# Image deblurring with custom deep explicit prior.\n\nIn this example, we show how to solve a deblurring inverse problem using an explicit prior.\n\nHere we use the simple L2 prior that penalizes the squared norm of the reconstruction, with an ADMM algorithm."
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "import deepinv as dinv\nfrom pathlib import Path\nimport torch\nfrom torch.utils.data import DataLoader\nfrom deepinv.optim.prior import Prior\nfrom deepinv.optim.data_fidelity import L2\nfrom deepinv.optim.optimizers import optim_builder\nfrom deepinv.training import test\nfrom torchvision import transforms\nfrom deepinv.utils import load_dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "language": "markdown"
      },
      "source": "## Setup paths for data loading and results.\n\n"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# Setup paths for data loading, results and checkpoints.\nBASE_DIR = Path(\".\")\nDATA_DIR = BASE_DIR / \"measurements\"\nRESULTS_DIR = BASE_DIR / \"results\"\nDEG_DIR = BASE_DIR / \"degradations\"\n\n# Set the global random seed from pytorch to ensure reproducibility of the example.\ntorch.manual_seed(0)\n\ndevice = dinv.utils.get_freer_gpu() if torch.cuda.is_available() else \"cpu\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "language": "markdown"
      },
      "source": "## Load base image datasets and degradation operators.\nIn this example, we use the CBSD68 dataset from the paper of Zhang et al. (2017) and the motion blur kernels from :footcite:t:`levin2009understanding`.\n\n"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# Set up the variable to fetch dataset and operators.\nmethod = \"L2_prior\"\ndataset_name = \"set3c\"\noperation = \"deblur\"\nimg_size = 256\nval_transform = transforms.Compose(\n    [transforms.CenterCrop(img_size), transforms.ToTensor()]\n)\ndataset = load_dataset(dataset_name, transform=val_transform)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "language": "markdown"
      },
      "source": "## Define physics operator\nWe use the [`deepinv.physics.BlurFFT`](https://deepinv.github.io/deepinv/api/stubs/deepinv.physics.BlurFFT.html) operator from the physics module to generate a dataset of blurred images.\nThe BlurFFT class performs the convolutions via the Fourier transform.\n\nIn this example, we choose a gaussian kernel with standard deviation 3, and we add a Gaussian noise with standard\ndeviation 0.03.\n"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# Generate a Gaussian blur filter.\nfilter_torch = dinv.physics.blur.gaussian_blur(sigma=(3, 3))\nnoise_level_img = 0.03  # Gaussian Noise standard deviation for the degradation\nn_channels = 3  # 3 for color images, 1 for gray-scale images\n\n# The BlurFFT instance from physics enables to compute efficently backward operators with Fourier transform.\np = dinv.physics.BlurFFT(\n    img_size=(n_channels, img_size, img_size),\n    filter=filter_torch,\n    device=device,\n    noise_model=dinv.physics.GaussianNoise(sigma=noise_level_img),\n)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "language": "markdown"
      },
      "source": "## Generate a dataset of blurred images\n"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# Use parallel dataloader if using a GPU to speed up training, otherwise, as all computes are on CPU, use synchronous\n# data loading.\nnum_workers = 4 if torch.cuda.is_available() else 0\nn_images_max = 3  # Maximal number of images to restore from the input dataset\n\nmeasurement_dir = DATA_DIR / dataset_name / operation\ndeepinv_dataset_path = dinv.datasets.generate_dataset(\n    train_dataset=dataset,\n    test_dataset=None,\n    physics=p,\n    device=device,\n    save_dir=measurement_dir,\n    train_datapoints=n_images_max,\n    num_workers=num_workers,\n)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "language": "markdown"
      },
      "source": "## Set up the optimization algorithm to solve the inverse problem.\nWe use the [`deepinv.optim.optim_builder`](https://deepinv.github.io/deepinv/api/stubs/deepinv.optim.optim_builder.html) function to instantiate the optimization algorithm.\n\nThe optimization algorithm is a proximal gradient descent algorithm that solves the following optimization problem:\n\n\\begin{align}\\min_{x} \\frac{1}{2} \\|y - Ax\\|_2^2 + \\lambda \\|x\\|_2^2\\end{align}\n\nwhere $A$ is the forward blurring operator, $y$ is the measurement\nand $\\lambda$ is a regularization parameter.\n\n"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# Create a custom prior which inherits from the base Prior class.\nclass L2Prior(Prior):\n    def __init__(self, *args, **kwargs):\n        super().__init__(*args, **kwargs)\n        self.explicit_prior = True\n\n    def fn(self, x, args, **kwargs):\n        return (\n            0.5 * torch.linalg.vector_norm(x, dim=tuple(range(1, x.dim())), ord=2) ** 2\n        )\n\n\n# Specify the custom prior\nprior = L2Prior()\n\n# Select the data fidelity term\ndata_fidelity = L2()\n\n# Specific parameters for restoration with the given prior (Note that these parameters have not been optimized here)\nparams_algo = {\"stepsize\": 1, \"lambda\": 0.1}\n\n# Logging parameters\nverbose = True\n\n# Parameters of the algorithm to solve the inverse problem\nearly_stop = True  # Stop algorithm when convergence criteria is reached\ncrit_conv = \"cost\"  # Convergence is reached when the difference of cost function between consecutive iterates is\n# smaller than thres_conv\nthres_conv = 1e-5\nbacktracking = False  # use backtraking to automatically adjust the stepsize\nmax_iter = 500  # Maximum number of iterations\n\n# Instantiate the algorithm class to solve the IP problem.\nmodel = optim_builder(\n    iteration=\"ADMM\",\n    prior=prior,\n    g_first=False,\n    data_fidelity=data_fidelity,\n    params_algo=params_algo,\n    early_stop=early_stop,\n    max_iter=max_iter,\n    crit_conv=crit_conv,\n    thres_conv=thres_conv,\n    backtracking=backtracking,\n    verbose=verbose,\n)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "language": "markdown"
      },
      "source": "## Evaluate the reconstruction algorithm on the problem.\n\nWe can use the [`deepinv.test`](https://deepinv.github.io/deepinv/api/stubs/deepinv.test.html) function to evaluate the reconstruction algorithm on a test set.\n"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "batch_size = 1\nplot_images = True  # plot results\nplot_convergence_metrics = True  # compute performance and convergence metrics along the algorithm, curves saved in RESULTS_DIR\n\n\ndataset = dinv.datasets.HDF5Dataset(path=deepinv_dataset_path, train=True)\ndataloader = DataLoader(\n    dataset, batch_size=batch_size, num_workers=num_workers, shuffle=False\n)\n\ntest(\n    model=model,\n    test_dataloader=dataloader,\n    physics=p,\n    device=device,\n    plot_images=plot_images,\n    save_folder=RESULTS_DIR / method / operation / dataset_name,\n    plot_convergence_metrics=plot_convergence_metrics,\n    verbose=verbose,\n)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "language": "markdown"
      },
      "source": ":References:\n\n> **Footbibliography**\n>\n>\n"
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}