{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n# Low-dose CT with ASTRA backend and Total-Variation (TV) prior\n\nThis example shows how to use the Astra tomography toolbox with deepinv, a popular toolbox for tomography with GPU acceleration.\n\nWe show how to use the :class:`deepinv.physics.TomographyWithAstra` operator (which wraps the [astra-toolbox](https://astra-toolbox.com/) backend) to solve a low-dose computed tomography problem with Total-Variation regularization.\n\n:class:`deepinv.physics.TomographyWithAstra` requires the astra-toolbox to function correctly, which can be easily installed using the command: `conda install -c astra-toolbox -c nvidia astra-toolbox`.\n\nAdditionally, this operator exclusively supports CUDA operations, so running the example requires a device with CUDA capabilities.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "import deepinv as dinv\nfrom pathlib import Path\nimport importlib\nimport torch\n\nfrom deepinv.optim.data_fidelity import L2\nfrom deepinv.optim.optimizers import optim_builder\nfrom deepinv.utils.plotting import plot, plot_curves\nfrom deepinv.utils import load_torch_url\nfrom deepinv.physics import LogPoissonNoise\nfrom deepinv.optim import LogPoissonLikelihood\n\nif importlib.util.find_spec(\"astra\") is not None:\n    from deepinv.physics import TomographyWithAstra\nelse:\n    raise ModuleNotFoundError(\n        \"The TomographyWithAstra operator runs with astra backend\"\n    )\n\ndevice = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n\nif device == \"cpu\":\n    raise RuntimeError(\n        \"The TomographyWithAstra operator only supports CUDA operations, got torch.cuda.is_available() = False\"\n    )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Setup paths for data loading and results.\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "BASE_DIR = Path(\".\")\nRESULTS_DIR = BASE_DIR / \"results\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Load training and test images\nHere, we use downsampled images from the [\"LoDoPaB-CT dataset\"](https://zenodo.org/records/3384092).\nMoreover, we define the size of the used patches and generate the dataset of patches in the training images.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "url = \"https://huggingface.co/datasets/deepinv/LoDoPaB-CT_toy/resolve/main/LoDoPaB-CT_small.pt\"\ndataset = load_torch_url(url)\ntest_imgs = dataset[\"test_imgs\"].to(device)\nimg_size = test_imgs.shape[-1]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Definition of forward operator and noise model\nThe training depends only on the image domain or prior distribution.\nFor the reconstruction, we now define forward operator and noise model.\nFor the noise model, we use log-Poisson noise as suggested for the LoDoPaB dataset.\nThen, we generate an observation by applying the physics and compute the filtered backprojection.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "mu = 1 / 50.0 * (362.0 / img_size)\nN0 = 1024.0\nnum_angles = 100\nnoise_model = LogPoissonNoise(mu=mu, N0=N0)\ndata_fidelity = LogPoissonLikelihood(mu=mu, N0=N0)\nphysics = TomographyWithAstra(\n    img_size=(img_size, img_size),\n    num_angles=num_angles,\n    device=device,\n    noise_model=noise_model,\n    geometry_type=\"fanbeam\",\n    num_detectors=2 * img_size,\n    geometry_parameters={\"source_radius\": 800.0, \"detector_radius\": 200.0},\n)\nobservation = physics(test_imgs)\nfbp = physics.A_dagger(observation)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Set up the optimization algorithm to solve the inverse problem.\nThe problem we want to minimize is the following:\n\n\\begin{align}\\begin{equation*}\n    \\underset{x}{\\operatorname{min}} \\,\\, \\frac{1}{2} \\|Ax-y\\|_2^2 + \\lambda \\|Dx\\|_{1,2}(x),\n    \\end{equation*}\\end{align}\n\n\nwhere $1/2 \\|A(x)-y\\|_2^2$ is the a data-fidelity term, $\\lambda \\|Dx\\|_{2,1}(x)$ is the total variation (TV)\nnorm of the image $x$, and $\\lambda>0$ is a regularisation parameters.\n\nWe use a Proximal Gradient Descent (PGD) algorithm to solve the inverse problem.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# Select the data fidelity term\ndata_fidelity = L2()\n\nprior = dinv.optim.prior.TVPrior(n_it_max=20)\n\n# Logging parameters\nverbose = True\nplot_convergence_metrics = (\n    True  # compute performance and convergence metrics along the algorithm.\n)\n\n# Algorithm parameters\nscaling = 1 / physics.compute_sqnorm(torch.rand_like(test_imgs)).item()\nstepsize = 0.99 * scaling\nlamb = 3.0  # TV regularisation parameter\nparams_algo = {\"stepsize\": stepsize, \"lambda\": lamb}\nmax_iter = 300\nearly_stop = True\n\n# Instantiate the algorithm class to solve the problem.\nmodel = optim_builder(\n    iteration=\"PGD\",\n    prior=prior,\n    data_fidelity=data_fidelity,\n    early_stop=early_stop,\n    max_iter=max_iter,\n    verbose=verbose,\n    params_algo=params_algo,\n    custom_init=lambda observation, physics: {\n        \"est\": (physics.A_dagger(observation), physics.A_dagger(observation))\n    },  # initialize the optimization with FBP reconstruction\n)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Evaluate the model on the problem and plot the results.\n\nThe model returns the output and the metrics computed along the iterations.\nThe PSNR is computed w.r.t the ground truth image in ``test_imgs``.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# run the model on the problem.\nx_model, metrics = model(\n    observation, physics, x_gt=test_imgs, compute_metrics=True\n)  # reconstruction with PGD algorithm\n\n# compute PSNR\nprint(\n    f\"Filtered Back-Projection PSNR: {dinv.metric.PSNR(max_pixel=test_imgs.max())(test_imgs, fbp).item():.2f} dB\"\n)\nprint(\n    f\"PGD reconstruction PSNR: {dinv.metric.PSNR(max_pixel=test_imgs.max())(test_imgs, x_model).item():.2f} dB\"\n)\n\n# plot images. Images are saved in RESULTS_DIR.\nimgs = [observation, test_imgs, fbp, x_model]\nplot(\n    imgs,\n    titles=[\"Noisy sinogram\", \"GT\", \"Filtered Back-Projection\", \"Recons.\"],\n    save_dir=RESULTS_DIR,\n)\n\n# plot convergence curves\nif plot_convergence_metrics:\n    plot_curves(metrics, save_dir=RESULTS_DIR)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}