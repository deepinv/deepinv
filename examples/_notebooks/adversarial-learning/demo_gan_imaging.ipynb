{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92ab411e",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "r\"\"\"\n",
    "Imaging inverse problems with adversarial networks\n",
    "==================================================\n",
    "\n",
    "This example shows you how to train various networks using adversarial\n",
    "training for deblurring problems. We demonstrate running training and\n",
    "inference using a conditional GAN (i.e. DeblurGAN), CSGM, AmbientGAN and\n",
    "UAIR implemented in the library, and how to simply train\n",
    "your own GAN by using :class:`deepinv.training.AdversarialTrainer`. These\n",
    "examples can also be easily extended to train more complicated GANs such\n",
    "as CycleGAN.\n",
    "\n",
    "This example is based on the papers DeblurGAN :footcite:p:`kupyn2018deblurgan`,\n",
    "Compressed Sensing using Generative Models (CSGM) :footcite:p:`bora2017compressed`,\n",
    "AmbiantGAN :footcite:p:`bora2018ambientgan`, and Unsupervised Adversarial Image Reconstruction (UAIR) :footcite:p:`pajot2019unsupervised`.\n",
    "\n",
    "Adversarial networks are characterized by the addition of an adversarial\n",
    "loss :math:`\\mathcal{L}_\\text{adv}` to the standard reconstruction loss:\n",
    "\n",
    ".. math:: \\mathcal{L}_\\text{adv}(x,\\hat x;D)=\\mathbb{E}_{x\\sim p_x}\\left[q(D(x))\\right]+\\mathbb{E}_{\\hat x\\sim p_{\\hat x}}\\left[q(1-D(\\hat x))\\right]\n",
    "\n",
    "where :math:`D(\\cdot)` is the discriminator model, :math:`x` is the\n",
    "reference image, :math:`\\hat x` is the estimated reconstruction,\n",
    ":math:`q(\\cdot)` is a quality function (e.g :math:`q(x)=x` for WGAN).\n",
    "Training alternates between generator :math:`G` and discriminator\n",
    ":math:`D` in a minimax game. When there are no ground truths (i.e.\n",
    "unsupervised), this may be defined on the measurements :math:`y`\n",
    "instead.\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "from pathlib import Path\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "from torchvision.transforms import Compose, ToTensor, CenterCrop, Resize\n",
    "\n",
    "import deepinv as dinv\n",
    "from deepinv.loss import adversarial\n",
    "from deepinv.utils import get_data_home\n",
    "from deepinv.physics.generator import MotionBlurGenerator\n",
    "\n",
    "device = dinv.utils.get_freer_gpu() if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "BASE_DIR = Path(\".\")\n",
    "DATA_DIR = BASE_DIR / \"measurments\"\n",
    "ORGINAL_DATA_DIR = get_data_home() / \"Urban100\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83088c28",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "# Generate dataset\n",
    "# ~~~~~~~~~~~~~~~~\n",
    "# In this example we use the Urban100 dataset resized to 128x128. We apply random\n",
    "# motion blur physics using\n",
    "# :class:`deepinv.physics.generator.MotionBlurGenerator`, and save the data\n",
    "# using :func:`deepinv.datasets.generate_dataset`.\n",
    "#\n",
    "\n",
    "physics = dinv.physics.Blur(padding=\"circular\", device=device)\n",
    "blur_generator = MotionBlurGenerator((11, 11), device=device)\n",
    "\n",
    "dataset = dinv.datasets.Urban100HR(\n",
    "    root=ORGINAL_DATA_DIR,\n",
    "    download=True,\n",
    "    transform=Compose([ToTensor(), Resize(256), CenterCrop(128)]),\n",
    ")\n",
    "\n",
    "train_dataset, test_dataset = random_split(dataset, (0.8, 0.2))\n",
    "\n",
    "# Generate data pairs x,y offline using a physics generator\n",
    "dataset_path = dinv.datasets.generate_dataset(\n",
    "    train_dataset=train_dataset,\n",
    "    test_dataset=test_dataset,\n",
    "    physics=physics,\n",
    "    physics_generator=blur_generator,\n",
    "    device=device,\n",
    "    save_dir=DATA_DIR,\n",
    "    batch_size=1,\n",
    ")\n",
    "\n",
    "train_dataloader = DataLoader(\n",
    "    dinv.datasets.HDF5Dataset(\n",
    "        dataset_path, train=True, load_physics_generator_params=True\n",
    "    ),\n",
    "    shuffle=True,\n",
    ")\n",
    "test_dataloader = DataLoader(\n",
    "    dinv.datasets.HDF5Dataset(\n",
    "        dataset_path, train=False, load_physics_generator_params=True\n",
    "    ),\n",
    "    shuffle=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dbf7f12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define models\n",
    "# ~~~~~~~~~~~~~\n",
    "#\n",
    "# We first define reconstruction network (i.e conditional generator) and\n",
    "# discriminator network to use for adversarial training. For demonstration\n",
    "# we use a simple U-Net as the reconstruction network and the\n",
    "# discriminator from PatchGAN :footcite:p:`isola2017image`, but\n",
    "# these can be replaced with any architecture e.g transformers, unrolled\n",
    "# etc. Further discriminator models are in :ref:`adversarial models <adversarial>`.\n",
    "#\n",
    "\n",
    "\n",
    "def get_models(model=None, D=None, lr_g=1e-4, lr_d=1e-4, device=device):\n",
    "    if model is None:\n",
    "        model = dinv.models.UNet(\n",
    "            in_channels=3,\n",
    "            out_channels=3,\n",
    "            scales=2,\n",
    "            circular_padding=True,\n",
    "            batch_norm=False,\n",
    "        ).to(device)\n",
    "\n",
    "    if D is None:\n",
    "        D = dinv.models.PatchGANDiscriminator(n_layers=2, batch_norm=False).to(device)\n",
    "\n",
    "    optimizer = dinv.training.adversarial.AdversarialOptimizer(\n",
    "        torch.optim.Adam(model.parameters(), lr=lr_g, weight_decay=1e-8),\n",
    "        torch.optim.Adam(D.parameters(), lr=lr_d, weight_decay=1e-8),\n",
    "    )\n",
    "    scheduler = dinv.training.adversarial.AdversarialScheduler(\n",
    "        torch.optim.lr_scheduler.StepLR(optimizer.G, step_size=5, gamma=0.9),\n",
    "        torch.optim.lr_scheduler.StepLR(optimizer.D, step_size=5, gamma=0.9),\n",
    "    )\n",
    "\n",
    "    return model, D, optimizer, scheduler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72b2386d",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "# Conditional GAN training\n",
    "# ~~~~~~~~~~~~~~~~~~~~~~~~\n",
    "#\n",
    "# Conditional GANs :footcite:p:`kupyn2018deblurgan` are a type of GAN where the generator is conditioned on a label or input.\n",
    "# In the context of imaging, this can be used to generate images from a given measurement.\n",
    "# In this example, we use a simple U-Net as the generator\n",
    "# and a PatchGAN discriminator. The forward pass of the generator is given by:\n",
    "#\n",
    "# **Conditional GAN** forward pass:\n",
    "#\n",
    "# .. math:: \\hat x = G(y)\n",
    "#\n",
    "# **Conditional GAN** loss:\n",
    "#\n",
    "# .. math:: \\mathcal{L}=\\mathcal{L}_\\text{sup}(\\hat x, x)+\\mathcal{L}_\\text{adv}(\\hat x, x;D)\n",
    "#\n",
    "# where :math:`\\mathcal{L}_\\text{sup}` is a supervised loss such as\n",
    "# pixel-wise MSE or VGG Perceptual Loss.\n",
    "#\n",
    "\n",
    "G, D, optimizer, scheduler = get_models()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e501e2e8",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "# We next define pixel-wise and adversarial losses as defined above. We use the\n",
    "# MSE for the supervised pixel-wise metric for simplicity but this can be\n",
    "# easily replaced with a perceptual loss if desired.\n",
    "#\n",
    "\n",
    "loss_g = [\n",
    "    dinv.loss.SupLoss(metric=torch.nn.MSELoss()),\n",
    "    adversarial.SupAdversarialGeneratorLoss(device=device),\n",
    "]\n",
    "loss_d = adversarial.SupAdversarialDiscriminatorLoss(device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "003977bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We are now ready to train the networks using :class:`deepinv.training.AdversarialTrainer`.\n",
    "# We load the pretrained models that were trained in the exact same way after 50 epochs,\n",
    "# and fine-tune the model for 1 epoch for a quick demo.\n",
    "# You can find the pretrained models on HuggingFace https://huggingface.co/deepinv/adversarial-demo.\n",
    "# To train from scratch, simply comment out the model loading code and increase the number of epochs.\n",
    "#\n",
    "\n",
    "ckpt = torch.hub.load_state_dict_from_url(\n",
    "    dinv.models.utils.get_weights_url(\"adversarial-demo\", \"deblurgan_model.pth\"),\n",
    "    map_location=lambda s, _: s,\n",
    ")\n",
    "\n",
    "G.load_state_dict(ckpt[\"state_dict\"])\n",
    "D.load_state_dict(ckpt[\"state_dict_D\"])\n",
    "optimizer.load_state_dict(ckpt[\"optimizer\"])\n",
    "\n",
    "trainer = dinv.training.AdversarialTrainer(\n",
    "    model=G,\n",
    "    D=D,\n",
    "    physics=physics,\n",
    "    train_dataloader=train_dataloader,\n",
    "    eval_dataloader=test_dataloader,\n",
    "    epochs=1,\n",
    "    losses=loss_g,\n",
    "    losses_d=loss_d,\n",
    "    optimizer=optimizer,\n",
    "    scheduler=scheduler,\n",
    "    verbose=True,\n",
    "    show_progress_bar=False,\n",
    "    save_path=None,\n",
    "    device=device,\n",
    ")\n",
    "\n",
    "G = trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bec67be",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "# Test the trained model and plot the results. We compare to the pseudo-inverse as a baseline.\n",
    "#\n",
    "\n",
    "trainer.plot_images = True\n",
    "trainer.test(test_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60cf06dc",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "# UAIR training\n",
    "# ~~~~~~~~~~~~~\n",
    "#\n",
    "# Unsupervised Adversarial Image Reconstruction (UAIR) :footcite:p:`pajot2019unsupervised`\n",
    "# is a method for solving inverse problems using generative models. In this\n",
    "# example, we use a simple U-Net as the generator and discriminator, and\n",
    "# train using the adversarial loss. The forward pass of the generator is defined as:\n",
    "#\n",
    "# **UAIR** forward pass:\n",
    "#\n",
    "# .. math:: \\hat x = G(y),\n",
    "#\n",
    "# **UAIR** loss:\n",
    "#\n",
    "# .. math:: \\mathcal{L}=\\mathcal{L}_\\text{adv}(\\hat y, y;D)+\\lVert \\forw{\\inverse{\\hat y}}- \\hat y\\rVert^2_2,\\quad\\hat y=\\forw{\\hat x}.\n",
    "#\n",
    "# We next load the models and construct losses as defined above.\n",
    "\n",
    "G, D, optimizer, scheduler = get_models(\n",
    "    lr_g=1e-4, lr_d=4e-4\n",
    ")  # learning rates from original paper\n",
    "\n",
    "loss_g = adversarial.UAIRGeneratorLoss(device=device)\n",
    "loss_d = adversarial.UnsupAdversarialDiscriminatorLoss(device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50d54669",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We are now ready to train the networks using :class:`deepinv.training.AdversarialTrainer`.\n",
    "# Like above, we load a pretrained model trained in the exact same way for 50 epochs,\n",
    "# and fine-tune here for a quick demo with 1 epoch.\n",
    "#\n",
    "\n",
    "ckpt = torch.hub.load_state_dict_from_url(\n",
    "    dinv.models.utils.get_weights_url(\"adversarial-demo\", \"uair_model.pth\"),\n",
    "    map_location=lambda s, _: s,\n",
    ")\n",
    "\n",
    "G.load_state_dict(ckpt[\"state_dict\"])\n",
    "D.load_state_dict(ckpt[\"state_dict_D\"])\n",
    "optimizer.load_state_dict(ckpt[\"optimizer\"])\n",
    "\n",
    "trainer = dinv.training.AdversarialTrainer(\n",
    "    model=G,\n",
    "    D=D,\n",
    "    physics=physics,\n",
    "    train_dataloader=train_dataloader,\n",
    "    eval_dataloader=test_dataloader,\n",
    "    epochs=1,\n",
    "    losses=loss_g,\n",
    "    losses_d=loss_d,\n",
    "    optimizer=optimizer,\n",
    "    scheduler=scheduler,\n",
    "    verbose=True,\n",
    "    show_progress_bar=False,\n",
    "    save_path=None,\n",
    "    device=device,\n",
    ")\n",
    "G = trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f3a789d",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "# Test the trained model and plot the results:\n",
    "#\n",
    "\n",
    "trainer.plot_images = True\n",
    "trainer.test(test_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bec891f9",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "# CSGM / AmbientGAN training\n",
    "# ~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
    "#\n",
    "# Compressed Sensing using Generative Models (CSGM) :footcite:p:`bora2017compressed` and AmbientGAN :footcite:p:`bora2018ambientgan` are two methods for solving inverse problems\n",
    "# using generative models. CSGM uses a generative model to solve the inverse problem by optimising the latent\n",
    "# space of the generator. AmbientGAN uses a generative model to solve the inverse problem by optimising the\n",
    "# measurements themselves. Both methods are trained using an adversarial loss; the main difference is that CSGM requires\n",
    "# a ground truth dataset (supervised loss), while AmbientGAN does not (unsupervised loss).\n",
    "#\n",
    "# In this example, we use a DCGAN as the\n",
    "# generator and discriminator, and train using the adversarial loss. The forward pass of the generator is given by:\n",
    "#\n",
    "# **CSGM** forward pass at train time:\n",
    "#\n",
    "# .. math:: \\hat x = \\inverse{z},\\quad z\\sim \\mathcal{N}(\\mathbf{0},\\mathbf{I}_k)\n",
    "#\n",
    "# **CSGM**/**AmbientGAN** forward pass at eval time:\n",
    "#\n",
    "# .. math:: \\hat x = \\inverse{\\hat z}\\quad\\text{s.t.}\\quad\\hat z=\\operatorname*{argmin}_z \\lVert \\forw{\\inverse{z}}-y\\rVert _2^2\n",
    "#\n",
    "# **CSGM** loss:\n",
    "#\n",
    "# .. math:: \\mathcal{L}=\\mathcal{L}_\\text{adv}(\\hat x, x;D)\n",
    "#\n",
    "# **AmbientGAN** loss (where :math:`\\forw{\\cdot}` is the physics):\n",
    "#\n",
    "# .. math:: \\mathcal{L}=\\mathcal{L}_\\text{adv}(\\forw{\\hat x}, y;D)\n",
    "#\n",
    "# We next load the models and construct losses as defined above.\n",
    "\n",
    "G = dinv.models.CSGMGenerator(\n",
    "    dinv.models.DCGANGenerator(output_size=128, nz=100, ngf=32), inf_tol=1e-2\n",
    ").to(device)\n",
    "D = dinv.models.DCGANDiscriminator(ndf=32).to(device)\n",
    "_, _, optimizer, scheduler = get_models(\n",
    "    model=G, D=D, lr_g=2e-4, lr_d=2e-4\n",
    ")  # learning rates from original paper\n",
    "\n",
    "# For AmbientGAN:\n",
    "loss_g = adversarial.UnsupAdversarialGeneratorLoss(device=device)\n",
    "loss_d = adversarial.UnsupAdversarialDiscriminatorLoss(device=device)\n",
    "\n",
    "# For CSGM:\n",
    "loss_g = adversarial.SupAdversarialGeneratorLoss(device=device)\n",
    "loss_d = adversarial.SupAdversarialDiscriminatorLoss(device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88f82cc5",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "# As before, we can now train our models. Since inference is very\n",
    "# slow for CSGM/AmbientGAN as it requires an optimisation, we only do one\n",
    "# evaluation at the end. Note the train PSNR is meaningless as this\n",
    "# generative model is trained on random latents.\n",
    "# Like above, we load a pretrained model trained in the exact same way for 50 epochs,\n",
    "# and fine-tune here for a quick demo with 1 epoch.\n",
    "#\n",
    "\n",
    "ckpt = torch.hub.load_state_dict_from_url(\n",
    "    dinv.models.utils.get_weights_url(\"adversarial-demo\", \"csgm_model.pth\"),\n",
    "    map_location=lambda s, _: s,\n",
    ")\n",
    "\n",
    "G.load_state_dict(ckpt[\"state_dict\"])\n",
    "D.load_state_dict(ckpt[\"state_dict_D\"])\n",
    "optimizer.load_state_dict(ckpt[\"optimizer\"])\n",
    "\n",
    "trainer = dinv.training.AdversarialTrainer(\n",
    "    model=G,\n",
    "    D=D,\n",
    "    physics=physics,\n",
    "    train_dataloader=train_dataloader,\n",
    "    epochs=1,\n",
    "    losses=loss_g,\n",
    "    losses_d=loss_d,\n",
    "    optimizer=optimizer,\n",
    "    scheduler=scheduler,\n",
    "    verbose=True,\n",
    "    show_progress_bar=False,\n",
    "    save_path=None,\n",
    "    device=device,\n",
    ")\n",
    "G = trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3ad59ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Eventually, we run evaluation of the generative model by running test-time optimisation\n",
    "# using test measurements. Note that we do not get great results as CSGM /\n",
    "# AmbientGAN relies on large datasets of diverse samples, and we run the\n",
    "# optimisation to a relatively high tolerance for speed. Improve the results by\n",
    "# running the optimisation for longer.\n",
    "#\n",
    "\n",
    "trainer.test(test_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9671fc31",
   "metadata": {},
   "outputs": [],
   "source": [
    "# :References:\n",
    "#\n",
    "# .. footbibliography::"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
