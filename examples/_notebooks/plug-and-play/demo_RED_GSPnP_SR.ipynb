{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n# Regularization by Denoising (RED) for Super-Resolution.\n\nImplementation of :footcite:t:`romano2017little` using as plug-in denoiser the Gradient-Step Denoiser (GSPnP) :footcite:t:`hurault2021gradient` which provides an explicit prior.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "import deepinv as dinv\nfrom pathlib import Path\nimport torch\nfrom torch.utils.data import DataLoader\nfrom deepinv.optim.data_fidelity import L2\nfrom deepinv.optim.prior import RED\nfrom deepinv.optim.optimizers import optim_builder\nfrom deepinv.training import test\nfrom torchvision import transforms\nfrom deepinv.utils.parameters import get_GSPnP_params\nfrom deepinv.utils import load_dataset, load_degradation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Setup paths for data loading and results.\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "BASE_DIR = Path(\".\")\nDATA_DIR = BASE_DIR / \"measurements\"\nRESULTS_DIR = BASE_DIR / \"results\"\nDEG_DIR = BASE_DIR / \"degradations\"\n\n# Set the global random seed from pytorch to ensure\n# the reproducibility of the example.\ntorch.manual_seed(0)\ndevice = dinv.utils.get_freer_gpu() if torch.cuda.is_available() else \"cpu\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Load base image datasets and degradation operators.\nIn this example, we use the Set3C dataset and a motion blur kernel from :footcite:t:`levin2009understanding`.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "dataset_name = \"set3c\"\nimg_size = 256 if torch.cuda.is_available() else 32\noperation = \"super-resolution\"\nval_transform = transforms.Compose(\n    [transforms.CenterCrop(img_size), transforms.ToTensor()]\n)\ndataset = load_dataset(dataset_name, transform=val_transform)\n\n# Generate the degradation operator.\nkernel_index = 1\nkernel_torch = load_degradation(\n    \"kernels_12.npy\", DEG_DIR / \"kernels\", index=kernel_index\n)\nkernel_torch = kernel_torch.unsqueeze(0).unsqueeze(\n    0\n)  # add batch and channel dimensions\n\n# Use parallel dataloader if using a GPU to speed up training, otherwise, as all computes are on CPU, use synchronous dataloading.\nnum_workers = 4 if torch.cuda.is_available() else 0\n\nfactor = 2  # down-sampling factor\nn_channels = 3  # 3 for color images, 1 for gray-scale images\nn_images_max = 3  # Maximal number of images to restore from the input dataset\nnoise_level_img = 0.03  # Gaussian Noise standard deviation for the degradation\np = dinv.physics.Downsampling(\n    img_size=(n_channels, img_size, img_size),\n    factor=factor,\n    filter=kernel_torch,\n    device=device,\n    noise_model=dinv.physics.GaussianNoise(sigma=noise_level_img),\n)\n\n# Generate a dataset in a HDF5 folder in \"{dir}/dinv_dataset0.h5'\" and load it.\nmeasurement_dir = DATA_DIR / dataset_name / operation\ndinv_dataset_path = dinv.datasets.generate_dataset(\n    train_dataset=dataset,\n    test_dataset=None,\n    physics=p,\n    device=device,\n    save_dir=measurement_dir,\n    train_datapoints=n_images_max,\n    num_workers=num_workers,\n)\ndataset = dinv.datasets.HDF5Dataset(path=dinv_dataset_path, train=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Setup the PnP algorithm. This involves in particular the definition of a custom prior class.\nWe use the proximal gradient algorithm to solve the super-resolution problem with GSPnP.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# Parameters of the algorithm to solve the inverse problem\nearly_stop = True  # Stop algorithm when convergence criteria is reached\ncrit_conv = \"cost\"  # Convergence is reached when the difference of cost function between consecutive iterates is\n# smaller than thres_conv\nthres_conv = 1e-5\nbacktracking = True\nuse_bicubic_init = False  # Use bicubic interpolation to initialize the algorithm\nbatch_size = 1  # batch size for evaluation is necessarily 1 for early stopping and backtracking to work.\n\n# load specific parameters for GSPnP\nlamb, sigma_denoiser, stepsize, max_iter = get_GSPnP_params(operation, noise_level_img)\n\nparams_algo = {\n    \"stepsize\": stepsize,\n    \"g_param\": sigma_denoiser,\n    \"lambda\": lamb,\n}\n\n# Select the data fidelity term\ndata_fidelity = L2()\n\n\n# The GSPnP prior corresponds to a RED prior with an explicit `g`.\n# We thus write a class that inherits from RED for this custom prior.\nclass GSPnP(RED):\n    r\"\"\"\n    Gradient-Step Denoiser prior.\n    \"\"\"\n\n    def __init__(self, *args, **kwargs):\n        super().__init__(*args, **kwargs)\n        self.explicit_prior = True\n\n    def forward(self, x, *args, **kwargs):\n        r\"\"\"\n        Computes the prior :math:`g(x)`.\n\n        :param torch.tensor x: Variable :math:`x` at which the prior is computed.\n        :return: (torch.tensor) prior :math:`g(x)`.\n        \"\"\"\n        return self.denoiser.potential(x, *args, **kwargs)\n\n\nmethod = \"GSPnP\"\ndenoiser_name = \"gsdrunet\"\n# Specify the Denoising prior\nprior = GSPnP(denoiser=dinv.models.GSDRUNet(pretrained=\"download\").to(device))\n\n\n# we want to output the intermediate PGD update to finish with a denoising step.\ndef custom_output(X):\n    return X[\"est\"][1]\n\n\n# instantiate the algorithm class to solve the IP problem.\nmodel = optim_builder(\n    iteration=\"PGD\",\n    prior=prior,\n    g_first=True,\n    data_fidelity=data_fidelity,\n    params_algo=params_algo,\n    early_stop=early_stop,\n    max_iter=max_iter,\n    crit_conv=crit_conv,\n    thres_conv=thres_conv,\n    backtracking=backtracking,\n    get_output=custom_output,\n    verbose=False,\n)\n\n# Set the model to evaluation mode. We do not require training here.\nmodel.eval()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Evaluate the model on the problem.\nWe evaluate the PnP algorithm on the test dataset, compute the PSNR metrics and plot reconstruction results.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "save_folder = RESULTS_DIR / method / operation / dataset_name\nplot_convergence_metrics = True  # plot metrics. Metrics are saved in save_folder.\nplot_images = True  # plot images. Images are saved in save_folder.\n\ndataloader = DataLoader(\n    dataset, batch_size=batch_size, num_workers=num_workers, shuffle=False\n)\n\ntest(\n    model=model,\n    test_dataloader=dataloader,\n    physics=p,\n    device=device,\n    plot_images=plot_images,\n    save_folder=RESULTS_DIR / method / operation / dataset_name,\n    plot_convergence_metrics=plot_convergence_metrics,\n    verbose=True,\n)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        ":References:\n\n.. footbibliography::\n\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}