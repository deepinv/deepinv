{
  "cells": [
    {
      "id": "d548bafc",
      "cell_type": "code",
      "metadata": {
        "language": "python"
      },
      "execution_count": null,
      "source": "# Install deepinv (skip if already installed)\n%pip install deepinv",
      "outputs": []
    },
    {
      "id": "317b253f",
      "cell_type": "markdown",
      "source": "<!-- MathJax macro definitions inserted automatically -->\n$$\n\\newcommand{\\forw}[1]{{A\\left({#1}\\right)}}\n\\newcommand{\\noise}[1]{{N\\left({#1}\\right)}}\n\\newcommand{\\inverse}[1]{{R\\left({#1}\\right)}}\n\\newcommand{\\inversef}[2]{{R\\left({#1},{#2}\\right)}}\n\\newcommand{\\inversename}{R}\n\\newcommand{\\reg}[1]{{g_\\sigma\\left({#1}\\right)}}\n\\newcommand{\\regname}{g_\\sigma}\n\\newcommand{\\sensor}[1]{{\\eta\\left({#1}\\right)}}\n\\newcommand{\\datafid}[2]{{f\\left({#1},{#2}\\right)}}\n\\newcommand{\\datafidname}{f}\n\\newcommand{\\distance}[2]{{d\\left({#1},{#2}\\right)}}\n\\newcommand{\\distancename}{d}\n\\newcommand{\\denoiser}[2]{{\\operatorname{D}_{{#2}}\\left({#1}\\right)}}\n\\newcommand{\\denoisername}{\\operatorname{D}_{\\sigma}}\n\\newcommand{\\xset}{\\mathcal{X}}\n\\newcommand{\\yset}{\\mathcal{Y}}\n\\newcommand{\\group}{\\mathcal{G}}\n\\newcommand{\\metric}[2]{{d\\left({#1},{#2}\\right)}}\n\\newcommand{\\loss}[1]{{\\mathcal\\left({#1}\\right)}}\n\\newcommand{\\conj}[1]{{\\overline{#1}^{\\top}}}\n$$",
      "metadata": {
        "language": "markdown"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "language": "markdown"
      },
      "source": "\n# PnP with custom optimization algorithm (Condat-Vu Primal-Dual)\n\nThis example shows how to define your own optimization algorithm.\nFor example, here, we implement the Condat-Vu Primal-Dual algorithm,\nand apply it for Single Pixel Camera reconstruction."
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "import deepinv as dinv\nfrom pathlib import Path\nimport torch\nfrom deepinv.models import DnCNN\nfrom deepinv.optim.data_fidelity import L2\nfrom deepinv.optim.prior import PnP\nfrom deepinv.optim.optimizers import optim_builder\nfrom deepinv.utils import load_example\nfrom deepinv.utils.plotting import plot, plot_curves\nfrom deepinv.optim.optim_iterators import OptimIterator, fStep, gStep"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "language": "markdown"
      },
      "source": "## Define a custom optimization algorithm\nCreating your optimization algorithm only requires the definition of an iteration step.\nThe iterator should be a subclass of [`deepinv.optim.OptimIterator`](https://deepinv.github.io/deepinv/api/stubs/deepinv.optim.OptimIterator.html).\n\nThe Condat-Vu Primal-Dual algorithm is defined as follows:\n\n\\begin{align}\\begin{align*}\n        v_k &= x_k-\\tau A^\\top z_k \\\\\n        x_{k+1} &= \\operatorname{prox}_{\\tau g}(v_k) \\\\\n        u_k &= z_k + \\sigma A(2x_{k+1}-x_k) \\\\\n        z_{k+1} &= \\operatorname{prox}_{\\sigma f^*}(u_k)\n        \\end{align*}\\end{align}\n\nwhere $f^*$ is the Fenchel-Legendre conjugate of $f$.\n"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "class CVIteration(OptimIterator):\n    r\"\"\"\n    Single iteration of Condat-Vu Primal-Dual.\n    \"\"\"\n\n    def __init__(self, **kwargs):\n        super().__init__(**kwargs)\n        self.g_step = gStepCV(**kwargs)\n        self.f_step = fStepCV(**kwargs)\n\n    def forward(self, X, cur_data_fidelity, cur_prior, cur_params, y, physics):\n        r\"\"\"\n        Single iteration of the Condat-Vu algorithm.\n\n        :param dict X: Dictionary containing the current iterate and the estimated cost.\n        :param deepinv.optim.DataFidelity cur_data_fidelity: Instance of the DataFidelity class defining the current data_fidelity.\n        :param dict cur_prior: dictionary containing the prior-related term of interest,\n            e.g. its proximal operator or gradient.\n        :param dict cur_params: dictionary containing the current parameters of the model.\n        :param torch.Tensor y: Input data.\n        :param deepinv.physics physics: Instance of the physics modeling the data-fidelity term.\n        :return: Dictionary `{\"est\": (x,z), \"cost\": F}` containing the updated current iterate\n            and the estimated current cost.\n        \"\"\"\n        x_prev, z_prev = X[\"est\"]\n        v = x_prev - cur_params[\"stepsize\"] * physics.A_adjoint(z_prev)\n        x = self.g_step(v, cur_prior, cur_params)\n        u = z_prev + cur_params[\"stepsize\"] * physics.A(2 * x - x_prev)\n        z = self.f_step(u, cur_data_fidelity, cur_params, y, physics)\n        F = (\n            self.F_fn(x, cur_data_fidelity, cur_params, y, physics)\n            if self.has_cost\n            else None\n        )\n        return {\"est\": (x, z), \"cost\": F}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "language": "markdown"
      },
      "source": "## Define the custom fStep and gStep modules\nThe iterator relies on custom fStepCV (subclass of [`deepinv.optim.optim_iterators.fStep`](https://deepinv.github.io/deepinv/api/stubs/deepinv.optim.optim_iterators.fStep.html))\nand gStepCV (subclass of [`deepinv.optim.optim_iterators.gStep`](https://deepinv.github.io/deepinv/api/stubs/deepinv.optim.optim_iterators.gStep.html)) modules.\n\nIn this case the fStep module is defined as follows:\n\n\\begin{align}u_{k+1} = \\operatorname{prox}_{\\sigma f^*}(u_k)\\end{align}\n\nwhere $f^*$ is the Fenchel-Legendre conjugate of $f$.\nThe proximal operator of $f^*$ is computed using the proximal operator\nof $f$ via Moreau's identity,\nand the gStep module is a simple proximal step on the prior term $\\lambda g$:\n\n\\begin{align}x_{k+1} = \\operatorname{prox}_{\\tau \\lambda g}(v_k)\\end{align}\n\n"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "class fStepCV(fStep):\n    r\"\"\"\n    Condat-Vu fStep module to compute :math:`\\operatorname{prox}_{\\sigma f^*}(z_k)``\n    \"\"\"\n\n    def __init__(self, **kwargs):\n        super().__init__(**kwargs)\n\n    def forward(self, u, cur_data_fidelity, cur_params, y, phyics):\n        r\"\"\"\n        Single iteration on the data-fidelity term :math:`f`.\n\n        :param torch.Tensor z: Current iterate :math:`z_k = 2Ax_{k+1}-x_k`\n        :param deepinv.optim.DataFidelity cur_data_fidelity: Instance of the DataFidelity class defining the current data_fidelity.\n        :param dict cur_params: Dictionary containing the current fStep parameters (keys `\"stepsize\"` and `\"lambda\"`).\n        :param torch.Tensor y: Input data.\n        :param deepinv.physics physics: Instance of the physics modeling the data-fidelity term.\n        \"\"\"\n        return cur_data_fidelity.d.prox_conjugate(u, y, gamma=cur_params[\"sigma\"])\n\n\nclass gStepCV(gStep):\n    r\"\"\"\n    Condat-Vu gStep module to compute :math:`\\operatorname{prox}_{\\tau g}(v_k)`\n    \"\"\"\n\n    def __init__(self, **kwargs):\n        super().__init__(**kwargs)\n\n    def forward(self, v, cur_prior, cur_params):\n        r\"\"\"\n        Single iteration step on the prior term :math:`\\lambda g`.\n\n        :param torch.Tensor x: Current iterate :math:`v_k = x_k-\\tau A^\\top u_k`.\n        :param dict cur_prior: Dictionary containing the current prior.\n        :param dict cur_params: Dictionary containing the current gStep parameters\n            (keys `\"stepsize\"` and `\"g_param\"`).\n        \"\"\"\n        return cur_prior.prox(\n            v,\n            cur_params[\"g_param\"],\n            gamma=cur_params[\"lambda\"] * cur_params[\"stepsize\"],\n        )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "language": "markdown"
      },
      "source": "## Setup paths for data loading and results.\n\n"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "BASE_DIR = Path(\".\")\nRESULTS_DIR = BASE_DIR / \"results\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "language": "markdown"
      },
      "source": "## Load base image datasets and degradation operators.\n"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# Set the global random seed from pytorch to ensure reproducibility of the example.\ntorch.manual_seed(0)\n\ndevice = dinv.utils.get_freer_gpu() if torch.cuda.is_available() else \"cpu\"\n\n# Set up the variable to fetch dataset and operators.\nmethod = \"PnP\"\ndataset_name = \"set3c\"\nimg_size = 64\n\nx = load_example(\n    \"barbara.jpeg\",\n    img_size=img_size,\n    grayscale=True,\n    resize_mode=\"resize\",\n    device=device,\n)\noperation = \"single_pixel\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "language": "markdown"
      },
      "source": "## Set the forward operator\nWe use the [`deepinv.physics.SinglePixelCamera`](https://deepinv.github.io/deepinv/api/stubs/deepinv.physics.SinglePixelCamera.html)\nclass from the physics module to generate a single-pixel measurements.\nThe forward operator consists of the multiplication with the low frequencies of the Hadamard transform.\n"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "noise_level_img = 0.03  # Gaussian Noise standard deviation for the degradation\nn_channels = 1  # 3 for color images, 1 for gray-scale images\nphysics = dinv.physics.SinglePixelCamera(\n    m=600,\n    img_size=(1, 64, 64),\n    ordering=\"cake_cutting\",\n    noise_model=dinv.physics.GaussianNoise(sigma=noise_level_img),\n    device=device,\n)\n\n# Use parallel dataloader if using a GPU to speed up training,\n# otherwise, as all computes are on CPU, use synchronous data loading.\nnum_workers = 4 if torch.cuda.is_available() else 0"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "language": "markdown"
      },
      "source": "## Set up the PnP algorithm to solve the inverse problem.\nWe build the PnP model using the [`deepinv.optim.optim_builder`](https://deepinv.github.io/deepinv/api/stubs/deepinv.optim.optim_builder.html) function,\nand setting the iterator to our custom CondatVu algorithm.\n\nThe primal dual stepsizes $\\tau$ corresponds to the ``stepsize`` key and $\\sigma$ to the ``sigma`` key.\nThe ``g_param`` key corresponds to the noise level of the denoiser.\n\nFor the denoiser, we choose the 1-Lipschitz grayscale DnCNN model (see the pretrained-weights).\n\n"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# Set up the PnP algorithm parameters :\nparams_algo = {\"stepsize\": 0.99, \"g_param\": 0.01, \"sigma\": 0.99}\nmax_iter = 200\nearly_stop = True  # stop the algorithm when convergence is reached\n\n# Select the data fidelity term\ndata_fidelity = L2()\n\n# Specify the denoising prior\ndenoiser = DnCNN(\n    in_channels=n_channels,\n    out_channels=n_channels,\n    pretrained=\"download_lipschitz\",\n    device=device,\n)\nprior = PnP(denoiser=denoiser)\n\n# instantiate the algorithm class to solve the IP problem.\niteration = CVIteration(F_fn=None, has_cost=False)\nmodel = optim_builder(\n    iteration=iteration,\n    prior=prior,\n    data_fidelity=data_fidelity,\n    early_stop=early_stop,\n    max_iter=max_iter,\n    verbose=True,\n    params_algo=params_algo,\n)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "language": "markdown"
      },
      "source": "## Evaluate the model on the problem and plot the results.\n\nThe model returns the output and the metrics computed along the iterations.\nThe ground truth image ``x_gt`` must be provided for computing the PSNR.\n"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "y = physics(x)\nx_lin = physics.A_adjoint(y)\n\n# run the model on the problem. For computing the metrics along the iterations, set ``compute_metrics=True``.\nx_model, metrics = model(y, physics, x_gt=x, compute_metrics=True)\n\n# compute PSNR\nprint(f\"Linear reconstruction PSNR: {dinv.metric.PSNR()(x, x_lin).item():.2f} dB\")\nprint(f\"Model reconstruction PSNR: {dinv.metric.PSNR()(x, x_model).item():.2f} dB\")\n\n# plot results\nimgs = [x, x_lin, x_model]\nplot(imgs, titles=[\"GT\", \"Linear\", \"Recons.\"], show=True)\n\n# plot convergence curves\nplot_curves(metrics, save_dir=RESULTS_DIR / \"curves\", show=True)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}