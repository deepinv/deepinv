{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0724a6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "DPIR method for PnP image deblurring.\n",
    "====================================================================================================\n",
    "\n",
    "This example shows how to use the DPIR method to solve a PnP image deblurring problem. The DPIR method is described in :footcite:t:`zhang2021plug`.\n",
    "In Proceedings of the IEEE conference on computer vision and pattern recognition (pp. 3929-3938).\n",
    "\"\"\"\n",
    "\n",
    "import deepinv as dinv\n",
    "from pathlib import Path\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from deepinv.models import DRUNet\n",
    "from deepinv.optim.data_fidelity import L2\n",
    "from deepinv.optim.prior import PnP\n",
    "from deepinv.optim.optimizers import optim_builder\n",
    "from deepinv.training import test\n",
    "from torchvision import transforms\n",
    "from deepinv.optim.dpir import get_DPIR_params\n",
    "from deepinv.utils import load_dataset, load_degradation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "478848d2",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "# Setup paths for data loading and results.\n",
    "# ----------------------------------------------------------------------------------------\n",
    "#\n",
    "\n",
    "BASE_DIR = Path(\".\")\n",
    "DATA_DIR = BASE_DIR / \"measurements\"\n",
    "RESULTS_DIR = BASE_DIR / \"results\"\n",
    "DEG_DIR = BASE_DIR / \"degradations\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27ad3a19",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "# Load base image datasets and degradation operators.\n",
    "# ----------------------------------------------------------------------------------------\n",
    "# In this example, we use the Set3C dataset and a motion blur kernel from :footcite:t:`levin2009understanding`.\n",
    "\n",
    "# Set the global random seed from pytorch to ensure reproducibility of the example.\n",
    "torch.manual_seed(0)\n",
    "\n",
    "device = dinv.utils.get_freer_gpu() if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "# Set up the variable to fetch dataset and operators.\n",
    "method = \"DPIR\"\n",
    "dataset_name = \"set3c\"\n",
    "img_size = 128 if torch.cuda.is_available() else 32\n",
    "val_transform = transforms.Compose(\n",
    "    [transforms.CenterCrop(img_size), transforms.ToTensor()]\n",
    ")\n",
    "\n",
    "# Generate a motion blur operator.\n",
    "kernel_index = 1  # which kernel to chose among the 8 motion kernels from 'Levin09.mat'\n",
    "kernel_torch = load_degradation(\"Levin09.npy\", DEG_DIR / \"kernels\", index=kernel_index)\n",
    "kernel_torch = kernel_torch.unsqueeze(0).unsqueeze(\n",
    "    0\n",
    ")  # add batch and channel dimensions\n",
    "dataset = load_dataset(dataset_name, transform=val_transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c750660",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate a dataset of blurred images and load it.\n",
    "# --------------------------------------------------------------------------------\n",
    "# We use the BlurFFT class from the physics module to generate a dataset of blurred images.\n",
    "\n",
    "\n",
    "noise_level_img = 0.03  # Gaussian Noise standard deviation for the degradation\n",
    "n_channels = 3  # 3 for color images, 1 for gray-scale images\n",
    "p = dinv.physics.BlurFFT(\n",
    "    img_size=(n_channels, img_size, img_size),\n",
    "    filter=kernel_torch,\n",
    "    device=device,\n",
    "    noise_model=dinv.physics.GaussianNoise(sigma=noise_level_img),\n",
    ")\n",
    "\n",
    "# Use parallel dataloader if using a GPU to speed up training,\n",
    "# otherwise, as all computes are on CPU, use synchronous data loading.\n",
    "num_workers = 4 if torch.cuda.is_available() else 0\n",
    "\n",
    "n_images_max = 3  # Maximal number of images to restore from the input dataset\n",
    "# Generate a dataset in a HDF5 folder in \"{dir}/dinv_dataset0.h5'\" and load it.\n",
    "operation = \"deblur\"\n",
    "measurement_dir = DATA_DIR / dataset_name / operation\n",
    "dinv_dataset_path = dinv.datasets.generate_dataset(\n",
    "    train_dataset=dataset,\n",
    "    test_dataset=None,\n",
    "    physics=p,\n",
    "    device=device,\n",
    "    save_dir=measurement_dir,\n",
    "    train_datapoints=n_images_max,\n",
    "    num_workers=num_workers,\n",
    ")\n",
    "\n",
    "batch_size = 3  # batch size for testing. As the number of iterations is fixed, we can use batch_size > 1\n",
    "# and restore multiple images in parallel.\n",
    "dataset = dinv.datasets.HDF5Dataset(path=dinv_dataset_path, train=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbf42c56",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "# Set up the DPIR algorithm to solve the inverse problem.\n",
    "# --------------------------------------------------------------------------------\n",
    "# This method is based on half-quadratic splitting (HQS).\n",
    "# The algorithm alternates between a denoising step and a data fidelity step, where\n",
    "# the denoising step is performed by a pretrained denoiser :class:`deepinv.models.DRUNet`.\n",
    "#\n",
    "# .. note::\n",
    "#    We provide a wrapper for rapidly creating the DPIR algorithm in :class:`deepinv.optim.DPIR`.\n",
    "\n",
    "# load specific parameters for DPIR\n",
    "sigma_denoiser, stepsize, max_iter = get_DPIR_params(noise_level_img, device=device)\n",
    "params_algo = {\"stepsize\": stepsize, \"g_param\": sigma_denoiser}\n",
    "early_stop = False  # Do not stop algorithm with convergence criteria\n",
    "\n",
    "# Select the data fidelity term\n",
    "data_fidelity = L2()\n",
    "\n",
    "# Specify the denoising prior\n",
    "prior = PnP(denoiser=DRUNet(pretrained=\"download\", device=device))\n",
    "\n",
    "# instantiate the algorithm class to solve the IP problem.\n",
    "model = optim_builder(\n",
    "    iteration=\"HQS\",\n",
    "    prior=prior,\n",
    "    data_fidelity=data_fidelity,\n",
    "    early_stop=early_stop,\n",
    "    max_iter=max_iter,\n",
    "    verbose=True,\n",
    "    params_algo=params_algo,\n",
    ")\n",
    "\n",
    "# Set the model to evaluation mode. We do not require training here.\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a01e478c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the model on the problem.\n",
    "# --------------------------------------------------------------------\n",
    "# The test function evaluates the model on the test dataset and computes the metrics.\n",
    "#\n",
    "\n",
    "save_folder = RESULTS_DIR / method / operation / dataset_name\n",
    "plot_convergence_metrics = True  # Metrics are saved in save_folder.\n",
    "plot_images = True  # Images are saved in save_folder.\n",
    "\n",
    "dataloader = DataLoader(\n",
    "    dataset, batch_size=batch_size, num_workers=num_workers, shuffle=False\n",
    ")\n",
    "\n",
    "test(\n",
    "    model=model,\n",
    "    test_dataloader=dataloader,\n",
    "    physics=p,\n",
    "    metrics=[dinv.metric.PSNR(), dinv.metric.LPIPS(device=device)],\n",
    "    device=device,\n",
    "    plot_images=plot_images,\n",
    "    save_folder=save_folder,\n",
    "    plot_convergence_metrics=plot_convergence_metrics,\n",
    "    verbose=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1b1f61b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# :References:\n",
    "#\n",
    "# .. footbibliography::"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
