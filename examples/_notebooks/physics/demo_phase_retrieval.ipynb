{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n# Random phase retrieval and reconstruction methods.\n\nThis example shows how to create a random phase retrieval operator and generate phaseless measurements from a given image. The example showcases 4 different reconstruction methods to recover the image from the phaseless measurements:\n\n#. Gradient descent with random initialization;\n#. Spectral methods;\n#. Gradient descent with spectral methods initialization;\n#. Gradient descent with PnP denoisers.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## General setup\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "import deepinv as dinv\nfrom pathlib import Path\nimport torch\nimport matplotlib.pyplot as plt\nfrom deepinv.models import DRUNet\nfrom deepinv.optim.data_fidelity import L2\nfrom deepinv.optim.prior import PnP, Zero\nfrom deepinv.optim.optimizers import optim_builder\nfrom deepinv.utils import load_example\nfrom deepinv.utils.plotting import plot\nfrom deepinv.optim.phase_retrieval import (\n    correct_global_phase,\n)\nfrom deepinv.models.complex import to_complex_denoiser\n\nBASE_DIR = Path(\".\")\nRESULTS_DIR = BASE_DIR / \"results\"\n# Set global random seed to ensure reproducibility.\ntorch.manual_seed(0)\n\ndevice = dinv.utils.get_freer_gpu() if torch.cuda.is_available() else \"cpu\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Load image from the internet\n\nWe use the standard test image \"Shepp\u2013Logan phantom\".\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# Image size\nimg_size = 32\n# The pixel values of the image are in the range [0, 1].\nx = load_example(\n    \"SheppLogan.png\",\n    img_size=img_size,\n    grayscale=True,\n    resize_mode=\"resize\",\n    device=device,\n)\nprint(x.min(), x.max())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Visualization\n\nWe use the customized plot() function in deepinv to visualize the original image.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "plot(x, titles=\"Original image\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Signal construction\nWe use the original image as the phase information for the complex signal. The original value range is [0, 1], and we map it to the phase range [-pi/2, pi/2].\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "x_phase = torch.exp(1j * x * torch.pi - 0.5j * torch.pi)\n\n# Every element of the signal should have unit norm.\nassert torch.allclose(x_phase.real**2 + x_phase.imag**2, torch.tensor(1.0))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Measurements generation\nCreate a random phase retrieval operator with an\noversampling ratio (measurements/pixels) of 5.0,\nand generate measurements from the signal with additive Gaussian noise.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# Define physics information\noversampling_ratio = 5.0\nimg_size = x.shape[1:]\nm = int(oversampling_ratio * torch.prod(torch.tensor(img_size)))\nn_channels = 1  # 3 for color images, 1 for gray-scale images\n\n# Create the physics\nphysics = dinv.physics.RandomPhaseRetrieval(\n    m=m,\n    img_size=img_size,\n    device=device,\n)\n\n# Generate measurements\ny = physics(x_phase)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Reconstruction with gradient descent and random initialization\nFirst, we use the function :class:`deepinv.optim.L2` as the data fidelity function, and the class :class:`deepinv.optim.optim_iterators.GDIteration` as the optimizer to run a gradient descent algorithm. The initial guess is a random complex signal.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "data_fidelity = L2()\nprior = Zero()\niterator = dinv.optim.optim_iterators.GDIteration()\n# Parameters for the optimizer, including stepsize and regularization coefficient.\noptim_params = {\"stepsize\": 0.06, \"lambda\": 1.0, \"g_param\": []}\nnum_iter = 1000\n\n# Initial guess\nx_phase_gd_rand = torch.randn_like(x_phase)\n\nloss_hist = []\n\nfor _ in range(num_iter):\n    res = iterator(\n        {\"est\": (x_phase_gd_rand,), \"cost\": 0},\n        cur_data_fidelity=data_fidelity,\n        cur_prior=prior,\n        cur_params=optim_params,\n        y=y,\n        physics=physics,\n    )\n    x_phase_gd_rand = res[\"est\"][0]\n    loss_hist.append(data_fidelity(x_phase_gd_rand, y, physics).cpu())\n\nprint(\"initial loss:\", loss_hist[0])\nprint(\"final loss:\", loss_hist[-1])\n# Plot the loss curve\nplt.plot(loss_hist)\nplt.yscale(\"log\")\nplt.title(\"loss curve (gradient descent with random initialization)\")\nplt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Phase correction and signal reconstruction\nThe solution of the optimization algorithm x_est may be any phase-shifted version of the original complex signal x_phase, i.e., x_est = a * x_phase where a is an arbitrary unit norm complex number.\nTherefore, we use the function :class:`deepinv.optim.phase_retrieval.correct_global_phase` to correct the global phase shift of the estimated signal x_est to make it closer to the original signal x_phase.\nWe then use ``torch.angle`` to extract the phase information. With the range of the returned value being [-pi/2, pi/2], we further normalize it to be [0, 1].\nThis operation will later be done for all the reconstruction methods.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# correct possible global phase shifts\nx_gd_rand = correct_global_phase(x_phase_gd_rand, x_phase)\n# extract phase information and normalize to the range [0, 1]\nx_gd_rand = torch.angle(x_gd_rand) / torch.pi + 0.5\n\nplot([x, x_gd_rand], titles=[\"Signal\", \"Reconstruction\"], rescale_mode=\"clip\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Reconstruction with spectral methods\nSpectral methods :class:`deepinv.optim.phase_retrieval.spectral_methods` offers a good initial guess on the original signal. Moreover, :class:`deepinv.physics.RandomPhaseRetrieval` uses spectral methods as its default reconstruction method `A_dagger`, which we can directly call.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# Spectral methods return a tensor with unit norm.\nx_phase_spec = physics.A_dagger(y, n_iter=300)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Phase correction and signal reconstruction\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# correct possible global phase shifts\nx_spec = correct_global_phase(x_phase_spec, x_phase)\n# extract phase information and normalize to the range [0, 1]\nx_spec = torch.angle(x_spec) / torch.pi + 0.5\nplot([x, x_spec], titles=[\"Signal\", \"Reconstruction\"], rescale_mode=\"clip\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Reconstruction with gradient descent and spectral methods initialization\nThe estimate from spectral methods can be directly used as the initial guess for the gradient descent algorithm.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# Initial guess from spectral methods\nx_phase_gd_spec = physics.A_dagger(y, n_iter=300)\n\nloss_hist = []\nfor _ in range(num_iter):\n    res = iterator(\n        {\"est\": (x_phase_gd_spec,), \"cost\": 0},\n        cur_data_fidelity=data_fidelity,\n        cur_prior=prior,\n        cur_params=optim_params,\n        y=y,\n        physics=physics,\n    )\n    x_phase_gd_spec = res[\"est\"][0]\n    loss_hist.append(data_fidelity(x_phase_gd_spec, y, physics).cpu())\n\nprint(\"intial loss:\", loss_hist[0])\nprint(\"final loss:\", loss_hist[-1])\nplt.plot(loss_hist)\nplt.yscale(\"log\")\nplt.title(\"loss curve (gradient descent with spectral initialization)\")\nplt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Phase correction and signal reconstruction\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# correct possible global phase shifts\nx_gd_spec = correct_global_phase(x_phase_gd_spec, x_phase)\n# extract phase information and normalize to the range [0, 1]\nx_gd_spec = torch.angle(x_gd_spec) / torch.pi + 0.5\nplot([x, x_gd_spec], titles=[\"Signal\", \"Reconstruction\"], rescale_mode=\"clip\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Reconstruction with gradient descent and PnP denoisers\nWe can also use the Plug-and-Play (PnP) framework to incorporate denoisers as regularizers in the optimization algorithm. We use a deep denoiser as the prior, which is trained on a large dataset of natural images.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# Load the pre-trained denoiser\ndenoiser = DRUNet(\n    in_channels=n_channels,\n    out_channels=n_channels,\n    pretrained=\"download\",  # automatically downloads the pretrained weights, set to a path to use custom weights.\n    device=device,\n)\n# The original denoiser is designed for real-valued images, so we need to convert it to a complex-valued denoiser for phase retrieval problems.\ndenoiser_complex = to_complex_denoiser(denoiser, mode=\"abs_angle\")\n\n# Algorithm parameters\ndata_fidelity = L2()\nprior = PnP(denoiser=denoiser_complex)\nparams_algo = {\"stepsize\": 0.30, \"g_param\": 0.04}\nmax_iter = 100\nearly_stop = True\nverbose = True\n\n# Instantiate the algorithm class to solve the IP problem.\nmodel = optim_builder(\n    iteration=\"PGD\",\n    prior=prior,\n    data_fidelity=data_fidelity,\n    early_stop=early_stop,\n    max_iter=max_iter,\n    verbose=verbose,\n    params_algo=params_algo,\n)\n\n# Run the algorithm\nx_phase_pnp, metrics = model(y, physics, x_gt=x_phase, compute_metrics=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Phase correction and signal reconstruction\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# correct possible global phase shifts\nx_pnp = correct_global_phase(x_phase_pnp, x_phase)\n# extract phase information and normalize to the range [0, 1]\nx_pnp = torch.angle(x_pnp) / (2 * torch.pi) + 0.5\nplot([x, x_pnp], titles=[\"Signal\", \"Reconstruction\"], rescale_mode=\"clip\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Overall comparison\nWe visualize the original image and the reconstructed images from the four methods.\nWe further compute the PSNR (Peak Signal-to-Noise Ratio) scores (higher better) for every reconstruction and their cosine similarities with the original image (range in [0,1], higher better).\nIn conclusion, gradient descent with random intialization provides a poor reconstruction, while spectral methods provide a good initial estimate which can later be improved by gradient descent to acquire the best reconstruction results. Besides, the PnP framework with a deep denoiser as the prior also provides a very good denoising results as it exploits prior information about the set of natural images.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "subtitles = [\n    \"PSNR\",\n    f\"{dinv.metric.PSNR()(x, x_gd_rand).item():.2f} dB\",\n    f\"{dinv.metric.PSNR()(x, x_spec).item():.2f} dB\",\n    f\"{dinv.metric.PSNR()(x, x_gd_spec).item():.2f} dB\",\n    f\"{dinv.metric.PSNR()(x, x_pnp).item():.2f} dB\",\n]\nplot(\n    {\n        \"Original\": x,\n        \"GD random\": x_gd_rand,\n        \"Spectral\": x_spec,\n        \"GD spectral\": x_gd_spec,\n        \"PnP\": x_pnp,\n    },\n    subtitles=subtitles,\n    save_dir=RESULTS_DIR / \"images\",\n    show=True,\n    rescale_mode=\"clip\",\n)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}