{
  "cells": [
    {
      "id": "e44046bd",
      "cell_type": "code",
      "metadata": {
        "language": "python"
      },
      "execution_count": null,
      "source": "# Install deepinv (skip if already installed)\n%pip install deepinv",
      "outputs": []
    },
    {
      "id": "1edc7e41",
      "cell_type": "markdown",
      "source": "<!-- MathJax macro definitions inserted automatically -->\n$$\n\\newcommand{\\forw}[1]{{A\\left({#1}\\right)}}\n\\newcommand{\\noise}[1]{{N\\left({#1}\\right)}}\n\\newcommand{\\inverse}[1]{{R\\left({#1}\\right)}}\n\\newcommand{\\inversef}[2]{{R\\left({#1},{#2}\\right)}}\n\\newcommand{\\inversename}{R}\n\\newcommand{\\reg}[1]{{g_\\sigma\\left({#1}\\right)}}\n\\newcommand{\\regname}{g_\\sigma}\n\\newcommand{\\sensor}[1]{{\\eta\\left({#1}\\right)}}\n\\newcommand{\\datafid}[2]{{f\\left({#1},{#2}\\right)}}\n\\newcommand{\\datafidname}{f}\n\\newcommand{\\distance}[2]{{d\\left({#1},{#2}\\right)}}\n\\newcommand{\\distancename}{d}\n\\newcommand{\\denoiser}[2]{{\\operatorname{D}_{{#2}}\\left({#1}\\right)}}\n\\newcommand{\\denoisername}{\\operatorname{D}_{\\sigma}}\n\\newcommand{\\xset}{\\mathcal{X}}\n\\newcommand{\\yset}{\\mathcal{Y}}\n\\newcommand{\\group}{\\mathcal{G}}\n\\newcommand{\\metric}[2]{{d\\left({#1},{#2}\\right)}}\n\\newcommand{\\loss}[1]{{\\mathcal\\left({#1}\\right)}}\n\\newcommand{\\conj}[1]{{\\overline{#1}^{\\top}}}\n$$",
      "metadata": {
        "language": "markdown"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "language": "markdown"
      },
      "source": "\n# Single photon lidar operator for depth ranging.\n\nIn this example we show how to use the [`deepinv.physics.SinglePhotonLidar`](https://deepinv.github.io/deepinv/api/stubs/deepinv.physics.SinglePhotonLidar.html) forward model."
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "import deepinv as dinv\nimport torch\nimport matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "language": "markdown"
      },
      "source": "## Create forward model\n\nWe create a lidar model with 100 bins per pixel and a Gaussian impulse response function\nwith a standard deviation of 2 bins.\n\nThe forward model for the case of a single depth per pixel is defined as (e.g. see :footcite:t:`rapp2020advances`):\n\n\\begin{align}y_{i,j,t} = \\mathcal{P}(h(t-d_{i,j}) r_{i,j} + b_{i,j})\\end{align}\n\nwhere $\\mathcal{P}$ is the Poisson noise model, $h(t)$ is a Gaussian impulse response function at\ntime $t$, $d_{i,j}$ is the depth of the scene at pixel $(i,j)$,\n$r_{i,j}$ is the intensity of the scene at pixel $(i,j)$ and $b_{i,j}$ is the background noise\nat pixel $(i,j)$.\n\n"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "device = dinv.utils.get_freer_gpu() if torch.cuda.is_available() else \"cpu\"\nbins = 100\nirf_sigma = 2\nphysics = dinv.physics.SinglePhotonLidar(bins=bins, sigma=irf_sigma, device=device)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "language": "markdown"
      },
      "source": "## Generate toy signal and measurement\n\nWe generate a toy signal with a single peak per pixel located around the 50th bin\nand a signal-to-background ratio of 10%.\n\nSignals should have size (B, 3, H, W) where the first channel contains the depth of the scene,\nthe second channel contains the intensity of the scene and the third channel contains the\nper pixel background noise levels.\n\nThe measurement associated with a signal has size (B, bins, H, W).\n"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "sbr = 0.1\nsignal = 50\nbkg_level = signal / sbr / bins\ndepth = bins / 2\n\n# depth\nd = torch.ones(1, 1, 2, 2, device=device) * depth\n# signal\nr = torch.ones_like(d) * signal\n# background\nb = torch.ones_like(d) * bkg_level\n\nx = torch.cat([d, r, b], dim=1)  # signal of size (B, 3, H, W)\n\ny = physics(x)  # measurement of size (B, bins, H, W)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "language": "markdown"
      },
      "source": "## Apply matched filtering to recover the signal and plot the results\n\nWe apply matched filtering to recover the signal and plot the results.\n\nThe measurements are shown in blue and the depth and intensity of the\nrecovered signals are shown in red.\n"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "xhat = physics.A_dagger(y)\n\nplt.figure()\nfor i in range(2):\n    for j in range(2):\n        plt.subplot(2, 2, i * 2 + j + 1)\n        plt.plot(y[0, :, i, j].detach().cpu().numpy())\n        plt.stem(\n            xhat[0, 0, i, j].detach().cpu().numpy(),\n            xhat[0, 1, i, j].detach().cpu().numpy() / 4,\n            linefmt=\"red\",\n            markerfmt=\"red\",\n        )\n        plt.title(f\"pixel ({i}, {j})\")\n\n\nplt.tight_layout()\nplt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "language": "markdown"
      },
      "source": ":References:\n\n> **Footbibliography**\n>\n>\n"
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}