{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n# Tour of blur operators\n\nThis example provides a tour of 2D blur operators in DeepInverse.\nIn particular, we show how to use DiffractionBlurs (Fresnel diffraction), motion blurs and space varying blurs.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "import torch\n\nimport deepinv as dinv\nfrom deepinv.utils.plotting import plot\nfrom deepinv.utils import load_example"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "----------------\n\nFirst, let's load some test images.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "dtype = torch.float32\ndevice = \"cuda\" if torch.cuda.is_available() else \"cpu\"\nimg_size = (173, 125)\n\nx_rgb = load_example(\n    \"CBSD_0010.png\", grayscale=False, device=device, dtype=dtype, img_size=img_size\n)\n\nx_gray = load_example(\n    \"barbara.jpeg\", grayscale=True, device=device, dtype=dtype, img_size=img_size\n)\n\n# Next, set the global random seed from pytorch to ensure reproducibility of the example.\ntorch.manual_seed(0)\ntorch.cuda.manual_seed(0)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We are now ready to explore the different blur operators.\n\n## Convolution Basics\n\nThe class :class:`deepinv.physics.Blur` implements convolution operations with kernels.\n\nFor instance, here is the convolution of a grayscale image with a grayscale filter:\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "filter_0 = dinv.physics.blur.gaussian_blur(sigma=(2, 0.1), angle=0.0)\nphysics = dinv.physics.Blur(filter_0, device=device)\ny = physics(x_gray)\nplot(\n    [x_gray, filter_0, y],\n    titles=[\"signal\", \"filter\", \"measurement\"],\n    suptitle=\"Grayscale convolution\",\n)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "When a single channel filter is used, all channels are convolved with the same filter:\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "physics = dinv.physics.Blur(filter_0, device=device)\ny = physics(x_rgb)\nplot(\n    [x_rgb, filter_0, y],\n    titles=[\"signal\", \"filter\", \"measurement\"],\n    suptitle=\"RGB image + grayscale filter convolution\",\n)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "By default, the boundary conditions are ``'valid'``, but other options among (``'circular'``, ``'reflect'``, ``'replicate'``) are possible:\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "physics = dinv.physics.Blur(filter_0, padding=\"reflect\", device=device)\ny = physics(x_rgb)\nplot(\n    [x_rgb, filter_0, y],\n    titles=[\"signal\", \"filter\", \"measurement\"],\n    suptitle=\"Reflection boundary conditions\",\n)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "For circular boundary conditions, an FFT implementation is also available. It is slower that :class:`deepinv.physics.Blur`,\nbut inherits from :class:`deepinv.physics.DecomposablePhysics`, so that the pseudo-inverse and regularized inverse are computed faster and more accurately.\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "physics = dinv.physics.BlurFFT(img_size=x_rgb[0].shape, filter=filter_0, device=device)\ny = physics(x_rgb)\nplot(\n    [x_rgb, filter_0, y],\n    titles=[\"signal\", \"filter\", \"measurement\"],\n    suptitle=\"FFT convolution with circular boundary conditions\",\n)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "One can also change the blur filter in the forward pass as follows:\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "filter_90 = dinv.physics.blur.gaussian_blur(sigma=(2, 0.1), angle=90.0).to(\n    device=device, dtype=dtype\n)\ny = physics(x_rgb, filter=filter_90)\nplot(\n    [x_rgb, filter_90, y],\n    titles=[\"signal\", \"filter\", \"measurement\"],\n    suptitle=\"Changing the filter on the fly\",\n)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "When applied to a new image, the last filter is used:\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "y = physics(x_gray, filter=filter_90)\nplot(\n    [x_gray, filter_90, y],\n    titles=[\"signal\", \"filter\", \"measurement\"],\n    suptitle=\"Effect of on the fly change is persistent\",\n)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We can also define color filters. In that situation, each channel is convolved with the corresponding channel of the filter:\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "psf_size = 9\nfilter_rgb = torch.zeros((1, 3, psf_size, psf_size), device=device, dtype=dtype)\nfilter_rgb[:, 0, :, psf_size // 2 : psf_size // 2 + 1] = 1.0 / psf_size\nfilter_rgb[:, 1, psf_size // 2 : psf_size // 2 + 1, :] = 1.0 / psf_size\nfilter_rgb[:, 2, ...] = (\n    torch.diag(torch.ones(psf_size, device=device, dtype=dtype)) / psf_size\n)\ny = physics(x_rgb, filter=filter_rgb)\nplot(\n    [x_rgb, filter_rgb, y],\n    titles=[\"signal\", \"Colour filter\", \"measurement\"],\n    suptitle=\"Color image + color filter convolution\",\n)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Blur generators\nMore advanced kernel generation methods are provided with the toolbox thanks to\nthe  :class:`deepinv.physics.generator.PSFGenerator`. In particular, motion blurs generators are implemented.\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Motion blur generators\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "from deepinv.physics.generator import MotionBlurGenerator"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "In order to generate motion blur kernels, we just need to instantiate a generator with specific the psf size.\nIn turn, motion blurs can be generated on the fly by calling the ``step()`` method. Let's illustrate this now and\ngenerate 3 motion blurs. First, we instantiate the generator:\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "psf_size = 31\nmotion_generator = MotionBlurGenerator((psf_size, psf_size), device=device, dtype=dtype)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "To generate new filters, we call the step() function:\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "filters = motion_generator.step(batch_size=3)\n# the `step()` function returns a dictionary:\nprint(filters.keys())\nplot(\n    [f for f in filters[\"filter\"]],\n    suptitle=\"Examples of randomly generated motion blurs\",\n)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Other options, such as the regularity and length of the blur trajectory can also be specified:\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "motion_generator = MotionBlurGenerator(\n    (psf_size, psf_size), l=0.6, sigma=1, device=device, dtype=dtype\n)\nfilters = motion_generator.step(batch_size=3)\nplot([f for f in filters[\"filter\"]], suptitle=\"Different length and regularity\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Diffraction blur generators\n\nWe also implemented diffraction blurs obtained through Fresnel theory and definition of the psf through the pupil\nplane expanded in Zernike polynomials\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "from deepinv.physics.generator import DiffractionBlurGenerator\n\ndiffraction_generator = DiffractionBlurGenerator(\n    (psf_size, psf_size), device=device, dtype=dtype\n)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Then, to generate new filters, it suffices to call the step() function as follows:\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "filters = diffraction_generator.step(batch_size=3)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "In this case, the `step()` function returns a dictionary containing the filters,\ntheir pupil function and Zernike coefficients:\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "print(filters.keys())\n\n# Note that we use **0.2 to increase the image dynamics\nplot(\n    [f for f in filters[\"filter\"] ** 0.5],\n    suptitle=\"Examples of randomly generated diffraction blurs\",\n)\nplot(\n    [\n        f\n        for f in torch.angle(filters[\"pupil\"][:, None])\n        * torch.abs(filters[\"pupil\"][:, None])\n    ],\n    suptitle=\"Corresponding pupil phases\",\n)\nprint(\"Coefficients of the decomposition on Zernike polynomials\")\nprint(filters[\"coeff\"])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We can change the cutoff frequency (below 1/4 to respect Shannon's sampling theorem)\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "diffraction_generator = DiffractionBlurGenerator(\n    (psf_size, psf_size), fc=1 / 8, device=device, dtype=dtype\n)\nfilters = diffraction_generator.step(batch_size=3)\nplot(\n    [f for f in filters[\"filter\"] ** 0.5],\n    suptitle=\"A different cutoff frequency\",\n)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "It is also possible to directly specify the Zernike decomposition.\nFor instance, if the pupil is null, the PSF is the Airy pattern\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "n_zernike = len(\n    diffraction_generator.list_param\n)  # number of Zernike coefficients in the decomposition\nfilters = diffraction_generator.step(coeff=torch.zeros(3, n_zernike, device=device))\nplot(\n    [f for f in filters[\"filter\"][:, None] ** 0.3],\n    suptitle=\"Airy pattern\",\n)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Finally, notice that you can activate the aberrations you want in the ANSI\nnomenclature https://en.wikipedia.org/wiki/Zernike_polynomials#OSA/ANSI_standard_indices\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "diffraction_generator = DiffractionBlurGenerator(\n    (psf_size, psf_size), fc=1 / 8, list_param=[\"Z5\", \"Z6\"], device=device, dtype=dtype\n)\nfilters = diffraction_generator.step(batch_size=3)\nplot(\n    [f for f in filters[\"filter\"] ** 0.5],\n    suptitle=\"PSF obtained with astigmatism only\",\n)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Generator Mixture\n\nDuring training, it's more robust to train on multiple family of operators. This can be done\nseamlessly with the :class:`deepinv.physics.generator.GeneratorMixture`.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "from deepinv.physics.generator import GeneratorMixture\n\ntorch.cuda.manual_seed(4)\ntorch.manual_seed(6)\n\ngenerator = GeneratorMixture(\n    ([motion_generator, diffraction_generator]), probs=[0.5, 0.5]\n)\nfor i in range(4):\n    filters = generator.step(batch_size=3)\n    plot(\n        [f for f in filters[\"filter\"]],\n        suptitle=f\"Random PSF generated at step {i + 1}\",\n    )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Space varying blurs\n\nSpace varying blurs are also available using :class:`deepinv.physics.SpaceVaryingBlur`\n\nWe plot the impulse responses at different spatial locations by convolving a Dirac comb with the operator.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "from deepinv.physics.generator import (\n    ProductConvolutionBlurGenerator,\n)\nfrom deepinv.physics.blur import SpaceVaryingBlur\n\nimg_size = (128, 128)\nn_eigenpsf = 3\nspacing = (32, 32)\npadding = \"valid\"\nbatch_size = 1\ndelta = 16\n\n# Now, scattered random psfs are synthesized and interpolated spatially\npc_generator = ProductConvolutionBlurGenerator(\n    psf_generator=motion_generator,\n    img_size=img_size,\n    n_eigen_psf=n_eigenpsf,\n    spacing=spacing,\n    padding=padding,\n    device=device,\n)\nparams_pc = pc_generator.step(batch_size)\n\nphysics = SpaceVaryingBlur(**params_pc, device=device)\n\ndirac_comb = torch.zeros(\n    (\n        1,\n        1,\n    )\n    + img_size,\n    device=device,\n)\ndirac_comb[0, 0, ::delta, ::delta] = 1\npsf_grid = physics(dirac_comb)\nplot(psf_grid, titles=\"Space varying impulse responses\", rescale_mode=\"clip\")"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}