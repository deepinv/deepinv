{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c141fe6d",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "r\"\"\"\n",
    "Tour of blur operators\n",
    "===================================================\n",
    "\n",
    "This example provides a tour of 2D blur operators in DeepInverse.\n",
    "In particular, we show how to use DiffractionBlurs (Fresnel diffraction), motion blurs and space varying blurs.\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "import torch\n",
    "\n",
    "import deepinv as dinv\n",
    "from deepinv.utils.plotting import plot\n",
    "from deepinv.utils import load_example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0dd4496",
   "metadata": {
    "title": "Load test images"
   },
   "outputs": [],
   "source": [
    "# ----------------\n",
    "#\n",
    "# First, let's load some test images.\n",
    "\n",
    "dtype = torch.float32\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "img_size = (173, 125)\n",
    "\n",
    "x_rgb = load_example(\n",
    "    \"CBSD_0010.png\", grayscale=False, device=device, dtype=dtype, img_size=img_size\n",
    ")\n",
    "\n",
    "x_gray = load_example(\n",
    "    \"barbara.jpeg\", grayscale=True, device=device, dtype=dtype, img_size=img_size\n",
    ")\n",
    "\n",
    "# Next, set the global random seed from pytorch to ensure reproducibility of the example.\n",
    "torch.manual_seed(0)\n",
    "torch.cuda.manual_seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2d392c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We are now ready to explore the different blur operators.\n",
    "#\n",
    "# Convolution Basics\n",
    "# ------------------\n",
    "#\n",
    "# The class :class:`deepinv.physics.Blur` implements convolution operations with kernels.\n",
    "#\n",
    "# For instance, here is the convolution of a grayscale image with a grayscale filter:\n",
    "filter_0 = dinv.physics.blur.gaussian_blur(sigma=(2, 0.1), angle=0.0)\n",
    "physics = dinv.physics.Blur(filter_0, device=device)\n",
    "y = physics(x_gray)\n",
    "plot(\n",
    "    [x_gray, filter_0, y],\n",
    "    titles=[\"signal\", \"filter\", \"measurement\"],\n",
    "    suptitle=\"Grayscale convolution\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "864e1ee0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# When a single channel filter is used, all channels are convolved with the same filter:\n",
    "#\n",
    "\n",
    "physics = dinv.physics.Blur(filter_0, device=device)\n",
    "y = physics(x_rgb)\n",
    "plot(\n",
    "    [x_rgb, filter_0, y],\n",
    "    titles=[\"signal\", \"filter\", \"measurement\"],\n",
    "    suptitle=\"RGB image + grayscale filter convolution\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "013d9fa9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# By default, the boundary conditions are ``'valid'``, but other options among (``'circular'``, ``'reflect'``, ``'replicate'``) are possible:\n",
    "#\n",
    "\n",
    "physics = dinv.physics.Blur(filter_0, padding=\"reflect\", device=device)\n",
    "y = physics(x_rgb)\n",
    "plot(\n",
    "    [x_rgb, filter_0, y],\n",
    "    titles=[\"signal\", \"filter\", \"measurement\"],\n",
    "    suptitle=\"Reflection boundary conditions\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d70dcae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For circular boundary conditions, an FFT implementation is also available. It is slower that :class:`deepinv.physics.Blur`,\n",
    "# but inherits from :class:`deepinv.physics.DecomposablePhysics`, so that the pseudo-inverse and regularized inverse are computed faster and more accurately.\n",
    "#\n",
    "physics = dinv.physics.BlurFFT(img_size=x_rgb[0].shape, filter=filter_0, device=device)\n",
    "y = physics(x_rgb)\n",
    "plot(\n",
    "    [x_rgb, filter_0, y],\n",
    "    titles=[\"signal\", \"filter\", \"measurement\"],\n",
    "    suptitle=\"FFT convolution with circular boundary conditions\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb200abc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# One can also change the blur filter in the forward pass as follows:\n",
    "filter_90 = dinv.physics.blur.gaussian_blur(sigma=(2, 0.1), angle=90.0).to(\n",
    "    device=device, dtype=dtype\n",
    ")\n",
    "y = physics(x_rgb, filter=filter_90)\n",
    "plot(\n",
    "    [x_rgb, filter_90, y],\n",
    "    titles=[\"signal\", \"filter\", \"measurement\"],\n",
    "    suptitle=\"Changing the filter on the fly\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18fa87da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# When applied to a new image, the last filter is used:\n",
    "y = physics(x_gray, filter=filter_90)\n",
    "plot(\n",
    "    [x_gray, filter_90, y],\n",
    "    titles=[\"signal\", \"filter\", \"measurement\"],\n",
    "    suptitle=\"Effect of on the fly change is persistent\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52fa0d7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can also define color filters. In that situation, each channel is convolved with the corresponding channel of the filter:\n",
    "psf_size = 9\n",
    "filter_rgb = torch.zeros((1, 3, psf_size, psf_size), device=device, dtype=dtype)\n",
    "filter_rgb[:, 0, :, psf_size // 2 : psf_size // 2 + 1] = 1.0 / psf_size\n",
    "filter_rgb[:, 1, psf_size // 2 : psf_size // 2 + 1, :] = 1.0 / psf_size\n",
    "filter_rgb[:, 2, ...] = (\n",
    "    torch.diag(torch.ones(psf_size, device=device, dtype=dtype)) / psf_size\n",
    ")\n",
    "y = physics(x_rgb, filter=filter_rgb)\n",
    "plot(\n",
    "    [x_rgb, filter_rgb, y],\n",
    "    titles=[\"signal\", \"Colour filter\", \"measurement\"],\n",
    "    suptitle=\"Color image + color filter convolution\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b47d4ed8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Blur generators\n",
    "# ----------------------\n",
    "# More advanced kernel generation methods are provided with the toolbox thanks to\n",
    "# the  :class:`deepinv.physics.generator.PSFGenerator`. In particular, motion blurs generators are implemented."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8ac04b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Motion blur generators\n",
    "# ~~~~~~~~~~~~~~~~~~~~~~\n",
    "from deepinv.physics.generator import MotionBlurGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "405df697",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "outputs": [],
   "source": [
    "# In order to generate motion blur kernels, we just need to instantiate a generator with specific the psf size.\n",
    "# In turn, motion blurs can be generated on the fly by calling the ``step()`` method. Let's illustrate this now and\n",
    "# generate 3 motion blurs. First, we instantiate the generator:\n",
    "#\n",
    "psf_size = 31\n",
    "motion_generator = MotionBlurGenerator((psf_size, psf_size), device=device, dtype=dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3e40d52",
   "metadata": {},
   "outputs": [],
   "source": [
    "# To generate new filters, we call the step() function:\n",
    "filters = motion_generator.step(batch_size=3)\n",
    "# the `step()` function returns a dictionary:\n",
    "print(filters.keys())\n",
    "plot(\n",
    "    [f for f in filters[\"filter\"]],\n",
    "    suptitle=\"Examples of randomly generated motion blurs\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e6999b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Other options, such as the regularity and length of the blur trajectory can also be specified:\n",
    "motion_generator = MotionBlurGenerator(\n",
    "    (psf_size, psf_size), l=0.6, sigma=1, device=device, dtype=dtype\n",
    ")\n",
    "filters = motion_generator.step(batch_size=3)\n",
    "plot([f for f in filters[\"filter\"]], suptitle=\"Different length and regularity\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1fcb5ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Diffraction blur generators\n",
    "# ~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
    "#\n",
    "# We also implemented diffraction blurs obtained through Fresnel theory and definition of the psf through the pupil\n",
    "# plane expanded in Zernike polynomials\n",
    "\n",
    "from deepinv.physics.generator import DiffractionBlurGenerator\n",
    "\n",
    "diffraction_generator = DiffractionBlurGenerator(\n",
    "    (psf_size, psf_size), device=device, dtype=dtype\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e834e92",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Then, to generate new filters, it suffices to call the step() function as follows:\n",
    "\n",
    "filters = diffraction_generator.step(batch_size=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "209f30fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# In this case, the `step()` function returns a dictionary containing the filters,\n",
    "# their pupil function and Zernike coefficients:\n",
    "print(filters.keys())\n",
    "\n",
    "# Note that we use **0.2 to increase the image dynamics\n",
    "plot(\n",
    "    [f for f in filters[\"filter\"] ** 0.5],\n",
    "    suptitle=\"Examples of randomly generated diffraction blurs\",\n",
    ")\n",
    "plot(\n",
    "    [\n",
    "        f\n",
    "        for f in torch.angle(filters[\"pupil\"][:, None])\n",
    "        * torch.abs(filters[\"pupil\"][:, None])\n",
    "    ],\n",
    "    suptitle=\"Corresponding pupil phases\",\n",
    ")\n",
    "print(\"Coefficients of the decomposition on Zernike polynomials\")\n",
    "print(filters[\"coeff\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20cb4017",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can change the cutoff frequency (below 1/4 to respect Shannon's sampling theorem)\n",
    "diffraction_generator = DiffractionBlurGenerator(\n",
    "    (psf_size, psf_size), fc=1 / 8, device=device, dtype=dtype\n",
    ")\n",
    "filters = diffraction_generator.step(batch_size=3)\n",
    "plot(\n",
    "    [f for f in filters[\"filter\"] ** 0.5],\n",
    "    suptitle=\"A different cutoff frequency\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15d3e289",
   "metadata": {},
   "outputs": [],
   "source": [
    "# It is also possible to directly specify the Zernike decomposition.\n",
    "# For instance, if the pupil is null, the PSF is the Airy pattern\n",
    "n_zernike = len(\n",
    "    diffraction_generator.list_param\n",
    ")  # number of Zernike coefficients in the decomposition\n",
    "filters = diffraction_generator.step(coeff=torch.zeros(3, n_zernike, device=device))\n",
    "plot(\n",
    "    [f for f in filters[\"filter\"][:, None] ** 0.3],\n",
    "    suptitle=\"Airy pattern\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a987f972",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finally, notice that you can activate the aberrations you want in the ANSI\n",
    "# nomenclature https://en.wikipedia.org/wiki/Zernike_polynomials#OSA/ANSI_standard_indices\n",
    "diffraction_generator = DiffractionBlurGenerator(\n",
    "    (psf_size, psf_size), fc=1 / 8, list_param=[\"Z5\", \"Z6\"], device=device, dtype=dtype\n",
    ")\n",
    "filters = diffraction_generator.step(batch_size=3)\n",
    "plot(\n",
    "    [f for f in filters[\"filter\"] ** 0.5],\n",
    "    suptitle=\"PSF obtained with astigmatism only\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25a74a80",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generator Mixture\n",
    "# ~~~~~~~~~~~~~~~~~\n",
    "#\n",
    "# During training, it's more robust to train on multiple family of operators. This can be done\n",
    "# seamlessly with the :class:`deepinv.physics.generator.GeneratorMixture`.\n",
    "\n",
    "from deepinv.physics.generator import GeneratorMixture\n",
    "\n",
    "torch.cuda.manual_seed(4)\n",
    "torch.manual_seed(6)\n",
    "\n",
    "generator = GeneratorMixture(\n",
    "    ([motion_generator, diffraction_generator]), probs=[0.5, 0.5]\n",
    ")\n",
    "for i in range(4):\n",
    "    filters = generator.step(batch_size=3)\n",
    "    plot(\n",
    "        [f for f in filters[\"filter\"]],\n",
    "        suptitle=f\"Random PSF generated at step {i + 1}\",\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c19a062",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Space varying blurs\n",
    "# --------------------\n",
    "#\n",
    "# Space varying blurs are also available using :class:`deepinv.physics.SpaceVaryingBlur`\n",
    "#\n",
    "# We plot the impulse responses at different spatial locations by convolving a Dirac comb with the operator.\n",
    "\n",
    "from deepinv.physics.generator import (\n",
    "    ProductConvolutionBlurGenerator,\n",
    ")\n",
    "from deepinv.physics.blur import SpaceVaryingBlur\n",
    "\n",
    "img_size = (128, 128)\n",
    "n_eigenpsf = 3\n",
    "spacing = (32, 32)\n",
    "padding = \"valid\"\n",
    "batch_size = 1\n",
    "delta = 16\n",
    "\n",
    "# Now, scattered random psfs are synthesized and interpolated spatially\n",
    "pc_generator = ProductConvolutionBlurGenerator(\n",
    "    psf_generator=motion_generator,\n",
    "    img_size=img_size,\n",
    "    n_eigen_psf=n_eigenpsf,\n",
    "    spacing=spacing,\n",
    "    padding=padding,\n",
    "    device=device,\n",
    ")\n",
    "params_pc = pc_generator.step(batch_size)\n",
    "\n",
    "physics = SpaceVaryingBlur(**params_pc, device=device)\n",
    "\n",
    "dirac_comb = torch.zeros(\n",
    "    (\n",
    "        1,\n",
    "        1,\n",
    "    )\n",
    "    + img_size,\n",
    "    device=device,\n",
    ")\n",
    "dirac_comb[0, 0, ::delta, ::delta] = 1\n",
    "psf_grid = physics(dirac_comb)\n",
    "plot(psf_grid, titles=\"Space varying impulse responses\", rescale_mode=\"clip\")"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "title,-all",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
