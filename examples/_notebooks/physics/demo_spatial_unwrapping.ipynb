{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "699de082",
   "metadata": {},
   "outputs": [],
   "source": [
    "r\"\"\"\n",
    "Spatial unwrapping and modulo imaging\n",
    "==============================================\n",
    "\n",
    "This demo shows the use of the :class:`deepinv.physics.SpatialUnwrapping` forward model and the :class:`deepinv.optim.ItohFidelity` for unwrapping problems, which occur in modulo imaging, interferometry SAR and other imaging applications.\n",
    "It shows how to generate a wrapped phase image, apply blur and noise, and reconstruct the original phase using both DCT inversion and ADMM optimization.\n",
    "\n",
    "\n",
    "The spatial unwrapping forward model can be mathematically described as follows:\n",
    "\n",
    ".. math::\n",
    "    y = w_t(x + n) = x + n - t \\cdot \\mathrm{q}((x + n) / t)\n",
    "\n",
    "where :math:`x` is the original image, :math:`n` is additive noise, and :math:`w_t(\\cdot)` denotes the modulo (wrapping) operation with threshold :math:`t`.\n",
    "Here, :math:`\\mathrm{q}(\\cdot)` is either the rounding or flooring function, depending on the chosen mode ('round' or 'floor').\n",
    "The goal is to recover :math:`x` from the observed wrapped image :math:`y`.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92ebd160",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "# Imports and setup\n",
    "# -------------------------------------------------------\n",
    "import torch\n",
    "import deepinv as dinv\n",
    "import torchvision.transforms as transforms\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from deepinv.utils.demo import load_example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3238ab3",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "# Load image and preprocess\n",
    "# -------------------------------------------------------\n",
    "# Load example image and preprocess to emulate a high dynamic range image.\n",
    "# Images are normalized to [0, 1] and then scaled to the desired dynamic range.\n",
    "\n",
    "\n",
    "def channel_norm(x):\n",
    "    x = x - x.min(dim=-1, keepdim=True)[0].min(dim=-2, keepdim=True)[0]\n",
    "    x = x / x.max(dim=-1, keepdim=True)[0].max(dim=-2, keepdim=True)[0]\n",
    "    return x\n",
    "\n",
    "\n",
    "size = 256\n",
    "dynamic_range = 2  # dynamic range\n",
    "threshold = 1.0  # threshold for spatial unwrapping\n",
    "factor = 2  # oversampling factor to ensure Itoh condition\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "img_size = (size, size)\n",
    "mode = \"round\"  # available modes: \"round\", \"floor\"\n",
    "\n",
    "\n",
    "x_rgb = load_example(\n",
    "    \"CBSD_0010.png\",\n",
    "    grayscale=False,\n",
    "    device=device,\n",
    "    dtype=torch.float32,\n",
    "    img_size=img_size,\n",
    ")\n",
    "x_rgb = channel_norm(x_rgb) * dynamic_range"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a42e124a",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "# Itoh condition\n",
    "# -------------------------------------------------------\n",
    "# The Itoh condition requires that the difference between adjacent pixels is less than half of the threshold (here, 1.0)\n",
    "# to enable perfect unwrapping. Specifically, :math:`\\|Dx\\|_{\\infty} < t / 2`\n",
    "# where :math:`D` denotes the spatial finite difference operator and :math:`x` is the original image :footcite:p:`itoh1982analysis`.\n",
    "# When this condition is satisfied, the high dynamic range (HDR) image can be recovered from\n",
    "# the wrapped differences of the modulo image by minimizing the Itoh fidelity term:\n",
    "#\n",
    "# .. math::\n",
    "#         \\begin{equation}  \\underset{x}{\\arg\\min} \\quad \\| Dx - w_t(Dy) \\|^2_2. \\end{equation}\n",
    "#\n",
    "# Below, we illustrate this for a single row of the image by visualizing the pixel values, their differences, and the wrapped differences.\n",
    "# We can understand the condition by artificially blurring the images with a Gaussian kernel to reduce their high frequencies (and thus the :math:`\\|Dx\\|_{\\infty}`) until the condition is verified.\n",
    "# For instace, with a blur of 0.1 it can be seen that the differences :math:`Dx` exceed the threshold (red dotted lines),\n",
    "# and consequently, we observe a mismatch with the wrapped differences :math:`w_t(Dy)`,\n",
    "# while with a blur of 2.0, the differences :math:`Dx` remain within the threshold, matching the wrapped differences :math:`w_t(Dy)`,\n",
    "# indicating that the Itoh condition is satisfied.\n",
    "\n",
    "modulo_round = lambda x: x - torch.round(x)\n",
    "modulo_fn = lambda x: x - torch.floor(x) if mode == \"floor\" else modulo_round(x)\n",
    "row = 120\n",
    "\n",
    "row_sel = x_rgb[0, 0, row, :]\n",
    "\n",
    "\n",
    "def plot_itoh(sigma_blur):\n",
    "\n",
    "    # Select a row and apply Gaussian blur\n",
    "    row_x = row_sel.clone()\n",
    "\n",
    "    # Construct 1D Gaussian filter with given sigma\n",
    "    filter1d = dinv.physics.blur.gaussian_blur(\n",
    "        sigma=(sigma_blur, sigma_blur), angle=0.0\n",
    "    ).to(device)\n",
    "    # Reduce to 1D filter and normalize\n",
    "    filter1d = filter1d[..., filter1d.shape[2] // 2, :].squeeze()\n",
    "    filter1d = filter1d / filter1d.sum()\n",
    "\n",
    "    # Upsample by factor and convolve with Gaussian filter\n",
    "    row_x = torch.kron(row_x, torch.ones(1, factor).to(device)).squeeze()\n",
    "    row_x = torch.nn.functional.conv1d(\n",
    "        row_x[None, None, :], filter1d[None, None, :], padding=filter1d.shape[0] // 2\n",
    "    ).squeeze()\n",
    "\n",
    "    # Center around zero for \"round\" mode\n",
    "    if mode == \"round\":\n",
    "        row_x = row_x - dynamic_range / 2\n",
    "\n",
    "    # Compute differences and wrapped differences\n",
    "    row_dx = row_x[1:] - row_x[:-1]\n",
    "    row_y = modulo_fn(row_x)\n",
    "    row_wdy = modulo_round(row_y[1:] - row_y[:-1])\n",
    "\n",
    "    plt.figure(figsize=(10, 2.5))\n",
    "    plt.plot(row_x.cpu(), label=\"Pixel values\", linewidth=3, color=\"g\")\n",
    "    plt.plot(row_dx.cpu(), label=\"Dx\", linewidth=3, color=\"k\")\n",
    "    plt.plot(row_wdy.cpu(), label=\"w_t(Dy)\", linewidth=3, color=\"b\", linestyle=\"--\")\n",
    "    plt.axhline(threshold / 2, color=\"r\", linestyle=\"--\", label=\"t/2\")\n",
    "    plt.axhline(-threshold / 2, color=\"r\", linestyle=\"--\")\n",
    "    plt.title(f\"Itoh Condition, sigma={sigma_blur}, mode={mode}\")\n",
    "    plt.xlabel(\"Pixel Index\")\n",
    "    plt.ylabel(\"Difference\")\n",
    "    plt.legend(loc=\"upper right\", bbox_to_anchor=(1.0, 1.0), ncol=4)\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "plot_itoh(sigma_blur=0.1)\n",
    "plot_itoh(sigma_blur=2.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4150734b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply Resize and Gaussian blur\n",
    "# -------------------------------------------------------\n",
    "# To satisfy the Itoh condition, we resize the image and apply a slight Gaussian blur.\n",
    "# The blur here is chosen similarly to the 1D analysis above, ensuring adjacent pixel differences are small enough for successful unwrapping.\n",
    "\n",
    "resize = transforms.Resize(size=(img_size[0] * factor, img_size[1] * factor))\n",
    "x_rgb = resize(x_rgb)\n",
    "\n",
    "if mode == \"round\":\n",
    "    x_rgb = x_rgb - dynamic_range / 2\n",
    "\n",
    "filter_0 = dinv.physics.blur.gaussian_blur(sigma=(1, 1), angle=0.0)\n",
    "blur_op = dinv.physics.Blur(filter_0, device=device)\n",
    "x_rgb = blur_op(x_rgb)\n",
    "\n",
    "\n",
    "%%s\n",
    "# Add Gaussian noise and modulo operation\n",
    "# -------------------------------------------------------\n",
    "# Include Gaussian noise and wrap the image using SpatialUnwrapping physics\n",
    "noise_model = dinv.physics.GaussianNoise(sigma=0.1)\n",
    "physics = dinv.physics.SpatialUnwrapping(\n",
    "    threshold=threshold, mode=mode, noise_model=noise_model\n",
    ")\n",
    "phase_map = x_rgb\n",
    "wrapped_phase = physics(phase_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc726ba8",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "# Invert with DCT and ADMM (ItohFidelity)\n",
    "# -------------------------------------------------------\n",
    "# We provide two inversion methods: a simple DCT-based inversion and an ADMM-based inversion using the Itoh fidelity term and TV prior.\n",
    "\n",
    "\n",
    "# ADMM-based inversion with TV prior and Itoh fidelity\n",
    "stepsize = 1e-4\n",
    "lam = 2.0 / stepsize\n",
    "prior = dinv.optim.TVPrior(n_it_max=10)\n",
    "fidelity = dinv.optim.ItohFidelity(threshold=threshold)\n",
    "\n",
    "# DCT-based inversion\n",
    "x_est = fidelity.D_dagger(wrapped_phase)\n",
    "\n",
    "\n",
    "params_algo = {\"stepsize\": stepsize, \"lambda\": lam, \"g_param\": 1.0}\n",
    "model = dinv.optim.optim_builder(\n",
    "    iteration=\"ADMM\",\n",
    "    prior=prior,\n",
    "    data_fidelity=fidelity,\n",
    "    max_iter=10,\n",
    "    verbose=False,\n",
    "    params_algo=params_algo,\n",
    ")\n",
    "x_model = model(wrapped_phase, physics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b0ae41a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize results\n",
    "# -------------------------------------------------------\n",
    "# Here we visualize the wrapped phase, original phase, and the reconstructions from both methods.\n",
    "# We also compute PSNR and SSIM metrics for both reconstructions.\n",
    "\n",
    "psnr_fn = dinv.metric.PSNR()\n",
    "ssim_fn = dinv.metric.SSIM()\n",
    "\n",
    "# Normalize for display\n",
    "x_est = channel_norm(x_est)\n",
    "x_model = channel_norm(x_model)\n",
    "phase_map = channel_norm(phase_map)\n",
    "\n",
    "# Compute metrics\n",
    "psnr_admm = psnr_fn(phase_map, x_model).item()\n",
    "psnr_dct = psnr_fn(phase_map, x_est).item()\n",
    "ssim_admm = ssim_fn(phase_map, x_model).item()\n",
    "ssim_dct = ssim_fn(phase_map, x_est).item()\n",
    "\n",
    "# Plot results\n",
    "imgs = [wrapped_phase[0], phase_map[0], x_est[0], x_model[0]]\n",
    "titles = [\n",
    "    \"Wrapped Phase\",\n",
    "    \"Original Phase\",\n",
    "    f\"DCT Inversion\\n PSNR={psnr_dct:.2f} SSIM={ssim_dct:.2f}\",\n",
    "    f\"ADMM Inversion\\n PSNR={psnr_admm:.2f} SSIM={ssim_admm:.2f}\",\n",
    "]\n",
    "\n",
    "dinv.utils.plotting.plot(imgs, titles=titles, cmap=\"gray\", figsize=(20, 10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3da6e062",
   "metadata": {},
   "outputs": [],
   "source": [
    "# :References:\n",
    "#\n",
    "# .. footbibliography::"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
