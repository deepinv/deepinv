{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n# Pattern Ordering in a Compressive Single Pixel Camera\n\nThis demo illustrates the impact of different Hadamard pattern ordering algorithms in the Single Pixel Camera (SPC),\na computational imaging system that uses a single photodetector to capture images by projecting the\nscene onto a series of patterns. The SPC is implemented in the DeepInverse library.\n\nIn this example, we explore the following ordering algorithms for the Hadamard transform:\n\n1. **Sequency Ordering**:\n   Rows are ordered based on the number of sign changes (sequency pattern).\n   Reference: https://en.wikipedia.org/wiki/Walsh_matrix#Sequency_ordering\n\n2. **Cake Cutting Ordering**:\n   Rows are ordered based on the number of blocks in the 2D resized Hadamard matrix.\n   Reference: https://doi.org/10.3390/s19194122\n\n3. **Zig-Zag Ordering**:\n   Rows are ordered in a zig-zag pattern from the top-left to the bottom-right of the matrix.\n   Reference: https://doi.org/10.1364/OE.451656\n\n4. **XY Ordering**:\n   Rows are ordered in a circular pattern starting from the top-left to the bottom-right.\n   Reference: https://doi.org/10.48550/arXiv.2209.04449\n\nWe compare the reconstructions obtained using these orderings and visualize their corresponding masks\nand Hadamard spectrum.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "import torch\nfrom pathlib import Path\nimport deepinv as dinv\nfrom deepinv.utils import get_image_url, load_url_image\nfrom deepinv.utils.plotting import plot\nfrom deepinv.loss.metric import PSNR\nfrom deepinv.physics.singlepixel import hadamard_2d_shift\nfrom deepinv.utils.compat import zip_strict"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## General Setup\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "BASE_DIR = Path(\".\")\nRESULTS_DIR = BASE_DIR / \"results\"\n\n# Set the global random seed for reproducibility.\ntorch.manual_seed(0)\ndevice = dinv.utils.get_freer_gpu() if torch.cuda.is_available() else \"cpu\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Configuration\nDefine the image size, noise level, number of measurements, and ordering algorithms.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "img_size_H = 128  # Size of the image (128x128 pixels)\nimg_size_W = 128\nnoise_level_img = 0.0  # Noise level in the image\nn = img_size_H * img_size_W  # Total number of pixels in the image\nm = 5000  # Number of measurements\norderings = [\n    \"sequency\",\n    \"cake_cutting\",\n    \"zig_zag\",\n    \"xy\",\n]  # Ordering algorithms to compare"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Load Image\nLoad a grayscale image from the internet and resize it to the desired size.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "url = get_image_url(\"barbara.jpeg\")\nx = load_url_image(\n    url=url,\n    img_size=(img_size_H, img_size_W),\n    grayscale=True,\n    resize_mode=\"resize\",\n    device=device,\n)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Create Physics Models\nInstantiate Single Pixel Camera models with different ordering algorithms.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "physics_list = [\n    dinv.physics.SinglePixelCamera(\n        m=m,\n        img_size=(1, img_size_H, img_size_W),\n        noise_model=dinv.physics.GaussianNoise(sigma=noise_level_img),\n        device=device,\n        ordering=ordering,\n    )\n    for ordering in orderings\n]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Generate Measurements and Reconstructions\nGenerate measurements using the physics models and reconstruct images using the adjoint operator.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "y_list = [physics(x) for physics in physics_list]\nx_list = [physics.A_adjoint(y) for physics, y in zip_strict(physics_list, y_list)]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Calculate PSNR\nCompute the Peak Signal-to-Noise Ratio (PSNR) for each reconstruction.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "psnr_metric = PSNR()\npsnr_values = [psnr_metric(x_recon, x).item() for x_recon in x_list]\n\n# Prepare titles for plotting\ntitle_orderings = [o.replace(\"_\", \" \").title() for o in orderings]\ntitle_orderings[-1] = \"XY\"  # Special case for 'xy'\ntitles = [\"Ground Truth\"] + title_orderings\nsubtitles = [\"PSNR\"] + [f\"{psnr:.2f} dB\" for psnr in psnr_values]\n# Print information about the SPC setup\nundersampling_rate = physics_list[0].mask.sum().float() / n\nprint(f\"Image Size: {x.shape}\")\nprint(f\"SPC Measurements: {physics_list[0].mask.sum()}\")\nprint(f\"SPC Undersampling Rate: {undersampling_rate:.2f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Plot Reconstructions\nVisualize the ground truth and reconstructed images with PSNR values.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "plot(\n    [x] + x_list,\n    titles=titles,\n    subtitles=subtitles,\n    show=True,\n    figsize=(15, 5),\n    fontsize=24,\n)\n\n# Recovery Algorithm\n# ------------------\n# Use a Plug-and-Play (PnP) denoising prior with the ADMM optimization algorithm for image recovery.\nfrom deepinv.models import DnCNN\nfrom deepinv.optim.data_fidelity import L2\nfrom deepinv.optim.prior import PnP\nfrom deepinv.optim.optimizers import optim_builder\n\nn_channels = 1  # Number of channels in the image\n\n# Define the data fidelity term (L2 loss)\ndata_fidelity = L2()\n\n# Specify the denoising prior using a pretrained DnCNN model\ndenoiser = DnCNN(\n    in_channels=n_channels,\n    out_channels=n_channels,\n    pretrained=\"download\",  # Automatically downloads pretrained weights\n    device=device,\n)\n\n# Define the prior using the Plug-and-Play framework\nprior = PnP(denoiser=denoiser)\n\n# Set optimization parameters\nmax_iter = 5  # Maximum number of iterations\nnoise_level_img = 0.03  # Noise level in the image\nparams_algo = {\"stepsize\": 0.8, \"g_param\": noise_level_img}\n\n# Instantiate the optimization algorithm (ADMM)\nmodel = optim_builder(\n    iteration=\"ADMM\",\n    prior=prior,\n    data_fidelity=data_fidelity,\n    early_stop=False,\n    max_iter=max_iter,\n    verbose=False,\n    params_algo=params_algo,\n    g_first=True,\n)\n\n# Set the model to evaluation mode (no training required)\nmodel.eval()\n\n# Perform image reconstruction using the optimization algorithm\nx_recon = []\npsnr_values = []\n\nfor y, physics in zip_strict(y_list, physics_list):\n    x_recon.append(model(y, physics))\n    psnr_values.append(psnr_metric(x_recon[-1], x).item())\n\n# Update titles with PSNR values for the reconstructed images\ntitles = [\"Ground Truth\"] + title_orderings\nsubtitles = [\"PSNR\"] + [f\"{psnr:.2f} dB\" for psnr in psnr_values]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Plot ADMM-TV Reconstructions\nVisualize the ground truth and reconstructed images with PSNR values.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "plot(\n    [x] + x_recon,\n    titles=titles,\n    subtitles=subtitles,\n    show=True,\n    figsize=(15, 5),\n    fontsize=24,\n)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Visualize Masks and Hadamard Spectrum\nPrepare and plot masks and the Hadamard spectrum for visualization.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "masks = [physics.mask for physics in physics_list]\nshifted_masks = [hadamard_2d_shift(mask) for mask in masks]\n\n# Calculate the Hadamard spectrum for visualization\nphysics_full = dinv.physics.SinglePixelCamera(\n    m=n,\n    img_size=(1, img_size_H, img_size_W),\n    noise_model=dinv.physics.GaussianNoise(sigma=noise_level_img),\n    device=device,\n)\ny_spectrum = hadamard_2d_shift(physics_full(x))\ny_spectrum = torch.pow(torch.abs(y_spectrum), 0.2)\ny_spectrum = y_spectrum / y_spectrum.max()\n\n# Plot the masks and Hadamard spectrum\nplot(\n    [y_spectrum] + shifted_masks,\n    titles=[\"Hadamard Spectrum\"] + title_orderings,\n    show=True,\n    figsize=(15, 5),\n    cmap=\"jet\",\n    fontsize=24,\n)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}