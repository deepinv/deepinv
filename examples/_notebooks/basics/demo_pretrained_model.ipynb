{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b9fb7c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "r\"\"\"\n",
    "Use a pretrained model\n",
    "====================================================================================================\n",
    "\n",
    "Follow this example to reconstruct images using a pretrained model in one line.\n",
    "\n",
    "We show three sets of general pretrained reconstruction methods, including:\n",
    "\n",
    "* Pretrained feedforward :class:`Reconstruct Anything Model (RAM) <deepinv.models.RAM>`;\n",
    "* :ref:`Plug-and-play <iterative>` with a pretrained denoiser.\n",
    "* Pretrained :ref:`diffusion model <diffusion>`;\n",
    "\n",
    "See :ref:`pretrained models <pretrained-models>` for a principled comparison between methods demonstrated in this example.\n",
    "\n",
    ".. tip::\n",
    "\n",
    "    * Want to use your own dataset? See :ref:`sphx_glr_auto_examples_basics_demo_custom_dataset.py`\n",
    "    * Want to use your own physics? See :ref:`sphx_glr_auto_examples_basics_demo_custom_physics.py`\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8df14b50",
   "metadata": {},
   "outputs": [],
   "source": [
    "import deepinv as dinv\n",
    "import torch\n",
    "\n",
    "device = dinv.utils.get_freer_gpu() if torch.cuda.is_available() else \"cpu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d858f71d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's say you want to reconstruct a butterfly from noisy, blurry measurements:\n",
    "\n",
    "# Ground truth\n",
    "x = dinv.utils.load_example(\"butterfly.png\", device=device)\n",
    "\n",
    "# Define physics\n",
    "physics = dinv.physics.BlurFFT(\n",
    "    x.shape[1:],\n",
    "    filter=dinv.physics.blur.gaussian_blur((5, 5)),\n",
    "    noise_model=dinv.physics.GaussianNoise(\n",
    "        sigma=0.1, rng=torch.Generator(device=x.device).manual_seed(123)\n",
    "    ),\n",
    "    device=device,\n",
    ")\n",
    "\n",
    "y = physics(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a852381e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For each model, define model in one line and reconstruct in one line.\n",
    "# Pretrained Reconstruct Anything Model:\n",
    "#\n",
    "# .. seealso::\n",
    "#     See :ref:`sphx_glr_auto_examples_models_demo_foundation_model.py` for further one-line examples for the RAM model across various domains.\n",
    "\n",
    "model = dinv.models.RAM(pretrained=True, device=device)\n",
    "\n",
    "with torch.no_grad():\n",
    "    x_hat1 = model(y, physics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a60199d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PnP algorithm with pretrained denoiser:\n",
    "#\n",
    "# .. seealso::\n",
    "#     See :ref:`pretrained denoisers <pretrained-weights>` for a full list of denoisers that can be plugged into iterative/sampling algorithms.\n",
    "#\n",
    "#     See :ref:`sphx_glr_auto_examples_plug-and-play_demo_PnP_DPIR_deblur.py` for a further example of using plug-and-play with a pretrained denoiser.\n",
    "\n",
    "denoiser = dinv.models.DRUNet(device=device)\n",
    "model = dinv.optim.DPIR(sigma=0.1, denoiser=denoiser, device=device)\n",
    "\n",
    "x_hat2 = model(y, physics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07f6ac60",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pretrained diffusion model (we reduce the image size for demo speed on CPU, as diffusion model is slow):\n",
    "#\n",
    "# .. seealso::\n",
    "#     See :ref:`sphx_glr_auto_examples_sampling_demo_ddrm.py` for a further example of using a pretrained diffusion model.\n",
    "\n",
    "\n",
    "model = dinv.sampling.DDRM(denoiser, sigmas=torch.linspace(1, 0, 20)).to(device)\n",
    "\n",
    "x_hat3 = model(y, physics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcff6e46",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot results\n",
    "dinv.utils.plot(\n",
    "    {\n",
    "        \"Ground Truth\": x,\n",
    "        \"Measurement\": y,\n",
    "        \"Pretrained \\nRAM\": x_hat1,\n",
    "        \"Pretrained \\nPnP\": x_hat2,\n",
    "        \"Pretrained \\nDiffusion\": x_hat3,\n",
    "    },\n",
    "    subtitles=[\n",
    "        \"PSNR:\",\n",
    "        f\"{dinv.metric.PSNR()(y, x).item():.2f} dB\",\n",
    "        f\"{dinv.metric.PSNR()(x_hat1, x).item():.2f} dB\",\n",
    "        f\"{dinv.metric.PSNR()(x_hat2, x).item():.2f} dB\",\n",
    "        f\"{dinv.metric.PSNR()(x_hat3, x).item():.2f} dB\",\n",
    "    ],\n",
    "    figsize=(10, 5),\n",
    ")\n",
    "\n",
    "\n",
    "# sphinx_gallery_start_ignore\n",
    "assert dinv.metric.PSNR()(x_hat1, x).item() > 19\n",
    "# sphinx_gallery_end_ignore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7080e1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ðŸŽ‰ Well done, you now know how to use pretrained models!\n",
    "#\n",
    "# What's next?\n",
    "# ~~~~~~~~~~~~\n",
    "# * Check out the :ref:`example on how to fine-tune a foundation model to your own problem <sphx_glr_auto_examples_models_demo_foundation_model.py>`.\n",
    "# * See :ref:`pretrained models <pretrained-models>` for a comparison between methods demonstrated in this example.\n",
    "# * See :ref:`diffusion <diffusion>` and :ref:`iterative <iterative>` for how to fully customize your sampling or iterative algorithm using a pretrained denoiser."
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
