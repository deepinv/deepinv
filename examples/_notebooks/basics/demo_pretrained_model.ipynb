{
  "cells": [
    {
      "id": "c878adee",
      "cell_type": "code",
      "metadata": {
        "language": "python"
      },
      "execution_count": null,
      "source": "# Install deepinv (skip if already installed)\n%pip install deepinv",
      "outputs": []
    },
    {
      "id": "ad996707",
      "cell_type": "markdown",
      "source": "<!-- MathJax macro definitions inserted automatically -->\n$$\n\\newcommand{\\forw}[1]{{A\\left({#1}\\right)}}\n\\newcommand{\\noise}[1]{{N\\left({#1}\\right)}}\n\\newcommand{\\inverse}[1]{{R\\left({#1}\\right)}}\n\\newcommand{\\inversef}[2]{{R\\left({#1},{#2}\\right)}}\n\\newcommand{\\inversename}{R}\n\\newcommand{\\reg}[1]{{g_\\sigma\\left({#1}\\right)}}\n\\newcommand{\\regname}{g_\\sigma}\n\\newcommand{\\sensor}[1]{{\\eta\\left({#1}\\right)}}\n\\newcommand{\\datafid}[2]{{f\\left({#1},{#2}\\right)}}\n\\newcommand{\\datafidname}{f}\n\\newcommand{\\distance}[2]{{d\\left({#1},{#2}\\right)}}\n\\newcommand{\\distancename}{d}\n\\newcommand{\\denoiser}[2]{{\\operatorname{D}_{{#2}}\\left({#1}\\right)}}\n\\newcommand{\\denoisername}{\\operatorname{D}_{\\sigma}}\n\\newcommand{\\xset}{\\mathcal{X}}\n\\newcommand{\\yset}{\\mathcal{Y}}\n\\newcommand{\\group}{\\mathcal{G}}\n\\newcommand{\\metric}[2]{{d\\left({#1},{#2}\\right)}}\n\\newcommand{\\loss}[1]{{\\mathcal\\left({#1}\\right)}}\n\\newcommand{\\conj}[1]{{\\overline{#1}^{\\top}}}\n$$",
      "metadata": {
        "language": "markdown"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "language": "markdown"
      },
      "source": "\n# Use a pretrained model\n\nFollow this example to reconstruct images using a pretrained model in one line.\n\nWe show three sets of general pretrained reconstruction methods, including:\n\n* Pretrained feedforward [Reconstruct Anything Model (RAM)](https://deepinv.github.io/deepinv/api/stubs/deepinv.models.RAM.html);\n* Plug-and-play with a pretrained denoiser.\n* Pretrained diffusion model;\n\nSee pretrained models for a principled comparison between methods demonstrated in this example.\n\n> **Tip**\n>\n>\n> * Want to use your own dataset? See [`basics/demo_custom_dataset.py`](https://deepinv.github.io/deepinv/auto_examples/basics/demo_custom_dataset.html#sphx-glr-auto-examples-basics-demo-custom-dataset-py)\n> * Want to use your own physics? See [`basics/demo_custom_physics.py`](https://deepinv.github.io/deepinv/auto_examples/basics/demo_custom_physics.html#sphx-glr-auto-examples-basics-demo-custom-physics-py)\n"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "import deepinv as dinv\nimport torch\n\ndevice = dinv.utils.get_freer_gpu() if torch.cuda.is_available() else \"cpu\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "language": "markdown"
      },
      "source": "Let's say you want to reconstruct a butterfly from noisy, blurry measurements:\n"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# Ground truth\nx = dinv.utils.load_example(\"butterfly.png\", device=device)\n\n# Define physics\nphysics = dinv.physics.BlurFFT(\n    x.shape[1:],\n    filter=dinv.physics.blur.gaussian_blur((5, 5)),\n    noise_model=dinv.physics.GaussianNoise(\n        sigma=0.1, rng=torch.Generator(device=x.device).manual_seed(123)\n    ),\n    device=device,\n)\n\ny = physics(x)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "language": "markdown"
      },
      "source": "For each model, define model in one line and reconstruct in one line.\nPretrained Reconstruct Anything Model:\n\n> **Seealso**\n>\n> See [`models/demo_foundation_model.py`](https://deepinv.github.io/deepinv/auto_examples/models/demo_foundation_model.html#sphx-glr-auto-examples-models-demo-foundation-model-py) for further one-line examples for the RAM model across various domains.\n>\n"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "model = dinv.models.RAM(pretrained=True, device=device)\n\nwith torch.no_grad():\n    x_hat1 = model(y, physics)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "language": "markdown"
      },
      "source": "PnP algorithm with pretrained denoiser:\n\n> **Seealso**\n>\n> See pretrained denoisers for a full list of denoisers that can be plugged into iterative/sampling algorithms.\n>\n> See [`plug-and-play/demo_PnP_DPIR_deblur.py`](https://deepinv.github.io/deepinv/auto_examples/plug-and-play/demo_PnP_DPIR_deblur.html#sphx-glr-auto-examples-plug-and-play-demo-PnP-DPIR-deblur-py) for a further example of using plug-and-play with a pretrained denoiser.\n>\n"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "denoiser = dinv.models.DRUNet(device=device)\nmodel = dinv.optim.DPIR(sigma=0.1, denoiser=denoiser, device=device)\n\nx_hat2 = model(y, physics)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "language": "markdown"
      },
      "source": "Pretrained diffusion model (we reduce the image size for demo speed on CPU, as diffusion model is slow):\n\n> **Seealso**\n>\n> See [`sampling/demo_ddrm.py`](https://deepinv.github.io/deepinv/auto_examples/sampling/demo_ddrm.html#sphx-glr-auto-examples-sampling-demo-ddrm-py) for a further example of using a pretrained diffusion model.\n>\n"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "model = dinv.sampling.DDRM(denoiser, sigmas=torch.linspace(1, 0, 20)).to(device)\n\nx_hat3 = model(y, physics)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "language": "markdown"
      },
      "source": "Plot results\n"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "dinv.utils.plot(\n    {\n        \"Ground Truth\": x,\n        \"Measurement\": y,\n        \"Pretrained \\nRAM\": x_hat1,\n        \"Pretrained \\nPnP\": x_hat2,\n        \"Pretrained \\nDiffusion\": x_hat3,\n    },\n    subtitles=[\n        \"PSNR:\",\n        f\"{dinv.metric.PSNR()(y, x).item():.2f} dB\",\n        f\"{dinv.metric.PSNR()(x_hat1, x).item():.2f} dB\",\n        f\"{dinv.metric.PSNR()(x_hat2, x).item():.2f} dB\",\n        f\"{dinv.metric.PSNR()(x_hat3, x).item():.2f} dB\",\n    ],\n    figsize=(10, 5),\n)\n\n\n# sphinx_gallery_start_ignore\nassert dinv.metric.PSNR()(x_hat1, x).item() > 19\n# sphinx_gallery_end_ignore"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "language": "markdown"
      },
      "source": "\ud83c\udf89 Well done, you now know how to use pretrained models!\n\n## What's next?\n* Check out the [example on how to fine-tune a foundation model to your own problem](https://deepinv.github.io/deepinv/auto_examples/models/demo_foundation_model.html#sphx-glr-auto-examples-models-demo-foundation-model-py).\n* See pretrained models for a comparison between methods demonstrated in this example.\n* See diffusion and iterative for how to fully customize your sampling or iterative algorithm using a pretrained denoiser.\n"
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}