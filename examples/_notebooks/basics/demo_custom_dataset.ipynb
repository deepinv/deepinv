{
  "cells": [
    {
      "id": "72578bb3",
      "cell_type": "code",
      "metadata": {
        "language": "python"
      },
      "execution_count": null,
      "source": "# Install deepinv (skip if already installed)\n%pip install deepinv",
      "outputs": []
    },
    {
      "id": "5dedac9a",
      "cell_type": "markdown",
      "source": "<!-- MathJax macro definitions inserted automatically -->\n$$\n\\newcommand{\\forw}[1]{{A\\left({#1}\\right)}}\n\\newcommand{\\noise}[1]{{N\\left({#1}\\right)}}\n\\newcommand{\\inverse}[1]{{R\\left({#1}\\right)}}\n\\newcommand{\\inversef}[2]{{R\\left({#1},{#2}\\right)}}\n\\newcommand{\\inversename}{R}\n\\newcommand{\\reg}[1]{{g_\\sigma\\left({#1}\\right)}}\n\\newcommand{\\regname}{g_\\sigma}\n\\newcommand{\\sensor}[1]{{\\eta\\left({#1}\\right)}}\n\\newcommand{\\datafid}[2]{{f\\left({#1},{#2}\\right)}}\n\\newcommand{\\datafidname}{f}\n\\newcommand{\\distance}[2]{{d\\left({#1},{#2}\\right)}}\n\\newcommand{\\distancename}{d}\n\\newcommand{\\denoiser}[2]{{\\operatorname{D}_{{#2}}\\left({#1}\\right)}}\n\\newcommand{\\denoisername}{\\operatorname{D}_{\\sigma}}\n\\newcommand{\\xset}{\\mathcal{X}}\n\\newcommand{\\yset}{\\mathcal{Y}}\n\\newcommand{\\group}{\\mathcal{G}}\n\\newcommand{\\metric}[2]{{d\\left({#1},{#2}\\right)}}\n\\newcommand{\\loss}[1]{{\\mathcal\\left({#1}\\right)}}\n\\newcommand{\\conj}[1]{{\\overline{#1}^{\\top}}}\n$$",
      "metadata": {
        "language": "markdown"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "language": "markdown"
      },
      "source": "\n# Bring your own dataset\n\nThis example shows how to use DeepInverse with your own dataset.\n\nA dataset in DeepInverse can consist of optional ground-truth images `x`, measurements `y`, or\nphysics parameters `params`, or any combination of these.\n\nSee datasets user guide for the formats we expect data to be returned in\nfor compatibility with DeepInverse (e.g., to be used with [`deepinv.Trainer`](https://deepinv.github.io/deepinv/api/stubs/deepinv.Trainer.html)).\n\nDeepInverse provides multiple ways of bringing your own dataset. This example has two parts:\nfirstly how to load images/data into a dataset, and secondly how to use this dataset with DeepInverse."
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "import deepinv as dinv\nimport torch\nfrom torch.utils.data import DataLoader\nfrom torchvision.transforms import ToTensor"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "language": "markdown"
      },
      "source": "## Part 1: Loading data into a dataset\n"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "language": "markdown"
      },
      "source": "### You have a folder of ground truth images\nHere we imagine we have a folder with one ground truth image of a butterfly.\n\n> **Tip**\n>\n> [`deepinv.datasets.ImageFolder`](https://deepinv.github.io/deepinv/api/stubs/deepinv.datasets.ImageFolder.html) can load any type of data (e.g. MRI, CT, etc.)\n> by passing in a custom `loader` function and `transform`.\n>\n"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "DATA_DIR = dinv.utils.get_data_home() / \"demo_custom_dataset\"\ndinv.utils.download_example(\"butterfly.png\", DATA_DIR / \"GT\")\n\ndataset1 = dinv.datasets.ImageFolder(DATA_DIR / \"GT\", transform=ToTensor())\n\n# Load one image from dataset\nx = next(iter(DataLoader(dataset1)))\n\ndinv.utils.plot({\"x\": x})"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "language": "markdown"
      },
      "source": "### You have a folder of paired ground truth and measurements\nNow imagine we have a ground truth folder with a butterfly, and a measurements folder\nwith a masked butterfly.\n"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "dinv.utils.download_example(\"butterfly_masked.png\", DATA_DIR / \"Measurements\")\n\ndataset2 = dinv.datasets.ImageFolder(\n    DATA_DIR, x_path=\"GT/*.png\", y_path=\"Measurements/*.png\", transform=ToTensor()\n)\n\nx, y = next(iter(DataLoader(dataset2)))\n\ndinv.utils.plot({\"x\": x, \"y\": y})"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "language": "markdown"
      },
      "source": "<div class=\"alert alert-info\"><h4>Note</h4><p>If you're loading measurements which have randomly varying `params`, your dataset must return\n   tuples `(x, y, params)` so that the physics is modified accordingly every image.\n   We provide a convenience argument `ImageFolder(estimate_params=...)` to help you estimate these\n   `params` on the fly.</p></div>\n"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "language": "markdown"
      },
      "source": "### You have a folder of only measurements\nImagine you have no ground truth, only measurements. Then `x` should be loaded in as NaN:\n"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "dataset3 = dinv.datasets.ImageFolder(\n    DATA_DIR, y_path=\"Measurements/*.png\", transform=ToTensor()\n)\n\nx, y = next(iter(DataLoader(dataset3)))\nprint(x)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "language": "markdown"
      },
      "source": "### You already have tensors\nSometimes you might already have tensor(s). You can construct a dataset using\n[`deepinv.datasets.TensorDataset`](https://deepinv.github.io/deepinv/api/stubs/deepinv.datasets.TensorDataset.html), for example here an unsupervised dataset\ncontaining just a single measurement (and will be loaded in as a tuple `(nan, y)`):\n"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "y = dinv.utils.load_example(\"butterfly_masked.png\")\n\ndataset4 = dinv.datasets.TensorDataset(y=y)\n\nx, y = next(iter(DataLoader(dataset4)))\nprint(x)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "language": "markdown"
      },
      "source": "### You already have a PyTorch dataset\nSay you already have your own PyTorch dataset:\n"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "class MyDataset(torch.utils.data.Dataset):\n    def __len__(self):\n        return 1\n\n    def __getitem__(self, i):  # Returns (x, y, params)\n        return torch.zeros(1), torch.zeros(1), {\"mask\": torch.zeros(1)}\n\n\ndataset5 = MyDataset()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "language": "markdown"
      },
      "source": "You should check that your dataset is compatible using [`deepinv.datasets.check_dataset`](https://deepinv.github.io/deepinv/api/stubs/deepinv.datasets.check_dataset.html)\n(alternatively inherit from [`deepinv.datasets.ImageDataset`](https://deepinv.github.io/deepinv/api/stubs/deepinv.datasets.ImageDataset.html) and use `self.check_dataset()`):\n"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "dinv.datasets.check_dataset(dataset5)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "language": "markdown"
      },
      "source": "## Part 2: Using your dataset with DeepInverse\n"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "language": "markdown"
      },
      "source": "Say you have a DeepInverse problem already set up:\n"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "device = dinv.utils.get_freer_gpu() if torch.cuda.is_available() else \"cpu\"\nphysics = dinv.physics.Inpainting(img_size=(3, 256, 256))\nmodel = dinv.models.RAM(pretrained=True, device=device)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "language": "markdown"
      },
      "source": "If your dataset already returns measurements in the form `(x, y)` or `(x, y, params)`,\nyou can directly test with it.\n\nOur physics does not yet know the `params` (here, the inpainting mask). Since it is fixed\nacross the dataset, we can define it manually by estimating it from y:\n\n<div class=\"alert alert-info\"><h4>Note</h4><p>If you're loading measurements which have randomly varying `params`, your dataset must\n   return tuples `(x, y, params)` so that the physics is modified accordingly every image.</p></div>\n"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "params = {\"mask\": (dataset2[0][1].to(device) != 0).float()}\nphysics.update(**params)\n\ndinv.test(model, DataLoader(dataset2), physics, plot_images=True, device=device)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "language": "markdown"
      },
      "source": "Even if the dataset doesn't have ground truth:\n\nHere reference-metrics such as PSNR will give NaN due to lack of ground truth, but\nno-reference metrics can be used.\n"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "metrics = [dinv.metric.PSNR(), dinv.metric.NIQE(device=device)]\n\ndinv.test(\n    model,\n    DataLoader(dataset3),\n    physics,\n    plot_images=True,\n    metrics=metrics,\n    device=device,\n)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "language": "markdown"
      },
      "source": "## Generating measurements\nIf your dataset returns only ground-truth `x`, you can generate a dataset of measurements using\n[`deepinv.datasets.generate_dataset`](https://deepinv.github.io/deepinv/api/stubs/deepinv.datasets.generate_dataset.html):\n"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "path = dinv.datasets.generate_dataset(\n    dataset1, physics, save_dir=DATA_DIR / \"measurements\", device=device\n)\ndinv.test(\n    model,\n    DataLoader(dinv.datasets.HDF5Dataset(path)),\n    physics,\n    plot_images=True,\n    device=device,\n)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "language": "markdown"
      },
      "source": "> **Tip**\n>\n>\n> Pass in a physics generator to simulate random physics and then use\n> `load_physics_generator_params=True` to load these `params` alongside the data during testing.\n>\n"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "language": "markdown"
      },
      "source": "If you don't want to generate a dataset offline, you can also generate measurements online\n(\"on-the-fly\") during testing or training:\n"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "dinv.test(\n    model,\n    DataLoader(dataset1),\n    physics,\n    plot_images=True,\n    device=device,\n    online_measurements=True,\n)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "language": "markdown"
      },
      "source": "\ud83c\udf89 Well done, you now know how to use your own dataset with DeepInverse!\n\n### What's next?\n* Check out [the example on how to test a state-of-the-art general pretrained model](https://deepinv.github.io/deepinv/auto_examples/basics/demo_pretrained_model.html#sphx-glr-auto-examples-basics-demo-pretrained-model-py) with your new dataset.\n* Check out the [example on how to fine-tune a foundation model](https://deepinv.github.io/deepinv/auto_examples/models/demo_foundation_model.html#sphx-glr-auto-examples-models-demo-foundation-model-py) to your own data.\n* Check out the [example on how to train a reconstruction model](https://deepinv.github.io/deepinv/auto_examples/models/demo_training.html#sphx-glr-auto-examples-models-demo-training-py) with your dataset.\n* Advanced: how to [stream or download a dataset from HuggingFace](https://deepinv.github.io/deepinv/auto_examples/external-libraries/demo_hf_dataset.html#sphx-glr-auto-examples-external-libraries-demo-hf-dataset-py).\n"
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}