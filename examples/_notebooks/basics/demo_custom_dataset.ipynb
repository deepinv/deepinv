{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n# Bring your own dataset\n\nThis example shows how to use DeepInverse with your own dataset.\n\nA dataset in DeepInverse can consist of optional ground-truth images `x`, measurements `y`, or\n`physics parameters <parameter-dependent-operators>` `params`, or any combination of these.\n\nSee `datasets user guide <datasets>` for the formats we expect data to be returned in\nfor compatibility with DeepInverse (e.g., to be used with :class:`deepinv.Trainer`).\n\nDeepInverse provides multiple ways of bringing your own dataset. This example has two parts:\nfirstly how to load images/data into a dataset, and secondly how to use this dataset with DeepInverse.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "import deepinv as dinv\nimport torch\nfrom torch.utils.data import DataLoader\nfrom torchvision.transforms import ToTensor"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Part 1: Loading data into a dataset\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### You have a folder of ground truth images\nHere we imagine we have a folder with one ground truth image of a butterfly.\n\n.. tip::\n   :class:`deepinv.datasets.ImageFolder` can load any type of data (e.g. MRI, CT, etc.)\n   by passing in a custom `loader` function and `transform`.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "DATA_DIR = dinv.utils.get_data_home() / \"demo_custom_dataset\"\ndinv.utils.download_example(\"butterfly.png\", DATA_DIR / \"GT\")\n\ndataset1 = dinv.datasets.ImageFolder(DATA_DIR / \"GT\", transform=ToTensor())\n\n# Load one image from dataset\nx = next(iter(DataLoader(dataset1)))\n\ndinv.utils.plot({\"x\": x})"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### You have a folder of paired ground truth and measurements\nNow imagine we have a ground truth folder with a butterfly, and a measurements folder\nwith a masked butterfly.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "dinv.utils.download_example(\"butterfly_masked.png\", DATA_DIR / \"Measurements\")\n\ndataset2 = dinv.datasets.ImageFolder(\n    DATA_DIR, x_path=\"GT/*.png\", y_path=\"Measurements/*.png\", transform=ToTensor()\n)\n\nx, y = next(iter(DataLoader(dataset2)))\n\ndinv.utils.plot({\"x\": x, \"y\": y})"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<div class=\"alert alert-info\"><h4>Note</h4><p>If you're loading measurements which have randomly varying `params`, your dataset must return\n   tuples `(x, y, params)` so that the physics is modified accordingly every image.\n   We provide a convenience argument `ImageFolder(estimate_params=...)` to help you estimate these\n   `params` on the fly.</p></div>\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### You have a folder of only measurements\nImagine you have no ground truth, only measurements. Then `x` should be loaded in as NaN:\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "dataset3 = dinv.datasets.ImageFolder(\n    DATA_DIR, y_path=\"Measurements/*.png\", transform=ToTensor()\n)\n\nx, y = next(iter(DataLoader(dataset3)))\nprint(x)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### You already have tensors\nSometimes you might already have tensor(s). You can construct a dataset using\n:class:`deepinv.datasets.TensorDataset`, for example here an unsupervised dataset\ncontaining just a single measurement (and will be loaded in as a tuple `(nan, y)`):\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "y = dinv.utils.load_example(\"butterfly_masked.png\")\n\ndataset4 = dinv.datasets.TensorDataset(y=y)\n\nx, y = next(iter(DataLoader(dataset4)))\nprint(x)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### You already have a PyTorch dataset\nSay you already have your own PyTorch dataset:\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "class MyDataset(torch.utils.data.Dataset):\n    def __len__(self):\n        return 1\n\n    def __getitem__(self, i):  # Returns (x, y, params)\n        return torch.zeros(1), torch.zeros(1), {\"mask\": torch.zeros(1)}\n\n\ndataset5 = MyDataset()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "You should check that your dataset is compatible using :func:`deepinv.datasets.check_dataset`\n(alternatively inherit from :class:`deepinv.datasets.ImageDataset` and use `self.check_dataset()`):\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "dinv.datasets.check_dataset(dataset5)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Part 2: Using your dataset with DeepInverse\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Say you have a DeepInverse problem already set up:\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "device = dinv.utils.get_freer_gpu() if torch.cuda.is_available() else \"cpu\"\nphysics = dinv.physics.Inpainting(img_size=(3, 256, 256))\nmodel = dinv.models.RAM(pretrained=True, device=device)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "If your dataset already returns measurements in the form `(x, y)` or `(x, y, params)`,\nyou can directly test with it.\n\nOur physics does not yet know the `params` (here, the inpainting mask). Since it is fixed\nacross the dataset, we can define it manually by estimating it from y:\n\n<div class=\"alert alert-info\"><h4>Note</h4><p>If you're loading measurements which have randomly varying `params`, your dataset must\n   return tuples `(x, y, params)` so that the physics is modified accordingly every image.</p></div>\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "params = {\"mask\": (dataset2[0][1].to(device) != 0).float()}\nphysics.update(**params)\n\ndinv.test(model, DataLoader(dataset2), physics, plot_images=True, device=device)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Even if the dataset doesn't have ground truth:\n\nHere reference-metrics such as PSNR will give NaN due to lack of ground truth, but\nno-reference metrics can be used.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "metrics = [dinv.metric.PSNR(), dinv.metric.NIQE(device=device)]\n\ndinv.test(\n    model,\n    DataLoader(dataset3),\n    physics,\n    plot_images=True,\n    metrics=metrics,\n    device=device,\n)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Generating measurements\nIf your dataset returns only ground-truth `x`, you can generate a dataset of measurements using\n:func:`deepinv.datasets.generate_dataset`:\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "path = dinv.datasets.generate_dataset(\n    dataset1, physics, save_dir=DATA_DIR / \"measurements\", device=device\n)\ndinv.test(\n    model,\n    DataLoader(dinv.datasets.HDF5Dataset(path)),\n    physics,\n    plot_images=True,\n    device=device,\n)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        ".. tip::\n\n   Pass in a `physics generator <physics_generators>` to simulate random physics and then use\n   `load_physics_generator_params=True` to load these `params` alongside the data during testing.\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "If you don't want to generate a dataset offline, you can also generate measurements online\n(\"on-the-fly\") during testing or training:\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "dinv.test(\n    model,\n    DataLoader(dataset1),\n    physics,\n    plot_images=True,\n    device=device,\n    online_measurements=True,\n)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\ud83c\udf89 Well done, you now know how to use your own dataset with DeepInverse!\n\n### What's next?\n* Check out `the example on how to test a state-of-the-art general pretrained model <sphx_glr_auto_examples_basics_demo_pretrained_model.py>` with your new dataset.\n* Check out the `example on how to fine-tune a foundation model <sphx_glr_auto_examples_models_demo_foundation_model.py>` to your own data.\n* Check out the `example on how to train a reconstruction model <sphx_glr_auto_examples_models_demo_training.py>` with your dataset.\n* Advanced: how to `stream or download a dataset from HuggingFace <sphx_glr_auto_examples_external-libraries_demo_hf_dataset.py>`.\n\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}