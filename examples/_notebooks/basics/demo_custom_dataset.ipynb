{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25204f30",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Bring your own dataset\n",
    "=======================\n",
    "\n",
    "This example shows how to use DeepInverse with your own dataset.\n",
    "\n",
    "A dataset in DeepInverse can consist of optional ground-truth images `x`, measurements `y`, or\n",
    ":ref:`physics parameters <parameter-dependent-operators>` `params`, or any combination of these.\n",
    "\n",
    "See :ref:`datasets user guide <datasets>` for the formats we expect data to be returned in\n",
    "for compatibility with DeepInverse (e.g., to be used with :class:`deepinv.Trainer`).\n",
    "\n",
    "DeepInverse provides multiple ways of bringing your own dataset. This example has two parts:\n",
    "firstly how to load images/data into a dataset, and secondly how to use this dataset with DeepInverse.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10625fee",
   "metadata": {},
   "outputs": [],
   "source": [
    "import deepinv as dinv\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.transforms import ToTensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c976fd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Part 1: Loading data into a dataset\n",
    "# -----------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0c2573e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# You have a folder of ground truth images\n",
    "# ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
    "# Here we imagine we have a folder with one ground truth image of a butterfly.\n",
    "#\n",
    "# .. tip::\n",
    "#    :class:`deepinv.datasets.ImageFolder` can load any type of data (e.g. MRI, CT, etc.)\n",
    "#    by passing in a custom `loader` function and `transform`.\n",
    "\n",
    "DATA_DIR = dinv.utils.get_data_home() / \"demo_custom_dataset\"\n",
    "dinv.utils.download_example(\"butterfly.png\", DATA_DIR / \"GT\")\n",
    "\n",
    "dataset1 = dinv.datasets.ImageFolder(DATA_DIR / \"GT\", transform=ToTensor())\n",
    "\n",
    "# Load one image from dataset\n",
    "x = next(iter(DataLoader(dataset1)))\n",
    "\n",
    "dinv.utils.plot({\"x\": x})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a555b738",
   "metadata": {},
   "outputs": [],
   "source": [
    "# You have a folder of paired ground truth and measurements\n",
    "# ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
    "# Now imagine we have a ground truth folder with a butterfly, and a measurements folder\n",
    "# with a masked butterfly.\n",
    "\n",
    "dinv.utils.download_example(\"butterfly_masked.png\", DATA_DIR / \"Measurements\")\n",
    "\n",
    "dataset2 = dinv.datasets.ImageFolder(\n",
    "    DATA_DIR, x_path=\"GT/*.png\", y_path=\"Measurements/*.png\", transform=ToTensor()\n",
    ")\n",
    "\n",
    "x, y = next(iter(DataLoader(dataset2)))\n",
    "\n",
    "dinv.utils.plot({\"x\": x, \"y\": y})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0791277",
   "metadata": {},
   "outputs": [],
   "source": [
    "# .. note::\n",
    "#\n",
    "#    If you're loading measurements which have randomly varying `params`, your dataset must return\n",
    "#    tuples `(x, y, params)` so that the physics is modified accordingly every image.\n",
    "#    We provide a convenience argument `ImageFolder(estimate_params=...)` to help you estimate these\n",
    "#    `params` on the fly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0fbfc05",
   "metadata": {},
   "outputs": [],
   "source": [
    "# You have a folder of only measurements\n",
    "# ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
    "# Imagine you have no ground truth, only measurements. Then `x` should be loaded in as NaN:\n",
    "\n",
    "dataset3 = dinv.datasets.ImageFolder(\n",
    "    DATA_DIR, y_path=\"Measurements/*.png\", transform=ToTensor()\n",
    ")\n",
    "\n",
    "x, y = next(iter(DataLoader(dataset3)))\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8e9fe22",
   "metadata": {},
   "outputs": [],
   "source": [
    "# You already have tensors\n",
    "# ~~~~~~~~~~~~~~~~~~~~~~~~\n",
    "# Sometimes you might already have tensor(s). You can construct a dataset using\n",
    "# :class:`deepinv.datasets.TensorDataset`, for example here an unsupervised dataset\n",
    "# containing just a single measurement (and will be loaded in as a tuple `(nan, y)`):\n",
    "\n",
    "y = dinv.utils.load_example(\"butterfly_masked.png\")\n",
    "\n",
    "dataset4 = dinv.datasets.TensorDataset(y=y)\n",
    "\n",
    "x, y = next(iter(DataLoader(dataset4)))\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "029502e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# You already have a PyTorch dataset\n",
    "# ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
    "# Say you already have your own PyTorch dataset:\n",
    "\n",
    "\n",
    "class MyDataset(torch.utils.data.Dataset):\n",
    "    def __len__(self):\n",
    "        return 1\n",
    "\n",
    "    def __getitem__(self, i):  # Returns (x, y, params)\n",
    "        return torch.zeros(1), torch.zeros(1), {\"mask\": torch.zeros(1)}\n",
    "\n",
    "\n",
    "dataset5 = MyDataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0afe6c14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# You should check that your dataset is compatible using :func:`deepinv.datasets.check_dataset`\n",
    "# (alternatively inherit from :class:`deepinv.datasets.ImageDataset` and use `self.check_dataset()`):\n",
    "\n",
    "dinv.datasets.check_dataset(dataset5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9beb3aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Part 2: Using your dataset with DeepInverse\n",
    "# -------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fef58388",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Say you have a DeepInverse problem already set up:\n",
    "\n",
    "device = dinv.utils.get_freer_gpu() if torch.cuda.is_available() else \"cpu\"\n",
    "physics = dinv.physics.Inpainting(img_size=(3, 256, 256))\n",
    "model = dinv.models.RAM(pretrained=True, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a542bce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# If your dataset already returns measurements in the form `(x, y)` or `(x, y, params)`,\n",
    "# you can directly test with it.\n",
    "#\n",
    "# Our physics does not yet know the `params` (here, the inpainting mask). Since it is fixed\n",
    "# across the dataset, we can define it manually by estimating it from y:\n",
    "#\n",
    "# .. note::\n",
    "#\n",
    "#    If you're loading measurements which have randomly varying `params`, your dataset must\n",
    "#    return tuples `(x, y, params)` so that the physics is modified accordingly every image.\n",
    "\n",
    "params = {\"mask\": (dataset2[0][1].to(device) != 0).float()}\n",
    "physics.update(**params)\n",
    "\n",
    "dinv.test(model, DataLoader(dataset2), physics, plot_images=True, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "853549c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Even if the dataset doesn't have ground truth:\n",
    "#\n",
    "# Here reference-metrics such as PSNR will give NaN due to lack of ground truth, but\n",
    "# no-reference metrics can be used.\n",
    "\n",
    "metrics = [dinv.metric.PSNR(), dinv.metric.NIQE(device=device)]\n",
    "\n",
    "dinv.test(\n",
    "    model,\n",
    "    DataLoader(dataset3),\n",
    "    physics,\n",
    "    plot_images=True,\n",
    "    metrics=metrics,\n",
    "    device=device,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db90c758",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generating measurements\n",
    "# -----------------------\n",
    "# If your dataset returns only ground-truth `x`, you can generate a dataset of measurements using\n",
    "# :func:`deepinv.datasets.generate_dataset`:\n",
    "\n",
    "path = dinv.datasets.generate_dataset(\n",
    "    dataset1, physics, save_dir=DATA_DIR / \"measurements\", device=device\n",
    ")\n",
    "dinv.test(\n",
    "    model,\n",
    "    DataLoader(dinv.datasets.HDF5Dataset(path)),\n",
    "    physics,\n",
    "    plot_images=True,\n",
    "    device=device,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f35e5288",
   "metadata": {},
   "outputs": [],
   "source": [
    "# .. tip::\n",
    "#\n",
    "#    Pass in a :ref:`physics generator <physics_generators>` to simulate random physics and then use\n",
    "#    `load_physics_generator_params=True` to load these `params` alongside the data during testing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6dda920",
   "metadata": {},
   "outputs": [],
   "source": [
    "# If you don't want to generate a dataset offline, you can also generate measurements online\n",
    "# (\"on-the-fly\") during testing or training:\n",
    "\n",
    "dinv.test(\n",
    "    model,\n",
    "    DataLoader(dataset1),\n",
    "    physics,\n",
    "    plot_images=True,\n",
    "    device=device,\n",
    "    online_measurements=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d1c34ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ðŸŽ‰ Well done, you now know how to use your own dataset with DeepInverse!\n",
    "#\n",
    "# What's next?\n",
    "# ~~~~~~~~~~~~\n",
    "# * Check out :ref:`the example on how to test a state-of-the-art general pretrained model <sphx_glr_auto_examples_basics_demo_pretrained_model.py>` with your new dataset.\n",
    "# * Check out the :ref:`example on how to fine-tune a foundation model <sphx_glr_auto_examples_models_demo_foundation_model.py>` to your own data.\n",
    "# * Check out the :ref:`example on how to train a reconstruction model <sphx_glr_auto_examples_models_demo_training.py>` with your dataset.\n",
    "# * Advanced: how to :ref:`stream or download a dataset from HuggingFace <sphx_glr_auto_examples_external-libraries_demo_hf_dataset.py>`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de7c3d18",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
