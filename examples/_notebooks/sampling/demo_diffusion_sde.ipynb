{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10c4c0bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "r\"\"\"\n",
    "Building your diffusion posterior sampling method using SDEs\n",
    "============================================================\n",
    "\n",
    "This demo shows you how to use\n",
    ":class:`deepinv.sampling.PosteriorDiffusion` to perform posterior sampling. It also can be used to perform unconditional image generation with arbitrary denoisers, if the data fidelity term is not specified.\n",
    "\n",
    "This method requires:\n",
    "\n",
    "* A well-trained denoiser with varying noise levels (ideally with large noise levels) (e.g., :class:`deepinv.models.NCSNpp`).\n",
    "\n",
    "* A (noisy) data fidelity term (e.g., :class:`deepinv.sampling.DPSDataFidelity`).\n",
    "\n",
    "* Define a drift term :math:`f(x, t)` and a diffusion term :math:`g(t)` for the forward-time SDE. They can be defined through the :class:`deepinv.sampling.DiffusionSDE` (e.g., :class:`deepinv.sampling.VarianceExplodingDiffusion`).\n",
    "\n",
    "The :class:`deepinv.sampling.PosteriorDiffusion` class can be used to perform posterior sampling for inverse problems.\n",
    "Consider the acquisition model:\n",
    "\n",
    ".. math::\n",
    "     y = \\noise{\\forw{x}}\n",
    "\n",
    "where :math:`\\forw{x}` is the forward operator (e.g., a convolutional operator) and :math:`\\noise{\\cdot}` is the noise operator (e.g., Gaussian noise).\n",
    "This class defines the reverse-time SDE for the posterior distribution :math:`p(x|y)` given the data :math:`y`:\n",
    "\n",
    ".. math::\n",
    "     d\\, x_t = \\left( f(x_t, t) - \\frac{1 + \\alpha}{2} g(t)^2 \\nabla_{x_t} \\log p_t(x_t | y) \\right) d\\,t + g(t) \\sqrt{\\alpha} d\\, w_{t}\n",
    "\n",
    "where :math:`f` is the drift term, :math:`g` is the diffusion coefficient and :math:`w` is the standard Brownian motion.\n",
    "The drift term and the diffusion coefficient are defined by the underlying (unconditional) forward-time SDE `sde`.\n",
    "In this example, we will use 2 well-known SDE in the literature: the Variance-Exploding (VE) and Variance-Preserving (VP or DDPM).\n",
    "\n",
    "The (conditional) score function :math:`\\nabla_{x_t} \\log p_t(x_t | y)` can be decomposed using the Bayes' rule:\n",
    "\n",
    ".. math::\n",
    "     \\nabla_{x_t} \\log p_t(x_t | y) = \\nabla_{x_t} \\log p_t(x_t) + \\nabla_{x_t} \\log p_t(y | x_t).\n",
    "\n",
    "The first term is the score function of the unconditional SDE, which is typically approximated by an MMSE denoiser (`denoiser`) using the well-known Tweedie's formula, while the\n",
    "second term is approximated by the (noisy) data-fidelity term (`data_fidelity`).\n",
    "We implement various data-fidelity terms in `the user guide <https://deepinv.github.io/deepinv/user_guide/reconstruction/sampling.html#id2>`_.\n",
    "\n",
    ".. note::\n",
    "\n",
    "    In this demo, we limit the number of diffusion steps for the sake of speed, but in practice, you should use a larger number of steps to obtain better results.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "498e2a72",
   "metadata": {
    "lines_to_next_cell": 0,
    "title": "Define the underlying SDE for posterior sampling"
   },
   "outputs": [],
   "source": [
    "# ---------------------------------------------------\n",
    "#\n",
    "# Let us import the necessary modules, define the denoiser and the SDE.\n",
    "#\n",
    "# In this first example, we use the Variance-Exploding SDE, whose forward process is defined as:\n",
    "#\n",
    "# .. math::\n",
    "#     d\\, x_t = g(t) d\\, w_t \\quad \\mbox{where } g(t) = \\sigma_{\\mathrm{min}}\\left( \\frac{\\sigma_{\\mathrm{max}}}{\\sigma_{\\mathrm{min}}}\\right)^t\\sqrt{2\\log\\frac{\\sigma_{\\mathrm{max}}}{\\sigma_{\\mathrm{min}}} }.\n",
    "\n",
    "import torch\n",
    "import deepinv as dinv\n",
    "from deepinv.models import NCSNpp\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "dtype = torch.float64\n",
    "figsize = 2.5\n",
    "gif_frequency = 10  # Increase this value to save the GIF saving time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d80e42f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from deepinv.sampling import (\n",
    "    PosteriorDiffusion,\n",
    "    DPSDataFidelity,\n",
    "    EulerSolver,\n",
    "    VarianceExplodingDiffusion,\n",
    ")\n",
    "from deepinv.optim import ZeroFidelity\n",
    "\n",
    "# In this example, we use the pre-trained FFHQ-64 model from the\n",
    "# EDM framework: https://arxiv.org/pdf/2206.00364 .\n",
    "# The network architecture is from Song et al: https://arxiv.org/abs/2011.13456 .\n",
    "denoiser = NCSNpp(pretrained=\"download\").to(device)\n",
    "\n",
    "# The solution is obtained by calling the SDE object with a desired solver (here, Euler).\n",
    "# The reproducibility of the SDE Solver class can be controlled by providing the pseudo-random number generator.\n",
    "num_steps = 150\n",
    "rng = torch.Generator(device).manual_seed(42)\n",
    "timesteps = torch.linspace(1, 0.001, num_steps)\n",
    "solver = EulerSolver(timesteps=timesteps, rng=rng)\n",
    "\n",
    "sigma_min = 0.005\n",
    "sigma_max = 5\n",
    "sde = VarianceExplodingDiffusion(\n",
    "    sigma_max=sigma_max,\n",
    "    sigma_min=sigma_min,\n",
    "    alpha=0.5,\n",
    "    device=device,\n",
    "    dtype=dtype,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9031cf5",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "outputs": [],
   "source": [
    "# Reverse-time SDE as sampling process\n",
    "# --------------------------------------\n",
    "#\n",
    "# When the data fidelity is not given, the posterior diffusion is equivalent to the unconditional diffusion.\n",
    "# Sampling is performed by solving the reverse-time SDE. To do so, we generate a reverse-time trajectory.\n",
    "\n",
    "model = PosteriorDiffusion(\n",
    "    data_fidelity=ZeroFidelity(),\n",
    "    sde=sde,\n",
    "    denoiser=denoiser,\n",
    "    solver=solver,\n",
    "    dtype=dtype,\n",
    "    device=device,\n",
    "    verbose=True,\n",
    ")\n",
    "x, trajectory = model(\n",
    "    y=None,\n",
    "    physics=None,\n",
    "    x_init=(1, 3, 64, 64),\n",
    "    seed=1,\n",
    "    get_trajectory=True,\n",
    ")\n",
    "dinv.utils.plot(\n",
    "    x,\n",
    "    titles=\"Unconditional generation\",\n",
    "    save_fn=\"sde_sample.png\",\n",
    "    figsize=(figsize, figsize),\n",
    ")\n",
    "\n",
    "dinv.utils.save_videos(\n",
    "    trajectory.cpu()[::gif_frequency],\n",
    "    time_dim=0,\n",
    "    titles=[\"VE-SDE Trajectory\"],\n",
    "    save_fn=\"sde_trajectory.gif\",\n",
    "    figsize=(figsize, figsize),\n",
    ")\n",
    "\n",
    "# sphinx_gallery_start_ignore\n",
    "# cleanup\n",
    "import os\n",
    "import shutil\n",
    "from pathlib import Path\n",
    "\n",
    "\n",
    "try:\n",
    "    final_dir = (\n",
    "        Path(os.getcwd()).parent.parent / \"docs\" / \"source\" / \"auto_examples\" / \"images\"\n",
    "    )\n",
    "    shutil.move(\"sde_trajectory.gif\", final_dir / \"sde_trajectory.gif\")\n",
    "    shutil.move(\"sde_sample.png\", final_dir / \"sde_sample.png\")\n",
    "except FileNotFoundError:\n",
    "    pass\n",
    "\n",
    "# sphinx_gallery_end_ignore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "592b8079",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We obtain the following unconditional sample\n",
    "#\n",
    "# .. container:: image-row\n",
    "#\n",
    "#    .. image-sg-ignore:: /auto_examples/images/sde_sample.png\n",
    "#       :alt: example of unconditional sample\n",
    "#       :srcset: /auto_examples/images/sde_sample.png\n",
    "#       :class: custom-img\n",
    "#       :ignore_missing: true\n",
    "#\n",
    "#    .. image-sg-ignore:: /auto_examples/images/sde_trajectory.gif\n",
    "#       :alt: example of unconditional trajectory\n",
    "#       :srcset: /auto_examples/images/sde_trajectory.gif\n",
    "#       :class: custom-gif\n",
    "#       :ignore_missing: true"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e196c55",
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# When the data fidelity is given, together with the measurements and the physics, this class can be used to perform posterior sampling for inverse problems.\n",
    "# For example, consider the inpainting problem, where we have a noisy image and we want to recover the original image.\n",
    "# We can use the :class:`deepinv.sampling.DPSDataFidelity` as the data fidelity term.\n",
    "\n",
    "del trajectory  # clean memory\n",
    "mask = torch.ones_like(x)\n",
    "mask[..., 24:40, 24:40] = 0.0\n",
    "physics = dinv.physics.Inpainting(img_size=x.shape[1:], mask=mask, device=device)\n",
    "y = physics(x)\n",
    "\n",
    "weight = 3.0  # guidance strength\n",
    "dps_fidelity = DPSDataFidelity(denoiser=denoiser, weight=weight)\n",
    "\n",
    "model = PosteriorDiffusion(\n",
    "    data_fidelity=dps_fidelity,\n",
    "    denoiser=denoiser,\n",
    "    sde=sde,\n",
    "    solver=solver,\n",
    "    dtype=dtype,\n",
    "    device=device,\n",
    "    verbose=True,\n",
    ")\n",
    "\n",
    "# To perform posterior sampling, we need to provide the measurements, the physics and the solver.\n",
    "# Moreover, when the physics is given, the initial point can be inferred from the physics if not given explicitly.\n",
    "seed_1 = 11\n",
    "x_hat, trajectory = model(\n",
    "    y,\n",
    "    physics,\n",
    "    seed=seed_1,\n",
    "    get_trajectory=True,\n",
    ")\n",
    "# Here, we plot the original image, the measurement and the posterior sample\n",
    "dinv.utils.plot(\n",
    "    [x, y, x_hat],\n",
    "    show=True,\n",
    "    titles=[\"Original\", \"Measurement\", \"Posterior sample\"],\n",
    "    save_fn=\"posterior_sample.png\",\n",
    "    figsize=(figsize * 3, figsize),\n",
    ")\n",
    "# We can also save the trajectory of the posterior sample\n",
    "dinv.utils.save_videos(\n",
    "    trajectory[::gif_frequency],\n",
    "    time_dim=0,\n",
    "    titles=[\"Posterior sample with VE\"],\n",
    "    save_fn=\"posterior_trajectory.gif\",\n",
    "    figsize=(figsize, figsize),\n",
    ")\n",
    "# sphinx_gallery_start_ignore\n",
    "# cleanup\n",
    "import os\n",
    "import shutil\n",
    "from pathlib import Path\n",
    "\n",
    "try:\n",
    "    final_dir = (\n",
    "        Path(os.getcwd()).parent.parent / \"docs\" / \"source\" / \"auto_examples\" / \"images\"\n",
    "    )\n",
    "    shutil.move(\"posterior_trajectory.gif\", final_dir / \"posterior_trajectory.gif\")\n",
    "    shutil.move(\"posterior_sample.png\", final_dir / \"posterior_sample.png\")\n",
    "\n",
    "except FileNotFoundError:\n",
    "    pass\n",
    "\n",
    "\n",
    "# sphinx_gallery_end_ignore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88fbff0e",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "# We obtain the following posterior sample and trajectory\n",
    "#\n",
    "# .. container:: image-col\n",
    "#\n",
    "#    .. image-sg-ignore:: /auto_examples/images/posterior_sample.png\n",
    "#       :alt: example of posterior sample\n",
    "#       :srcset: /auto_examples/images/posterior_sample.png\n",
    "#       :ignore_missing: true\n",
    "#\n",
    "#    .. image-sg-ignore:: /auto_examples/images/posterior_trajectory.gif\n",
    "#       :alt: example of posterior trajectory\n",
    "#       :srcset: /auto_examples/images/posterior_trajectory.gif\n",
    "#       :ignore_missing: true\n",
    "#       :class: custom-gif"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4eb49777",
   "metadata": {},
   "outputs": [],
   "source": [
    "#   .. note::\n",
    "#\n",
    "#       **Reproducibility**: To ensure the reproducibility, if the parameter `rng` is given, the same sample will\n",
    "#       be generated when the same seed is used.\n",
    "#       One can obtain varying samples by using a different seed.\n",
    "#\n",
    "#       **Parallel sampling**: one can draw multiple samples in parallel by giving the initial shape, e.g., `x_init = (B, C, H, W)`\n",
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4c70513",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Varying the SDE\n",
    "# ---------------\n",
    "#\n",
    "# One can also change the underlying SDE for sampling.\n",
    "# For example, we can also use the Variance-Preserving (VP or DDPM) in :class:`deepinv.sampling.VariancePreservingDiffusion`, whose forward drift and diffusion term are defined as:\n",
    "#\n",
    "# .. math::\n",
    "#     f(x_t, t) = -\\frac{1}{2} \\beta(t)x_t \\qquad \\mbox{ and } \\qquad g(t) = \\beta(t)  \\qquad \\mbox{ with } \\beta(t) = \\beta_{\\mathrm{min}}  + t \\left( \\beta_{\\mathrm{max}} - \\beta_{\\mathrm{min}} \\right).\n",
    "\n",
    "from deepinv.sampling import VariancePreservingDiffusion\n",
    "\n",
    "del trajectory\n",
    "sde = VariancePreservingDiffusion(device=device, dtype=dtype)\n",
    "model = PosteriorDiffusion(\n",
    "    data_fidelity=dps_fidelity,\n",
    "    denoiser=denoiser,\n",
    "    sde=sde,\n",
    "    solver=solver,\n",
    "    device=device,\n",
    "    dtype=dtype,\n",
    "    verbose=True,\n",
    ")\n",
    "\n",
    "x_hat_vp, trajectory = model(\n",
    "    y,\n",
    "    physics,\n",
    "    seed=111,\n",
    "    timesteps=torch.linspace(1, 0.001, 150),\n",
    "    get_trajectory=True,\n",
    ")\n",
    "dinv.utils.plot(\n",
    "    [x_hat, x_hat_vp],\n",
    "    titles=[\n",
    "        \"posterior sample with VE\",\n",
    "        \"posterior sample with VP\",\n",
    "    ],\n",
    "    save_fn=\"posterior_sample_ve_vp.png\",\n",
    "    figsize=(figsize * 3, figsize),\n",
    ")\n",
    "\n",
    "\n",
    "# We can also save the trajectory of the posterior sample\n",
    "dinv.utils.save_videos(\n",
    "    trajectory[::gif_frequency],\n",
    "    time_dim=0,\n",
    "    titles=[\"Posterior sample with VP\"],\n",
    "    save_fn=\"posterior_trajectory_vp.gif\",\n",
    "    figsize=(figsize, figsize),\n",
    ")\n",
    "\n",
    "# sphinx_gallery_start_ignore\n",
    "# cleanup\n",
    "import os\n",
    "import shutil\n",
    "from pathlib import Path\n",
    "\n",
    "try:\n",
    "    final_dir = (\n",
    "        Path(os.getcwd()).parent.parent / \"docs\" / \"source\" / \"auto_examples\" / \"images\"\n",
    "    )\n",
    "    shutil.move(\"posterior_sample_ve_vp.png\", final_dir / \"posterior_sample_ve_vp.png\")\n",
    "    shutil.move(\n",
    "        \"posterior_trajectory_vp.gif\", final_dir / \"posterior_trajectory_vp.gif\"\n",
    "    )\n",
    "\n",
    "except FileNotFoundError:\n",
    "    pass\n",
    "\n",
    "# sphinx_gallery_end_ignore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76542dc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can comparing the sampling trajectory depending on the underlying SDE\n",
    "#\n",
    "# .. container:: image-col\n",
    "#\n",
    "#    .. image-sg-ignore:: /auto_examples/images/posterior_sample_ve_vp.png\n",
    "#       :alt: posterior sample with VP\n",
    "#       :srcset: /auto_examples/images/posterior_sample_ve_vp.png\n",
    "#       :ignore_missing: true\n",
    "#    .. container:: image-row\n",
    "#\n",
    "#       .. image-sg-ignore:: /auto_examples/images/posterior_trajectory.gif\n",
    "#           :alt: posterior trajectory with VE\n",
    "#           :srcset: /auto_examples/images/posterior_trajectory.gif\n",
    "#           :ignore_missing: true\n",
    "#           :class: custom-gif\n",
    "#\n",
    "#       .. image-sg-ignore:: /auto_examples/images/posterior_trajectory_vp.gif\n",
    "#           :alt: posterior trajectory with VP\n",
    "#           :srcset: /auto_examples/images/posterior_trajectory_vp.gif\n",
    "#           :ignore_missing: true\n",
    "#           :class: custom-gif"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f176c38",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plug-and-play Posterior Sampling with arbitrary denoisers\n",
    "# ---------------------------------------------------------\n",
    "#\n",
    "# The :class:`deepinv.sampling.PosteriorDiffusion` class can be used together with any (well-trained) denoisers for posterior sampling.\n",
    "# For example, we can use the :class:`deepinv.models.DRUNet` for posterior sampling.\n",
    "# We can also change the underlying SDE, for example change the `sigma_max` value.\n",
    "\n",
    "del trajectory  # clean memory\n",
    "sigma_min = 0.001\n",
    "sigma_max = 10.0\n",
    "rng = torch.Generator(device)\n",
    "dtype = torch.float32\n",
    "timesteps = torch.linspace(1, 0.001, 250)\n",
    "solver = EulerSolver(timesteps=timesteps, rng=rng)\n",
    "denoiser = dinv.models.DRUNet(pretrained=\"download\").to(device)\n",
    "\n",
    "sde = VarianceExplodingDiffusion(\n",
    "    sigma_max=sigma_max, sigma_min=sigma_min, alpha=0.75, device=device, dtype=dtype\n",
    ")\n",
    "x = dinv.utils.load_example(\n",
    "    \"butterfly.png\",\n",
    "    img_size=256,\n",
    "    resize_mode=\"resize\",\n",
    ").to(device)\n",
    "\n",
    "mask = torch.ones_like(x)\n",
    "mask[..., 70:150, 120:180] = 0\n",
    "physics = dinv.physics.Inpainting(\n",
    "    mask=mask,\n",
    "    img_size=x.shape[1:],\n",
    "    device=device,\n",
    ")\n",
    "\n",
    "y = physics(x)\n",
    "model = PosteriorDiffusion(\n",
    "    data_fidelity=DPSDataFidelity(denoiser=denoiser, weight=0.3),\n",
    "    denoiser=denoiser,\n",
    "    sde=sde,\n",
    "    solver=solver,\n",
    "    dtype=dtype,\n",
    "    device=device,\n",
    "    verbose=True,\n",
    ")\n",
    "\n",
    "# To perform posterior sampling, we need to provide the measurements, the physics and the solver.\n",
    "x_hat, trajectory = model(\n",
    "    y=y,\n",
    "    physics=physics,\n",
    "    seed=12,\n",
    "    get_trajectory=True,\n",
    ")\n",
    "\n",
    "# Here, we plot the original image, the measurement and the posterior sample\n",
    "dinv.utils.plot(\n",
    "    [x, y, x_hat.clip(0, 1)],\n",
    "    titles=[\"Original\", \"Measurement\", \"Posterior sample DRUNet\"],\n",
    "    figsize=(figsize * 3, figsize),\n",
    "    save_fn=\"posterior_sample_DRUNet.png\",\n",
    ")\n",
    "\n",
    "# We can also save the trajectory of the posterior sample\n",
    "dinv.utils.save_videos(\n",
    "    trajectory[::gif_frequency].clip(0, 1),\n",
    "    time_dim=0,\n",
    "    titles=[\"Posterior trajectory DRUNet\"],\n",
    "    save_fn=\"posterior_sample_DRUNet.gif\",\n",
    "    figsize=(figsize, figsize),\n",
    ")\n",
    "\n",
    "# sphinx_gallery_start_ignore\n",
    "# cleanup\n",
    "import os\n",
    "import shutil\n",
    "from pathlib import Path\n",
    "\n",
    "try:\n",
    "    final_dir = (\n",
    "        Path(os.getcwd()).parent.parent / \"docs\" / \"source\" / \"auto_examples\" / \"images\"\n",
    "    )\n",
    "    shutil.move(\n",
    "        \"posterior_sample_DRUNet.png\", final_dir / \"posterior_sample_DRUNet.png\"\n",
    "    )\n",
    "    shutil.move(\n",
    "        \"posterior_sample_DRUNet.gif\", final_dir / \"posterior_sample_DRUNet.gif\"\n",
    "    )\n",
    "\n",
    "except FileNotFoundError:\n",
    "    pass\n",
    "\n",
    "# sphinx_gallery_end_ignore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "918cab51",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We obtain the following posterior trajectory\n",
    "#\n",
    "# .. container:: image-col\n",
    "#\n",
    "#    .. image-sg-ignore:: /auto_examples/images/posterior_sample_DRUNet.png\n",
    "#       :alt: posterior sample DRUNet\n",
    "#       :srcset: /auto_examples/images/posterior_sample_DRUNet.png\n",
    "#       :ignore_missing: true\n",
    "#\n",
    "#    .. image-sg-ignore:: /auto_examples/images/posterior_sample_DRUNet.gif\n",
    "#       :alt: posterior trajectory DRUNet\n",
    "#       :srcset: /auto_examples/images/posterior_sample_DRUNet.gif\n",
    "#       :ignore_missing: true\n",
    "#       :class: custom-gif"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "title,-all",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
