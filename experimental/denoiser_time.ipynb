{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/miniconda/base/envs/deepinv/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "from deepinv.models import DRUNet\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_channels = 1\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "img_shape = (5, 1, 128, 128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "denoiser = DRUNet(\n",
    "    in_channels=n_channels,\n",
    "    out_channels=n_channels,\n",
    "    pretrained=\"download\",  # automatically downloads the pretrained weights, set to a path to use custom weights.\n",
    "    train=False,\n",
    "    device=device,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.float32, torch.float32)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img = torch.randn(img_shape, device=device, dtype=torch.cfloat)\n",
    "img_abs = torch.abs(img)\n",
    "img_phase = torch.angle(img)\n",
    "img_abs.dtype, img_phase.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken:  157.50350689888\n"
     ]
    }
   ],
   "source": [
    "# process amplitude and phase separately\n",
    "start = time.time()\n",
    "for _ in range(100):\n",
    "    img = torch.randn(img_shape, device=device, dtype=torch.cfloat)\n",
    "    img_abs = torch.abs(img)\n",
    "    img_phase = torch.angle(img)\n",
    "    img_abs_denoised = denoiser(img_abs, sigma=0.03)\n",
    "    img_phase_denoised = denoiser(img_phase, sigma=0.03)\n",
    "    img_denoised = img_abs_denoised * torch.exp(1j * img_phase_denoised)\n",
    "end = time.time()\n",
    "print(\"Time taken: \", end - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken:  155.910080909729\n"
     ]
    }
   ],
   "source": [
    "# process amplitude and phase together\n",
    "start = time.time()\n",
    "for _ in range(100):\n",
    "    img = torch.randn(img_shape, device=device, dtype=torch.cfloat)\n",
    "    img_abs = torch.abs(img)\n",
    "    img_phase = torch.angle(img)\n",
    "    noisy_batch = torch.cat((img_abs, img_phase), 0)\n",
    "    denoised_batch = denoiser(noisy_batch, sigma=0.03)\n",
    "    #print(denoised_batch[:img_abs.shape[0]].shape, denoised_batch[img_phase.shape[0]:].shape)\n",
    "    img_denoised = denoised_batch[:img_abs.shape[0]] * torch.exp(1j * denoised_batch[img_phase.shape[0]:])\n",
    "end = time.time()\n",
    "print(\"Time taken: \", end - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.5055)\n",
      "tensor(1.)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[1.0000],\n",
       "        [1.0000],\n",
       "        [1.0000]])"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.manual_seed(0)\n",
    "\n",
    "x = torch.randn(3, 3, 9, 9)\n",
    "\n",
    "x_1 = x/torch.linalg.norm(x, keepdim=True)  # Normalizes the full batch\n",
    "x_2 = x/torch.linalg.norm(x, dim=(2,3), keepdim=True)  # Normalizes each sub-tensor of the batch\n",
    "\n",
    "print(x_1[2].norm())  # torch.linalg.norm(x_1) = 1\n",
    "print(x_2[2].norm())  # will contain unit elements\n",
    "\n",
    "torch.linalg.norm(x_2, dim=(2,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1.)"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.randn(3, 3, 9, 9)\n",
    "x[0] = x[0] / torch.linalg.norm(x[0])\n",
    "x[1] = x[1] / torch.linalg.norm(x[1])\n",
    "x[2] = x[2] / torch.linalg.norm(x[2])\n",
    "x[0].norm()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(1.0000), tensor(1.0000), tensor(1.0000))"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = torch.randn(3, 100)\n",
    "res = y / torch.mean(y, dim=1,keepdim=True)\n",
    "res[0].mean(), res[1].mean(), res[2].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(34.5784),\n",
       " tensor(1.),\n",
       " tensor(34.7137),\n",
       " tensor(1.0000),\n",
       " tensor(32.8030),\n",
       " tensor(1.))"
      ]
     },
     "execution_count": 183,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.randn(3, 3, 23, 17)\n",
    "normalized_x = torch.stack([subtensor/subtensor.norm() for subtensor in x])\n",
    "\n",
    "x[0].norm(), normalized_x[0].norm(), x[1].norm(), normalized_x[1].norm(), x[2].norm(), normalized_x[2].norm()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 9, 9])\n",
      "torch.Size([3, 9, 9])\n",
      "torch.Size([3, 9, 9])\n"
     ]
    }
   ],
   "source": [
    "for subtensor in x:\n",
    "    print(subtensor.shape)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deepinv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
