{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import deepinv\n",
    "\n",
    "from deepinv.physics.phase_retrieval import RandomPhaseRetrieval, PseudoRandomPhaseRetrieval\n",
    "from deepinv.utils import randn_like\n",
    "from deepinv.physics.forward import adjoint_function\n",
    "from deepinv.optim.data_fidelity import L2, AmplitudeLoss\n",
    "from deepinv.utils.plotting import plot\n",
    "from deepinv.utils.demo import load_url_image, get_image_url\n",
    "from deepinv.optim.phase_retrieval import cosine_similarity, correct_global_phase, spectral_methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_norm(model,x0, max_iter=100, tol=1e-3, verbose=True):\n",
    "    r\"\"\"\n",
    "    Computes the spectral :math:`\\ell_2` norm (Lipschitz constant) of the operator\n",
    "\n",
    "    :math:`A^{\\top}A`, i.e., :math:`\\|A^{\\top}A\\|`.\n",
    "\n",
    "    using the `power method <https://en.wikipedia.org/wiki/Power_iteration>`_.\n",
    "\n",
    "    :param torch.Tensor x0: initialisation point of the algorithm\n",
    "    :param int max_iter: maximum number of iterations\n",
    "    :param float tol: relative variation criterion for convergence\n",
    "    :param bool verbose: print information\n",
    "\n",
    "    :returns z: (float) spectral norm of :math:`A^{\\top}A`, i.e., :math:`\\|A^{\\top}A\\|`.\n",
    "    \"\"\"\n",
    "    x = torch.randn_like(x0)\n",
    "    x /= torch.norm(x)\n",
    "    zold = torch.zeros_like(x)\n",
    "    print(\"zold\",zold)\n",
    "    for it in range(max_iter):\n",
    "        y = model.A(x)\n",
    "        y = model.A_adjoint(y)\n",
    "        z = torch.matmul(x.reshape(-1), y.reshape(-1)) / torch.norm(x) ** 2\n",
    "        #print(\"z\",z)\n",
    "        rel_var = torch.norm(z - zold)\n",
    "        if rel_var < tol and verbose:\n",
    "            print(\n",
    "                f\"Power iteration converged at iteration {it}, value={z.item():.2f}\"\n",
    "            )\n",
    "            break\n",
    "        zold = z\n",
    "        x = y / torch.norm(y)\n",
    "\n",
    "    return z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/g7/kcfjzxyn1klcs6f0xk8vby0w0000gn/T/ipykernel_43602/2840899565.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  x = torch.tensor(x, device=device, dtype=torch.float)\n"
     ]
    }
   ],
   "source": [
    "# Set the global random seed from pytorch to ensure reproducibility of the example.\n",
    "torch.manual_seed(0)\n",
    "\n",
    "device = deepinv.utils.get_freer_gpu() if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "url = get_image_url(\"CBSD_0010.png\")\n",
    "x = load_url_image(url, grayscale=False).to(device)\n",
    "\n",
    "x = torch.tensor(x, device=device, dtype=torch.float)\n",
    "x = torch.nn.functional.interpolate(x, size=(16, 16))\n",
    "\n",
    "x = x.to(torch.cfloat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 3, 20, 20])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "physics = PseudoRandomPhaseRetrieval(2, (3, 16, 16),2)\n",
    "\n",
    "torch.allclose(x - physics.B_adjoint(physics.B(x)),torch.tensor(0.0+0.0j))\n",
    "physics(x).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "physics2 = RandomPhaseRetrieval(5*3*16*16, (3, 16, 16))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([21.+0.0000j, -3.+5.1962j, -3.+1.7321j, -3.+0.0000j, -3.-1.7321j,\n",
       "        -3.-5.1962j])"
      ]
     },
     "execution_count": 178,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = torch.tensor([1,2,3,4,5,6])\n",
    "torch.fft.fft(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[[ 1.5126,  3.6288,  2.1499],\n",
      "          [ 1.2216,  2.1887, -0.8486],\n",
      "          [ 0.4221,  6.5647,  0.8041]]]], grad_fn=<ViewBackward0>)\n",
      "tensor([[[[ 1.5126,  3.6288,  2.1499],\n",
      "          [ 1.2216,  2.1887, -0.8486],\n",
      "          [ 0.4221,  6.5647,  0.8041]]]], grad_fn=<ViewBackward0>)\n"
     ]
    }
   ],
   "source": [
    "x = torch.randn((1, 1, 3, 3), dtype=torch.float, requires_grad=True)\n",
    "physics = deepinv.physics.CompressedSensing(\n",
    "    m=10, img_shape=(1, 3, 3), dtype=torch.float\n",
    ")\n",
    "loss = L2()\n",
    "func = lambda x: loss(x, torch.ones_like(physics(x)), physics)[0]\n",
    "# grad_value = torch.func.grad(func)(x)\n",
    "print(loss.grad(x, torch.ones_like(physics(x)), physics))\n",
    "# assert torch.isclose(grad_value[0], jvp_value, rtol=1e-5).all()\n",
    "print(torch.func.grad(func)(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[[ 0.0797+1.0785j,  0.2736+1.5841j, -0.5817+0.4442j],\n",
      "          [ 1.4804+0.0176j, -0.5149-0.3055j, -0.8389+0.5117j],\n",
      "          [-1.6124-1.0875j, -1.7800+0.9745j,  0.4210+1.6172j]]]],\n",
      "       requires_grad=True)\n",
      "tensor([[6.1272, 0.5628, 3.1397, 2.6942, 4.7124, 0.2080, 3.1730, 0.1719, 3.9874,\n",
      "         0.8332]], grad_fn=<PowBackward0>)\n",
      "tensor([[[[nan+nanj, nan+nanj, nan+nanj],\n",
      "          [nan+nanj, nan+nanj, nan+nanj],\n",
      "          [nan+nanj, nan+nanj, nan+nanj]]]], grad_fn=<CloneBackward0>)\n"
     ]
    }
   ],
   "source": [
    "x = torch.randn((1, 1, 3, 3), dtype=torch.cfloat, requires_grad=True)\n",
    "physics = deepinv.physics.RandomPhaseRetrieval(\n",
    "    m=10, img_shape=(1, 3, 3), dtype=torch.cfloat\n",
    ")\n",
    "print(x)\n",
    "y = physics.A(x)\n",
    "print(y)\n",
    "print(physics.A_dagger(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[ 0.8858-1.4252j,  0.4933-1.2174j, -1.4996+1.6350j],\n",
       "          [-0.3503-0.1512j,  1.0030+0.2949j,  0.4901+0.2424j],\n",
       "          [ 2.2457+0.3787j, -0.1436-2.0321j, -0.8641-0.9089j]]]],\n",
       "       grad_fn=<ViewBackward0>)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = physics(x)\n",
    "y.shape\n",
    "physics.B_adjoint(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hasattr(physics, 'B')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 354,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([6.4934, 9.5337, 6.0647, 5.2444, 4.5400], grad_fn=<PowBackward0>)"
      ]
     },
     "execution_count": 354,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss = AmplitudeLoss()\n",
    "x = torch.randn((5, 1, 3, 3), dtype=torch.cfloat, requires_grad=True)\n",
    "physics = deepinv.physics.CompressedSensing(\n",
    "    m=10, img_shape=(1, 3, 3), dtype=torch.cfloat\n",
    ")\n",
    "loss(x, torch.ones_like(physics(x)), physics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1., 1., 1.])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.Tensor([1, 2, 3])\n",
    "func = lambda x: x.sum()\n",
    "grad_value = torch.func.grad(func)(x)\n",
    "grad_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Power iteration converged at iteration 12, value=2.86-0.00j\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor(2.8610)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "physics = deepinv.physics.CompressedSensing(\n",
    "    m=10, img_shape=(1, 3, 3), dtype=torch.cfloat\n",
    ")\n",
    "physics.compute_norm(torch.randn((1, 1, 3, 3),dtype=torch.cfloat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1., 2., 3.], dtype=torch.float64)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A = torch.eye(3, dtype=torch.float64)\n",
    "def A_forward(v):\n",
    "    return A @ v\n",
    "\n",
    "physics = deepinv.physics.Physics(A=A_forward)\n",
    "\n",
    "x = torch.tensor([1,2,3],dtype=torch.float64)\n",
    "physics(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x tensor([-0.0437, -2.2669, -1.1095], dtype=torch.float64)\n",
      "v tensor([-0.4212,  0.5659,  0.7871], dtype=torch.float64)\n",
      "A_jvp tensor([-0.4212,  0.5659,  0.7871], dtype=torch.float64)\n",
      "x tensor([1.9426, 1.4612, 0.9582], dtype=torch.float64)\n",
      "v tensor([ 0.4383, -1.1001, -0.6980], dtype=torch.float64)\n",
      "A_jvp tensor([ 0.4383, -1.1001, -0.6980], dtype=torch.float64)\n",
      "x tensor([-0.3678, -0.8955, -1.6981], dtype=torch.float64)\n",
      "v tensor([ 0.2353, -2.0151, -1.0602], dtype=torch.float64)\n",
      "A_jvp tensor([ 0.2353, -2.0151, -1.0602], dtype=torch.float64)\n",
      "x tensor([-0.6248,  1.6312, -0.2137], dtype=torch.float64)\n",
      "v tensor([-0.1252, -0.5810, -1.0189], dtype=torch.float64)\n",
      "A_jvp tensor([-0.1252, -0.5810, -1.0189], dtype=torch.float64)\n",
      "x tensor([-2.8340,  0.6608, -1.3493], dtype=torch.float64)\n",
      "v tensor([0.8876, 0.0263, 1.3302], dtype=torch.float64)\n",
      "A_jvp tensor([0.8876, 0.0263, 1.3302], dtype=torch.float64)\n",
      "x tensor([ 0.4767, -1.5042,  0.2863], dtype=torch.float64)\n",
      "v tensor([-0.1405, -0.9067, -0.9800], dtype=torch.float64)\n",
      "A_jvp tensor([-0.1405, -0.9067, -0.9800], dtype=torch.float64)\n",
      "x tensor([ 1.6419, -0.7131,  0.3443], dtype=torch.float64)\n",
      "v tensor([-1.1408, -0.3745,  0.6315], dtype=torch.float64)\n",
      "A_jvp tensor([-1.1408, -0.3745,  0.6315], dtype=torch.float64)\n",
      "x tensor([ 0.6065,  0.7204, -0.4938], dtype=torch.float64)\n",
      "v tensor([-0.1599,  1.5378,  0.4936], dtype=torch.float64)\n",
      "A_jvp tensor([-0.1599,  1.5378,  0.4936], dtype=torch.float64)\n",
      "x tensor([-0.3581,  0.2084, -0.6838], dtype=torch.float64)\n",
      "v tensor([-1.6808, -0.3487,  0.1976], dtype=torch.float64)\n",
      "A_jvp tensor([-1.6808, -0.3487,  0.1976], dtype=torch.float64)\n",
      "x tensor([ 0.2014,  0.3190, -0.8291], dtype=torch.float64)\n",
      "v tensor([0.5383, 1.5105, 1.0814], dtype=torch.float64)\n",
      "A_jvp tensor([0.5383, 1.5105, 1.0814], dtype=torch.float64)\n",
      "x tensor([-0.6649, -0.0449, -0.1029], dtype=torch.float64)\n",
      "v tensor([-1.6061,  0.1478,  0.3555], dtype=torch.float64)\n",
      "A_jvp tensor([-1.6061,  0.1478,  0.3555], dtype=torch.float64)\n",
      "x tensor([-0.9251, -1.4593,  0.7594], dtype=torch.float64)\n",
      "v tensor([-0.6618,  0.2099, -1.2740], dtype=torch.float64)\n",
      "A_jvp tensor([-0.6618,  0.2099, -1.2740], dtype=torch.float64)\n",
      "x tensor([-0.2697, -0.4802,  0.2103], dtype=torch.float64)\n",
      "v tensor([-1.3085, -1.7273, -0.1300], dtype=torch.float64)\n",
      "A_jvp tensor([-1.3085, -1.7273, -0.1300], dtype=torch.float64)\n",
      "x tensor([0.7559, 2.1981, 0.8859], dtype=torch.float64)\n",
      "v tensor([ 1.3217, -1.2846,  0.2309], dtype=torch.float64)\n",
      "A_jvp tensor([ 1.3217, -1.2846,  0.2309], dtype=torch.float64)\n",
      "x tensor([-0.4873,  0.7622,  0.3438], dtype=torch.float64)\n",
      "v tensor([-1.7317, -0.7251, -0.1872], dtype=torch.float64)\n",
      "A_jvp tensor([-1.7317, -0.7251, -0.1872], dtype=torch.float64)\n",
      "x tensor([ 0.9442, -2.0466, -1.2360], dtype=torch.float64)\n",
      "v tensor([ 1.3883,  1.8134, -0.9380], dtype=torch.float64)\n",
      "A_jvp tensor([ 1.3883,  1.8134, -0.9380], dtype=torch.float64)\n",
      "x tensor([-1.5911,  0.4809,  0.2895], dtype=torch.float64)\n",
      "v tensor([ 1.8956, -1.0076,  0.1238], dtype=torch.float64)\n",
      "A_jvp tensor([ 1.8956, -1.0076,  0.1238], dtype=torch.float64)\n",
      "x tensor([0.5013, 0.5477, 0.3307], dtype=torch.float64)\n",
      "v tensor([ 0.4628, -1.1168, -1.1110], dtype=torch.float64)\n",
      "A_jvp tensor([ 0.4628, -1.1168, -1.1110], dtype=torch.float64)\n",
      "x tensor([-0.8158,  0.2630,  0.5769], dtype=torch.float64)\n",
      "v tensor([ 0.2336, -1.8600,  0.5459], dtype=torch.float64)\n",
      "A_jvp tensor([ 0.2336, -1.8600,  0.5459], dtype=torch.float64)\n",
      "x tensor([-0.4170,  1.2585, -0.7479], dtype=torch.float64)\n",
      "v tensor([ 0.2011, -0.2032, -1.6608], dtype=torch.float64)\n",
      "A_jvp tensor([ 0.2011, -0.2032, -1.6608], dtype=torch.float64)\n",
      "x tensor([0.2317, 0.5577, 1.0065], dtype=torch.float64)\n",
      "v tensor([-0.9092,  1.6777,  0.7851], dtype=torch.float64)\n",
      "A_jvp tensor([-0.9092,  1.6777,  0.7851], dtype=torch.float64)\n",
      "x tensor([ 1.2373, -0.5964,  0.0393], dtype=torch.float64)\n",
      "v tensor([-1.0637,  1.0407, -0.3428], dtype=torch.float64)\n",
      "A_jvp tensor([-1.0637,  1.0407, -0.3428], dtype=torch.float64)\n",
      "x tensor([-0.9479, -1.0832,  0.5282], dtype=torch.float64)\n",
      "v tensor([-0.0684, -2.2276, -1.7168], dtype=torch.float64)\n",
      "A_jvp tensor([-0.0684, -2.2276, -1.7168], dtype=torch.float64)\n",
      "x tensor([-0.4776, -0.1745, -0.0442], dtype=torch.float64)\n",
      "v tensor([ 0.6069,  0.3468, -0.1771], dtype=torch.float64)\n",
      "A_jvp tensor([ 0.6069,  0.3468, -0.1771], dtype=torch.float64)\n",
      "x tensor([ 0.3863,  1.1681, -0.1284], dtype=torch.float64)\n",
      "v tensor([-0.1161,  1.1409,  0.2396], dtype=torch.float64)\n",
      "A_jvp tensor([-0.1161,  1.1409,  0.2396], dtype=torch.float64)\n",
      "x tensor([ 0.3055, -1.1098,  1.3854], dtype=torch.float64)\n",
      "v tensor([-0.5326,  1.5922,  0.1978], dtype=torch.float64)\n",
      "A_jvp tensor([-0.5326,  1.5922,  0.1978], dtype=torch.float64)\n",
      "x tensor([-0.4913, -1.1717,  0.2398], dtype=torch.float64)\n",
      "v tensor([-0.5820,  0.3781, -0.7533], dtype=torch.float64)\n",
      "A_jvp tensor([-0.5820,  0.3781, -0.7533], dtype=torch.float64)\n",
      "x tensor([ 1.4311, -1.5980,  1.2493], dtype=torch.float64)\n",
      "v tensor([-0.7283, -0.3309, -0.2489], dtype=torch.float64)\n",
      "A_jvp tensor([-0.7283, -0.3309, -0.2489], dtype=torch.float64)\n",
      "x tensor([-1.3057,  0.8372, -1.5112], dtype=torch.float64)\n",
      "v tensor([ 0.9209, -0.3548, -0.4917], dtype=torch.float64)\n",
      "A_jvp tensor([ 0.9209, -0.3548, -0.4917], dtype=torch.float64)\n",
      "x tensor([ 0.5052, -1.5614, -1.7465], dtype=torch.float64)\n",
      "v tensor([-1.0487,  1.8276,  0.9385], dtype=torch.float64)\n",
      "A_jvp tensor([-1.0487,  1.8276,  0.9385], dtype=torch.float64)\n",
      "x tensor([-1.2194, -0.5964,  0.2724], dtype=torch.float64)\n",
      "v tensor([-1.1867,  1.2514,  0.0925], dtype=torch.float64)\n",
      "A_jvp tensor([-1.1867,  1.2514,  0.0925], dtype=torch.float64)\n",
      "x tensor([0.1692, 0.6788, 0.9211], dtype=torch.float64)\n",
      "v tensor([ 1.6501, -0.0147,  0.0374], dtype=torch.float64)\n",
      "A_jvp tensor([ 1.6501, -0.0147,  0.0374], dtype=torch.float64)\n",
      "x tensor([ 2.6546, -0.0904,  2.5645], dtype=torch.float64)\n",
      "v tensor([ 0.2933,  2.2423, -0.3945], dtype=torch.float64)\n",
      "A_jvp tensor([ 0.2933,  2.2423, -0.3945], dtype=torch.float64)\n",
      "x tensor([-0.9521,  1.5870,  0.1899], dtype=torch.float64)\n",
      "v tensor([-0.6377,  0.4551, -0.9320], dtype=torch.float64)\n",
      "A_jvp tensor([-0.6377,  0.4551, -0.9320], dtype=torch.float64)\n",
      "x tensor([0.0524, 0.4549, 0.0376], dtype=torch.float64)\n",
      "v tensor([-1.5844, -0.6183,  0.3377], dtype=torch.float64)\n",
      "A_jvp tensor([-1.5844, -0.6183,  0.3377], dtype=torch.float64)\n",
      "x tensor([-0.6176,  0.0300, -0.6783], dtype=torch.float64)\n",
      "v tensor([-0.4733, -0.5381, -0.6650], dtype=torch.float64)\n",
      "A_jvp tensor([-0.4733, -0.5381, -0.6650], dtype=torch.float64)\n",
      "x tensor([-0.9417,  1.4519,  0.6213], dtype=torch.float64)\n",
      "v tensor([-0.6909, -0.9276,  0.0931], dtype=torch.float64)\n",
      "A_jvp tensor([-0.6909, -0.9276,  0.0931], dtype=torch.float64)\n",
      "x tensor([ 0.4623, -2.2401, -0.7241], dtype=torch.float64)\n",
      "v tensor([-1.3488,  0.5350, -0.3665], dtype=torch.float64)\n",
      "A_jvp tensor([-1.3488,  0.5350, -0.3665], dtype=torch.float64)\n",
      "x tensor([1.6495, 0.0479, 1.2052], dtype=torch.float64)\n",
      "v tensor([-0.0469, -1.3267, -1.2537], dtype=torch.float64)\n",
      "A_jvp tensor([-0.0469, -1.3267, -1.2537], dtype=torch.float64)\n",
      "x tensor([1.1947, 0.3746, 0.0448], dtype=torch.float64)\n",
      "v tensor([ 0.6683,  1.5888, -2.0982], dtype=torch.float64)\n",
      "A_jvp tensor([ 0.6683,  1.5888, -2.0982], dtype=torch.float64)\n",
      "x tensor([-0.4391,  0.1574, -0.0818], dtype=torch.float64)\n",
      "v tensor([-0.6930, -1.0511, -0.7446], dtype=torch.float64)\n",
      "A_jvp tensor([-0.6930, -1.0511, -0.7446], dtype=torch.float64)\n",
      "x tensor([0.1919, 0.2605, 0.5713], dtype=torch.float64)\n",
      "v tensor([-1.8173, -2.2037,  1.0597], dtype=torch.float64)\n",
      "A_jvp tensor([-1.8173, -2.2037,  1.0597], dtype=torch.float64)\n",
      "x tensor([-2.1089, -0.8873,  0.6198], dtype=torch.float64)\n",
      "v tensor([-1.2495,  0.4424, -0.4346], dtype=torch.float64)\n",
      "A_jvp tensor([-1.2495,  0.4424, -0.4346], dtype=torch.float64)\n",
      "x tensor([0.6460, 1.4891, 0.1013], dtype=torch.float64)\n",
      "v tensor([0.3082, 1.1039, 0.4757], dtype=torch.float64)\n",
      "A_jvp tensor([0.3082, 1.1039, 0.4757], dtype=torch.float64)\n",
      "x tensor([-0.2569,  0.3633,  0.8996], dtype=torch.float64)\n",
      "v tensor([-1.1028, -0.6285,  0.3399], dtype=torch.float64)\n",
      "A_jvp tensor([-1.1028, -0.6285,  0.3399], dtype=torch.float64)\n",
      "x tensor([ 0.9398, -0.0043, -0.5687], dtype=torch.float64)\n",
      "v tensor([-2.3226, -1.1695, -1.1642], dtype=torch.float64)\n",
      "A_jvp tensor([-2.3226, -1.1695, -1.1642], dtype=torch.float64)\n",
      "x tensor([-0.7519, -0.0587, -0.4902], dtype=torch.float64)\n",
      "v tensor([1.1057, 0.4012, 0.0453], dtype=torch.float64)\n",
      "A_jvp tensor([1.1057, 0.4012, 0.0453], dtype=torch.float64)\n",
      "x tensor([-0.4342,  2.2686,  0.0699], dtype=torch.float64)\n",
      "v tensor([-1.6103, -1.6102,  1.2157], dtype=torch.float64)\n",
      "A_jvp tensor([-1.6103, -1.6102,  1.2157], dtype=torch.float64)\n",
      "x tensor([ 1.2718, -0.7215, -1.4679], dtype=torch.float64)\n",
      "v tensor([2.2157, 0.6043, 0.8561], dtype=torch.float64)\n",
      "A_jvp tensor([2.2157, 0.6043, 0.8561], dtype=torch.float64)\n",
      "x tensor([-0.8662, -0.6720, -0.4298], dtype=torch.float64)\n",
      "v tensor([-1.9740,  0.2458,  0.8466], dtype=torch.float64)\n",
      "A_jvp tensor([-1.9740,  0.2458,  0.8466], dtype=torch.float64)\n",
      "x tensor([-1.6731, -1.0307, -0.1640], dtype=torch.float64)\n",
      "v tensor([-0.1794,  0.5030,  0.1870], dtype=torch.float64)\n",
      "A_jvp tensor([-0.1794,  0.5030,  0.1870], dtype=torch.float64)\n",
      "x tensor([0.7083, 0.7936, 0.0150], dtype=torch.float64)\n",
      "v tensor([ 0.3449, -0.8807,  0.0901], dtype=torch.float64)\n",
      "A_jvp tensor([ 0.3449, -0.8807,  0.0901], dtype=torch.float64)\n",
      "x tensor([-0.1609, -1.1972,  2.2941], dtype=torch.float64)\n",
      "v tensor([-0.4592,  1.0765, -0.0183], dtype=torch.float64)\n",
      "A_jvp tensor([-0.4592,  1.0765, -0.0183], dtype=torch.float64)\n",
      "x tensor([-0.5254, -0.0343,  0.3076], dtype=torch.float64)\n",
      "v tensor([-1.4130, -1.1535,  1.7823], dtype=torch.float64)\n",
      "A_jvp tensor([-1.4130, -1.1535,  1.7823], dtype=torch.float64)\n",
      "x tensor([ 0.6858, -0.7458, -1.1176], dtype=torch.float64)\n",
      "v tensor([ 0.4500,  0.3967, -1.9855], dtype=torch.float64)\n",
      "A_jvp tensor([ 0.4500,  0.3967, -1.9855], dtype=torch.float64)\n",
      "x tensor([-1.0615,  0.1171, -1.6826], dtype=torch.float64)\n",
      "v tensor([ 0.7732,  2.5285, -2.1629], dtype=torch.float64)\n",
      "A_jvp tensor([ 0.7732,  2.5285, -2.1629], dtype=torch.float64)\n",
      "x tensor([-1.5447, -1.2566,  1.1242], dtype=torch.float64)\n",
      "v tensor([1.6547, 0.3210, 0.0423], dtype=torch.float64)\n",
      "A_jvp tensor([1.6547, 0.3210, 0.0423], dtype=torch.float64)\n",
      "x tensor([0.8598, 0.2311, 0.5216], dtype=torch.float64)\n",
      "v tensor([ 1.1529,  0.3120, -0.2239], dtype=torch.float64)\n",
      "A_jvp tensor([ 1.1529,  0.3120, -0.2239], dtype=torch.float64)\n",
      "x tensor([-0.4733, -0.8480,  0.7496], dtype=torch.float64)\n",
      "v tensor([ 0.3218, -0.0908,  0.4039], dtype=torch.float64)\n",
      "A_jvp tensor([ 0.3218, -0.0908,  0.4039], dtype=torch.float64)\n",
      "x tensor([-0.1659,  0.4455,  0.2713], dtype=torch.float64)\n",
      "v tensor([ 1.7907, -1.5867,  1.9079], dtype=torch.float64)\n",
      "A_jvp tensor([ 1.7907, -1.5867,  1.9079], dtype=torch.float64)\n",
      "x tensor([0.3789, 1.2291, 0.3839], dtype=torch.float64)\n",
      "v tensor([ 0.9067, -1.0860, -0.3337], dtype=torch.float64)\n",
      "A_jvp tensor([ 0.9067, -1.0860, -0.3337], dtype=torch.float64)\n",
      "x tensor([-0.8500, -1.9993,  1.2622], dtype=torch.float64)\n",
      "v tensor([-0.6603,  0.2490,  0.9223], dtype=torch.float64)\n",
      "A_jvp tensor([-0.6603,  0.2490,  0.9223], dtype=torch.float64)\n",
      "x tensor([-1.3861, -0.9196,  0.5513], dtype=torch.float64)\n",
      "v tensor([-1.5304,  0.2930,  1.2608], dtype=torch.float64)\n",
      "A_jvp tensor([-1.5304,  0.2930,  1.2608], dtype=torch.float64)\n",
      "x tensor([0.6552, 2.0198, 0.6315], dtype=torch.float64)\n",
      "v tensor([-1.3020,  1.7541,  1.5472], dtype=torch.float64)\n",
      "A_jvp tensor([-1.3020,  1.7541,  1.5472], dtype=torch.float64)\n",
      "x tensor([ 0.6982, -0.9291,  0.1818], dtype=torch.float64)\n",
      "v tensor([-0.0758, -0.4470, -2.9934], dtype=torch.float64)\n",
      "A_jvp tensor([-0.0758, -0.4470, -2.9934], dtype=torch.float64)\n",
      "x tensor([-1.0256,  1.3358, -0.3936], dtype=torch.float64)\n",
      "v tensor([2.1204, 2.0353, 0.3992], dtype=torch.float64)\n",
      "A_jvp tensor([2.1204, 2.0353, 0.3992], dtype=torch.float64)\n",
      "x tensor([-2.2304,  1.0232, -0.0317], dtype=torch.float64)\n",
      "v tensor([-1.5522, -0.4518,  0.3388], dtype=torch.float64)\n",
      "A_jvp tensor([-1.5522, -0.4518,  0.3388], dtype=torch.float64)\n",
      "x tensor([ 0.7238,  0.3307, -0.5546], dtype=torch.float64)\n",
      "v tensor([-1.7771,  0.1637,  0.6927], dtype=torch.float64)\n",
      "A_jvp tensor([-1.7771,  0.1637,  0.6927], dtype=torch.float64)\n",
      "x tensor([0.7448, 0.3018, 0.2791], dtype=torch.float64)\n",
      "v tensor([-0.0703,  1.4561, -0.3786], dtype=torch.float64)\n",
      "A_jvp tensor([-0.0703,  1.4561, -0.3786], dtype=torch.float64)\n",
      "x tensor([-0.4547,  1.5689, -0.8985], dtype=torch.float64)\n",
      "v tensor([ 1.0939, -0.1651,  0.0936], dtype=torch.float64)\n",
      "A_jvp tensor([ 1.0939, -0.1651,  0.0936], dtype=torch.float64)\n",
      "x tensor([-0.5869, -1.7333, -1.0951], dtype=torch.float64)\n",
      "v tensor([-0.7418,  1.6491, -0.0180], dtype=torch.float64)\n",
      "A_jvp tensor([-0.7418,  1.6491, -0.0180], dtype=torch.float64)\n",
      "x tensor([-0.7503, -0.8114, -0.5495], dtype=torch.float64)\n",
      "v tensor([ 1.0862, -0.5223, -0.5273], dtype=torch.float64)\n",
      "A_jvp tensor([ 1.0862, -0.5223, -0.5273], dtype=torch.float64)\n",
      "x tensor([-0.8432,  0.4039, -1.7224], dtype=torch.float64)\n",
      "v tensor([-0.0866,  0.2175, -0.3367], dtype=torch.float64)\n",
      "A_jvp tensor([-0.0866,  0.2175, -0.3367], dtype=torch.float64)\n",
      "x tensor([ 1.9273, -0.9144,  0.7932], dtype=torch.float64)\n",
      "v tensor([-0.1766, -0.3792,  1.1549], dtype=torch.float64)\n",
      "A_jvp tensor([-0.1766, -0.3792,  1.1549], dtype=torch.float64)\n",
      "x tensor([0.2455, 1.6425, 0.1823], dtype=torch.float64)\n",
      "v tensor([-0.1245,  0.8704, -0.6707], dtype=torch.float64)\n",
      "A_jvp tensor([-0.1245,  0.8704, -0.6707], dtype=torch.float64)\n",
      "x tensor([-1.0686, -1.0689, -1.8832], dtype=torch.float64)\n",
      "v tensor([ 0.3552,  1.3764, -0.2549], dtype=torch.float64)\n",
      "A_jvp tensor([ 0.3552,  1.3764, -0.2549], dtype=torch.float64)\n",
      "x tensor([-1.5367,  0.3458, -0.7277], dtype=torch.float64)\n",
      "v tensor([-0.8895, -0.7048, -0.2206], dtype=torch.float64)\n",
      "A_jvp tensor([-0.8895, -0.7048, -0.2206], dtype=torch.float64)\n",
      "x tensor([-0.9859, -0.4114,  0.5820], dtype=torch.float64)\n",
      "v tensor([-0.4853,  1.2421, -0.1329], dtype=torch.float64)\n",
      "A_jvp tensor([-0.4853,  1.2421, -0.1329], dtype=torch.float64)\n",
      "x tensor([-1.5500,  0.9694, -0.6363], dtype=torch.float64)\n",
      "v tensor([-0.8047, -0.9228, -0.5309], dtype=torch.float64)\n",
      "A_jvp tensor([-0.8047, -0.9228, -0.5309], dtype=torch.float64)\n",
      "x tensor([-0.6153, -0.4401,  0.5298], dtype=torch.float64)\n",
      "v tensor([1.3615, 0.0407, 0.2608], dtype=torch.float64)\n",
      "A_jvp tensor([1.3615, 0.0407, 0.2608], dtype=torch.float64)\n",
      "x tensor([-0.8413, -1.0747,  0.3459], dtype=torch.float64)\n",
      "v tensor([ 0.7618,  1.3911, -1.2557], dtype=torch.float64)\n",
      "A_jvp tensor([ 0.7618,  1.3911, -1.2557], dtype=torch.float64)\n",
      "x tensor([-0.9824, -1.2679,  0.7577], dtype=torch.float64)\n",
      "v tensor([-0.6906,  0.9030,  0.8297], dtype=torch.float64)\n",
      "A_jvp tensor([-0.6906,  0.9030,  0.8297], dtype=torch.float64)\n",
      "x tensor([ 2.1936, -0.3286, -0.1843], dtype=torch.float64)\n",
      "v tensor([ 0.1314, -0.8303,  0.8116], dtype=torch.float64)\n",
      "A_jvp tensor([ 0.1314, -0.8303,  0.8116], dtype=torch.float64)\n",
      "x tensor([ 0.0464,  0.4308, -0.9674], dtype=torch.float64)\n",
      "v tensor([-0.4975, -0.1338, -0.9062], dtype=torch.float64)\n",
      "A_jvp tensor([-0.4975, -0.1338, -0.9062], dtype=torch.float64)\n",
      "x tensor([-1.4796,  1.1152, -0.0334], dtype=torch.float64)\n",
      "v tensor([-0.3002,  0.1795, -1.2040], dtype=torch.float64)\n",
      "A_jvp tensor([-0.3002,  0.1795, -1.2040], dtype=torch.float64)\n",
      "x tensor([-0.6843, -0.2611, -0.3421], dtype=torch.float64)\n",
      "v tensor([-0.3280,  1.6732,  0.0570], dtype=torch.float64)\n",
      "A_jvp tensor([-0.3280,  1.6732,  0.0570], dtype=torch.float64)\n",
      "x tensor([-1.0828, -0.0720, -0.5158], dtype=torch.float64)\n",
      "v tensor([0.6007, 0.8372, 0.6930], dtype=torch.float64)\n",
      "A_jvp tensor([0.6007, 0.8372, 0.6930], dtype=torch.float64)\n",
      "x tensor([0.6848, 0.0255, 1.1636], dtype=torch.float64)\n",
      "v tensor([-0.1689,  0.0766, -0.0126], dtype=torch.float64)\n",
      "A_jvp tensor([-0.1689,  0.0766, -0.0126], dtype=torch.float64)\n",
      "x tensor([ 0.2684, -1.1765,  0.9000], dtype=torch.float64)\n",
      "v tensor([0.3347, 2.6376, 0.7810], dtype=torch.float64)\n",
      "A_jvp tensor([0.3347, 2.6376, 0.7810], dtype=torch.float64)\n",
      "x tensor([-1.0567,  0.8329,  1.0891], dtype=torch.float64)\n",
      "v tensor([0.1011, 0.3735, 0.6939], dtype=torch.float64)\n",
      "A_jvp tensor([0.1011, 0.3735, 0.6939], dtype=torch.float64)\n",
      "x tensor([0.5362, 0.0180, 0.9173], dtype=torch.float64)\n",
      "v tensor([-1.2759, -2.1311,  0.4172], dtype=torch.float64)\n",
      "A_jvp tensor([-1.2759, -2.1311,  0.4172], dtype=torch.float64)\n",
      "x tensor([ 0.4032,  1.1766, -0.7307], dtype=torch.float64)\n",
      "v tensor([ 0.9061, -0.8351,  0.1754], dtype=torch.float64)\n",
      "A_jvp tensor([ 0.9061, -0.8351,  0.1754], dtype=torch.float64)\n",
      "x tensor([ 0.8743,  0.0267, -0.5420], dtype=torch.float64)\n",
      "v tensor([ 1.1665,  0.1810, -0.8079], dtype=torch.float64)\n",
      "A_jvp tensor([ 1.1665,  0.1810, -0.8079], dtype=torch.float64)\n",
      "x tensor([ 0.4657, -1.3055,  1.6805], dtype=torch.float64)\n",
      "v tensor([-0.5926, -1.2520, -0.7611], dtype=torch.float64)\n",
      "A_jvp tensor([-0.5926, -1.2520, -0.7611], dtype=torch.float64)\n",
      "x tensor([ 0.1305, -1.3516, -0.1704], dtype=torch.float64)\n",
      "v tensor([1.0036, 1.5276, 0.2972], dtype=torch.float64)\n",
      "A_jvp tensor([1.0036, 1.5276, 0.2972], dtype=torch.float64)\n",
      "x tensor([0.3170, 1.0061, 1.8505], dtype=torch.float64)\n",
      "v tensor([-1.2717, -0.1119, -0.8241], dtype=torch.float64)\n",
      "A_jvp tensor([-1.2717, -0.1119, -0.8241], dtype=torch.float64)\n",
      "x tensor([ 0.1026, -0.9098,  0.3935], dtype=torch.float64)\n",
      "v tensor([ 0.4702, -0.5772,  0.0998], dtype=torch.float64)\n",
      "A_jvp tensor([ 0.4702, -0.5772,  0.0998], dtype=torch.float64)\n",
      "x tensor([ 0.1606, -0.6765, -0.9093], dtype=torch.float64)\n",
      "v tensor([ 1.8963,  0.0780, -0.3280], dtype=torch.float64)\n",
      "A_jvp tensor([ 1.8963,  0.0780, -0.3280], dtype=torch.float64)\n",
      "x tensor([-0.4968,  0.4972,  1.3954], dtype=torch.float64)\n",
      "v tensor([ 1.3546, -0.0684,  0.1526], dtype=torch.float64)\n",
      "A_jvp tensor([ 1.3546, -0.0684,  0.1526], dtype=torch.float64)\n",
      "x tensor([ 0.3137,  0.2823, -0.2144], dtype=torch.float64)\n",
      "v tensor([-0.5455,  0.2648, -0.8067], dtype=torch.float64)\n",
      "A_jvp tensor([-0.5455,  0.2648, -0.8067], dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "for _ in range(100):\n",
    "    x = torch.randn(3, dtype=torch.float64)\n",
    "    print(\"x\",x)\n",
    "    v = torch.randn(3, dtype=torch.float64)\n",
    "    print(\"v\",v)\n",
    "    print(\"A_jvp\",v)\n",
    "    assert torch.allclose(physics.A_jvp(x, x), x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1.1901, 4.0743, 0.1858, 2.3197, 0.0734, 0.4557, 0.1231, 0.6597, 1.7768,\n",
       "         0.3864]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seed = torch.manual_seed(0) # Random seed for reproducibility\n",
    "x = torch.randn((1, 1, 3, 3),dtype=torch.cfloat) # Define random 3x3 image\n",
    "physics = RandomPhaseRetrieval(m=10,img_shape=(1, 3, 3))\n",
    "physics(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1.1901, 4.0743, 0.1858, 2.3197, 0.0734, 0.4557, 0.1231, 0.6597, 1.7768,\n",
       "         0.3864]])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seed = torch.manual_seed(0) # Random seed for reproducibility\n",
    "x = torch.randn((1, 1, 3, 3),dtype=torch.cfloat) # Define random 3x3 image\n",
    "physics = RandomPhaseRetrieval(m=10, img_shape=(1, 3, 3))\n",
    "physics(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([2.2016], grad_fn=<PowBackward0>)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[[[True, True, True],\n",
       "          [True, True, True],\n",
       "          [True, True, True]]]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# assert A_jvp and autograd works the same\n",
    "x = torch.randn((1, 1, 3, 3),dtype=torch.cfloat,requires_grad=True)\n",
    "loss = AmplitudeLoss()\n",
    "print(loss(x,torch.ones_like(physics(x)),physics))\n",
    "grad_value = torch.autograd.grad(loss(x,torch.ones_like(physics(x)),physics),x)\n",
    "jvp_value = loss.grad(x, torch.ones_like(physics(x)), physics)\n",
    "torch.isclose(grad_value[0],jvp_value,rtol=1e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 740,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(True)\n"
     ]
    }
   ],
   "source": [
    "x = torch.randn((1, 1, 3, 3), dtype=torch.cfloat, device='cpu', requires_grad=True)\n",
    "physics = deepinv.physics.RandomPhaseRetrieval(m=10, img_shape=(1, 3, 3), device='cpu')\n",
    "loss = L2()\n",
    "grad_value = torch.autograd.grad(loss(x,torch.ones_like(physics(x)),physics),x)[0]\n",
    "jvp_value = loss.grad(x, torch.ones_like(physics(x)), physics)\n",
    "print(torch.isclose(grad_value[0],jvp_value,rtol=1e-5).all())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([2., 4., 6.]),)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = torch.Tensor([1,2,3])\n",
    "a.requires_grad = True\n",
    "b = torch.sum(a**2)\n",
    "torch.autograd.grad(b,a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(-2.9910+1.7972j) tensor(-2.9910-1.7972j)\n"
     ]
    }
   ],
   "source": [
    "u = randn_like(x)\n",
    "\n",
    "Au = physics.B.A(u)\n",
    "\n",
    "v = randn_like(Au)\n",
    "Atv = physics.A_adjoint(v)\n",
    "\n",
    "s1 = (v.conj() * Au).flatten().sum()\n",
    "\n",
    "s2 = (Atv * u.conj()).flatten().sum()\n",
    "\n",
    "print(s1,s2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 1, 2, 2])\n",
      "tensor([[[[-0.3516, -1.3869],\n",
      "          [ 0.2270,  0.8023]]]])\n",
      "tensor([[[[-0.3516, -1.3869],\n",
      "          [ 0.2270,  0.8023]]]])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A = lambda x: torch.roll(x, shifts=(1,1), dims=(2,3)) # shift image by one pixel\n",
    "x = torch.randn((1, 1, 2, 2))\n",
    "y = A(x)\n",
    "print(y.shape)\n",
    "A_adjoint = adjoint_function(A, x.shape)\n",
    "print(x)\n",
    "print(A_adjoint(y))\n",
    "torch.allclose(A_adjoint(y), x) # we have A^T(A(x)) = x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "zold tensor([[[[0.+0.j, 0.+0.j, 0.+0.j, 0.+0.j, 0.+0.j],\n",
      "          [0.+0.j, 0.+0.j, 0.+0.j, 0.+0.j, 0.+0.j],\n",
      "          [0.+0.j, 0.+0.j, 0.+0.j, 0.+0.j, 0.+0.j],\n",
      "          [0.+0.j, 0.+0.j, 0.+0.j, 0.+0.j, 0.+0.j],\n",
      "          [0.+0.j, 0.+0.j, 0.+0.j, 0.+0.j, 0.+0.j]]]])\n",
      "Power iteration converged at iteration 12, value=0.20+0.94j\n",
      "tensor(0.9611)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[27.6474,  2.0685,  2.0891,  0.8423,  1.1014,  5.0582,  2.2531,  3.1285,\n",
       "          2.4926,  3.6849]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img_size = (1,5,5)\n",
    "model = RandomPhaseRetrieval(10,img_size)\n",
    "x = torch.randn(img_size, device=\"cpu\", dtype=torch.cfloat).unsqueeze(0)\n",
    "y = torch.randn(img_size, device=\"cpu\", dtype=torch.cfloat).unsqueeze(0)\n",
    "#print(x.reshape(-1).shape)\n",
    "#print(model.A_adjoint(model.A(x)))\n",
    "#print(x.reshape(-1).shape)\n",
    "#print(x.reshape(-1)@y.reshape(-1))\n",
    "norm = compute_norm(model,x)\n",
    "print(norm.abs())\n",
    "model.forward(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[8.1145, 4.5697, 1.9492, 2.4946, 2.9993, 0.3669, 0.4354, 0.1007, 0.3566,\n",
      "         4.3726]])\n",
      "tensor([[8.1145, 4.5697, 1.9492, 2.4946, 2.9993, 0.3669, 0.4354, 0.1007, 0.3566,\n",
      "         4.3726]])\n"
     ]
    }
   ],
   "source": [
    "x = torch.randn(img_size, device=\"cpu\", dtype=torch.cfloat).unsqueeze(0)\n",
    "x.shape\n",
    "print(model.A(x).abs()**2)\n",
    "print(model.forward(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.0838-1.1806j, -0.6708-0.2329j],\n",
      "        [-0.2557+0.1537j,  0.9800-0.2512j]])\n",
      "tensor([[-0.0838-1.1806j, -0.2557+0.1537j],\n",
      "        [-0.6708-0.2329j,  0.9800-0.2512j]])\n",
      "tensor([[-0.0838+1.1806j, -0.2557-0.1537j],\n",
      "        [-0.6708+0.2329j,  0.9800+0.2512j]])\n",
      "tensor([[-0.9911+0.5104j, -0.5130+0.2292j],\n",
      "        [-0.5130+0.2292j,  0.9390-0.5710j]])\n",
      "tensor([[ 1.9050+0.0000j, -0.7588-0.0821j],\n",
      "        [-0.7588+0.0821j,  1.1124+0.0000j]])\n"
     ]
    }
   ],
   "source": [
    "a = torch.randn(2,2, dtype=torch.cfloat)\n",
    "print(a)\n",
    "print(a.T)\n",
    "print(a.conj().T)\n",
    "print(a @ a.T)\n",
    "print(a @ a.conj().T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.1951+0.7924j, -0.4214+0.3880j],\n",
       "        [ 0.0117+0.2403j,  0.8712+0.3906j]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.linalg.pinv(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 0.3328+0.4799j,  0.3259-0.3818j,  0.5162+0.5780j, -0.2479+0.8042j])\n",
      "tensor([-0.6631+0.0180j, -0.2426+0.4473j, -0.7994+0.4581j,  1.1511-0.2296j])\n",
      "tensor(-1.0798+0.2071j)\n"
     ]
    }
   ],
   "source": [
    "p = torch.randn(2,2, dtype=torch.cfloat)\n",
    "q = torch.randn(2,2, dtype=torch.cfloat)\n",
    "print(p.reshape(-1))\n",
    "print(q.reshape(-1))\n",
    "print(torch.vdot(p.reshape(-1),q.reshape(-1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1.+1.j, 2.+2.j, 3.+3.j, 4.+4.j])\n",
      "tensor([16.+6.j,  2.+6.j,  3.+5.j,  4.+8.j])\n",
      "tensor(110.+20.j)\n"
     ]
    }
   ],
   "source": [
    "#  create a constant 2-by-2 complex matrix\n",
    "a = torch.tensor([1+1j, 2+2j, 3+3j, 4+4j], dtype=torch.cfloat)\n",
    "b = torch.tensor([16+6j, 2+6j, 3+5j, 4+8j], dtype=torch.cfloat)\n",
    "c = a.flatten()\n",
    "print(c)\n",
    "d = b.flatten()\n",
    "print(d)\n",
    "print(torch.vdot(a,b))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(16.+1.j)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.vdot(torch.tensor([2, 3]), torch.tensor([2, 1]))\n",
    "a = torch.tensor((1 +2j, 3 - 1j))\n",
    "b = torch.tensor((2 +1j, 4 - 0j))\n",
    "torch.vdot(b, a)\n",
    "torch.vdot(a, b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate the performance of spectral methods w.r.t. oversampling ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 600/600 [01:13<00:00,  8.17it/s]\n"
     ]
    }
   ],
   "source": [
    "RANGE_M = 600\n",
    "REPEATS = 30\n",
    "IMG_SHAPE = (1, 8, 8)\n",
    "\n",
    "avg_cosines = []\n",
    "raw_cosines = torch.zeros((RANGE_M, REPEATS))\n",
    "\n",
    "for m in tqdm(range(1,RANGE_M+1)):\n",
    "    physics = RandomPhaseRetrieval(m=m, img_shape=IMG_SHAPE)\n",
    "    cosines = []\n",
    "    for i in range(REPEATS):\n",
    "        x = torch.randn((1,) + IMG_SHAPE,dtype=torch.cfloat)\n",
    "        y = physics(x)\n",
    "        x_hat = spectral_methods(y,physics)\n",
    "        x_hat = x_hat * torch.sqrt(y.sum())\n",
    "        cosine = cosine_similarity(x,x_hat)\n",
    "        cosines.append(cosine)\n",
    "        raw_cosines[m-1, i] = cosines[-1]\n",
    "    avg_cosines.append(sum(cosines)/len(cosines))\n",
    "oversampling_ratio = [i/np.prod(IMG_SHAPE) for i in range(1,RANGE_M+1)]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deepinv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
