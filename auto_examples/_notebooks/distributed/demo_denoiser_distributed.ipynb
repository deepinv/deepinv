{
  "cells": [
    {
      "id": "8c574d6e",
      "cell_type": "code",
      "metadata": {
        "language": "python"
      },
      "execution_count": null,
      "source": "# Install deepinv (skip if already installed)\n%pip install deepinv",
      "outputs": []
    },
    {
      "id": "f5f8c8e7",
      "cell_type": "markdown",
      "source": "<!-- MathJax macro definitions inserted automatically -->\n$$\n\\newcommand{\\forw}[1]{{A\\left({#1}\\right)}}\n\\newcommand{\\noise}[1]{{N\\left({#1}\\right)}}\n\\newcommand{\\inverse}[1]{{R\\left({#1}\\right)}}\n\\newcommand{\\inversef}[2]{{R\\left({#1},{#2}\\right)}}\n\\newcommand{\\inversename}{R}\n\\newcommand{\\reg}[1]{{g_\\sigma\\left({#1}\\right)}}\n\\newcommand{\\regname}{g_\\sigma}\n\\newcommand{\\sensor}[1]{{\\eta\\left({#1}\\right)}}\n\\newcommand{\\datafid}[2]{{f\\left({#1},{#2}\\right)}}\n\\newcommand{\\datafidname}{f}\n\\newcommand{\\distance}[2]{{d\\left({#1},{#2}\\right)}}\n\\newcommand{\\distancename}{d}\n\\newcommand{\\denoiser}[2]{{\\operatorname{D}_{{#2}}\\left({#1}\\right)}}\n\\newcommand{\\denoisername}{\\operatorname{D}_{\\sigma}}\n\\newcommand{\\xset}{\\mathcal{X}}\n\\newcommand{\\yset}{\\mathcal{Y}}\n\\newcommand{\\group}{\\mathcal{G}}\n\\newcommand{\\metric}[2]{{d\\left({#1},{#2}\\right)}}\n\\newcommand{\\loss}[1]{{\\mathcal\\left({#1}\\right)}}\n\\newcommand{\\conj}[1]{{\\overline{#1}^{\\top}}}\n$$",
      "metadata": {
        "language": "markdown"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "language": "markdown"
      },
      "source": "# Distributed Denoiser with Image Tiling\n\nIn many imaging problems, the data to be processed can be very large, making it challenging to fit the\ndenoising process into the memory of a single device. For instance, medical imaging or satellite imagery\noften involves processing gigapixel images that cannot be processed as a whole.\n\nThe distributed framework enables you to parallelize the denoising of large images across multiple devices\nusing image tiling. Each device processes different image patches independently, and the results are merged\nto produce the final denoised image.\n\nThis example demonstrates how to use the [`deepinv.distributed.distribute`](https://deepinv.github.io/deepinv/api/stubs/deepinv.distributed.distribute.html) function to create a\ndistributed denoiser that automatically handles patch extraction, processing, and merging.\n\n**Usage:**\n\n```bash\n# Single process\npython examples/distributed/demo_denoiser_distributed.py\n```\n```bash\n# Multi-process with torchrun (2 GPUs/processes)\npython -m torch.distributed.run --nproc_per_node=2 examples/distributed/demo_denoiser_distributed.py\n```\n**Key Features:**\n\n- Distribute denoising across processes/devices using image tiling\n- Automatic patch extraction and reassembly\n- Memory-efficient processing of large images\n\n**Key Steps:**\n\n1. Load a large test image\n2. Add noise to create a noisy observation\n3. Initialize distributed context\n4. Configure tiling parameters\n5. Distribute denoiser with [`deepinv.distributed.distribute`](https://deepinv.github.io/deepinv/api/stubs/deepinv.distributed.distribute.html)\n6. Apply distributed denoising\n7. Visualize results and compute metrics\n\n# Import modules and define noisy image generation\nWe start by importing `torch` and the modules of deepinv that we use in this example. We also define a function that generates noisy images to evaluate the distributed framework."
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "import torch\nfrom deepinv.models import DRUNet\nfrom deepinv.utils.demo import load_example\nfrom deepinv.utils.plotting import plot\nfrom deepinv.loss.metric import PSNR\n\n# Import distributed framework\nfrom deepinv.distributed import DistributedContext, distribute\n\n\ndef create_noisy_image(device, img_size=1024, noise_sigma=0.1, seed=42):\n    \"\"\"\n    Create a noisy test image.\n\n    :param device: Device to create image on\n    :param tuple img_size: Size of the image (H, W)\n    :param float noise_sigma: Standard deviation of Gaussian noise\n    :param int seed: Random seed for reproducible noise\n    :returns: Tuple of (clean_image, noisy_image, noise_sigma)\n    \"\"\"\n    # Load example image in original size\n    clean_image = load_example(\n        \"CBSD_0010.png\",\n        grayscale=False,\n        device=device,\n        img_size=img_size,\n        resize_mode=\"resize\",\n    )\n\n    # Set seed for reproducible noise\n    torch.manual_seed(seed)\n\n    # Add Gaussian noise\n    noise = torch.randn_like(clean_image) * noise_sigma\n    noisy_image = clean_image + noise\n\n    # Clip to valid range\n    noisy_image = torch.clamp(noisy_image, 0, 1)\n\n    return clean_image, noisy_image, noise_sigma"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "language": "markdown"
      },
      "source": "## Configuration of parallel denoising"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "img_size = 512  # Large image for demonstrating tiling\nnoise_sigma = 0.1\npatch_size = 256  # Size of each patch\noverlap = 64  # Overlap for smooth boundaries"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "language": "markdown"
      },
      "source": "## Define distributed context and run algorithm"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# Initialize distributed context (handles single and multi-process automatically)\nwith DistributedContext(seed=42) as ctx:\n\n    if ctx.rank == 0:\n        print(\"=\" * 70)\n        print(\"Distributed Denoiser Demo\")\n        print(\"=\" * 70)\n        print(f\"\\nRunning on {ctx.world_size} process(es)\")\n        print(f\"   Device: {ctx.device}\")\n\n    # ---------------------------------------------------------------------------\n    # Step 1: Create test image with noise\n    # ---------------------------------------------------------------------------\n\n    clean_image, noisy_image, sigma = create_noisy_image(\n        ctx.device, img_size=img_size, noise_sigma=noise_sigma\n    )\n\n    # Compute input PSNR (create metric on all ranks for consistency)\n    psnr_metric = PSNR()\n    input_psnr = psnr_metric(noisy_image, clean_image).item()\n\n    if ctx.rank == 0:\n        print(f\"\\nCreated test image\")\n        print(f\"   Image shape: {clean_image.shape}\")\n        print(f\"   Noise sigma: {sigma}\")\n        print(f\"   Input PSNR: {input_psnr:.2f} dB\")\n\n    # ---------------------------------------------------------------------------\n    # Step 2: Load denoiser model\n    # ---------------------------------------------------------------------------\n\n    if ctx.rank == 0:\n        print(f\"\\nLoading DRUNet denoiser...\")\n\n    denoiser = DRUNet(pretrained=\"download\").to(ctx.device)\n\n    if ctx.rank == 0:\n        print(f\"   Denoiser loaded\")\n\n    # ---------------------------------------------------------------------------\n    # Step 3: Distribute denoiser with tiling configuration\n    # ---------------------------------------------------------------------------\n\n    if ctx.rank == 0:\n        print(f\"\\nConfiguring distributed denoiser\")\n        print(f\"   Patch size: {patch_size}x{patch_size}\")\n        print(f\"   Receptive field radius: {overlap}\")\n        print(f\"   Tiling strategy: overlap_tiling\")\n\n    distributed_denoiser = distribute(\n        denoiser,\n        ctx,\n        patch_size=patch_size,\n        overlap=overlap,\n    )\n\n    if ctx.rank == 0:\n        print(f\"   Distributed denoiser created\")\n\n    # ---------------------------------------------------------------------------\n    # Step 4: Apply distributed denoising\n    # ---------------------------------------------------------------------------\n\n    if ctx.rank == 0:\n        print(f\"\\nApplying distributed denoising...\")\n\n    with torch.no_grad():\n        denoised_image = distributed_denoiser(noisy_image, sigma=sigma)\n\n    if ctx.rank == 0:\n        print(f\"   Denoising completed\")\n        print(f\"   Output shape: {denoised_image.shape}\")\n\n    # Compare with non-distributed result (only on rank 0)\n    if ctx.rank == 0:\n        print(f\"\\nComparing with non-distributed denoising...\")\n        with torch.no_grad():\n            denoised_ref = denoiser(noisy_image, sigma=sigma)\n\n        diff = torch.abs(denoised_image - denoised_ref)\n        mean_diff = diff.mean().item()\n        max_diff = diff.max().item()\n\n        print(f\"   Mean absolute difference: {mean_diff:.2e}\")\n        print(f\"   Max absolute difference:  {max_diff:.2e}\")\n\n        # Check that differences are small (due to tiling boundary effects)\n        # The distributed version uses tiling with overlapping patches and blending,\n        # which can produce slightly different results at patch boundaries.\n        # These differences are typically very small (< 0.01 mean, < 0.5 max).\n        tolerance_mean = 0.01\n        tolerance_max = 0.5\n        assert (\n            mean_diff < tolerance_mean\n        ), f\"Mean difference too large: {mean_diff:.4f} (tolerance: {tolerance_mean})\"\n        assert (\n            max_diff < tolerance_max\n        ), f\"Max difference too large: {max_diff:.4f} (tolerance: {tolerance_max})\"\n        print(f\"   Results are very close (within tolerance)!\")\n\n    # ---------------------------------------------------------------------------\n    # Step 5: Compute metrics and visualize results (only on rank 0)\n    # ---------------------------------------------------------------------------\n\n    if ctx.rank == 0:\n        # Compute output PSNR\n        output_psnr = psnr_metric(denoised_image, clean_image).item()\n        psnr_improvement = output_psnr - input_psnr\n\n        print(f\"\\nResults:\")\n        print(f\"   Input PSNR:  {input_psnr:.2f} dB\")\n        print(f\"   Output PSNR: {output_psnr:.2f} dB\")\n        print(f\"   Improvement: {psnr_improvement:.2f} dB\")\n\n        # Plot results\n        plot(\n            [clean_image, noisy_image, denoised_image],\n            titles=[\n                \"Clean Image\",\n                f\"Noisy (PSNR: {input_psnr:.2f} dB)\",\n                f\"Denoised (PSNR: {output_psnr:.2f} dB)\",\n            ],\n            save_fn=\"distributed_denoiser_result.png\",\n            figsize=(15, 4),\n        )\n\n        # Plot zoom on a region to see details\n        # Extract a 256x256 patch from center\n        h, w = clean_image.shape[-2:]\n        y_start, x_start = h // 2 - 128, w // 2 - 128\n        y_end, x_end = y_start + 256, x_start + 256\n\n        clean_patch = clean_image[..., y_start:y_end, x_start:x_end]\n        noisy_patch = noisy_image[..., y_start:y_end, x_start:x_end]\n        denoised_patch = denoised_image[..., y_start:y_end, x_start:x_end]\n\n        plot(\n            [clean_patch, noisy_patch, denoised_patch],\n            titles=[\"Clean (zoom)\", \"Noisy (zoom)\", \"Denoised (zoom)\"],\n            save_fn=\"distributed_denoiser_zoom.png\",\n            figsize=(15, 4),\n        )\n\n        print(f\"\\nDemo completed successfully!\")\n        print(f\"   Results saved to:\")\n        print(f\"   - distributed_denoiser_result.png\")\n        print(f\"   - distributed_denoiser_zoom.png\")\n        print(\"\\n\" + \"=\" * 70)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.14"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}