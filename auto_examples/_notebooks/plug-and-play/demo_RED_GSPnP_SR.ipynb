{
  "cells": [
    {
      "id": "7a451b7f",
      "cell_type": "code",
      "metadata": {
        "language": "python"
      },
      "execution_count": null,
      "source": "# Install deepinv (skip if already installed)\n%pip install deepinv",
      "outputs": []
    },
    {
      "id": "71a2569c",
      "cell_type": "markdown",
      "source": "<!-- MathJax macro definitions inserted automatically -->\n$$\n\\newcommand{\\forw}[1]{{A\\left({#1}\\right)}}\n\\newcommand{\\noise}[1]{{N\\left({#1}\\right)}}\n\\newcommand{\\inverse}[1]{{R\\left({#1}\\right)}}\n\\newcommand{\\inversef}[2]{{R\\left({#1},{#2}\\right)}}\n\\newcommand{\\inversename}{R}\n\\newcommand{\\reg}[1]{{g_\\sigma\\left({#1}\\right)}}\n\\newcommand{\\regname}{g_\\sigma}\n\\newcommand{\\sensor}[1]{{\\eta\\left({#1}\\right)}}\n\\newcommand{\\datafid}[2]{{f\\left({#1},{#2}\\right)}}\n\\newcommand{\\datafidname}{f}\n\\newcommand{\\distance}[2]{{d\\left({#1},{#2}\\right)}}\n\\newcommand{\\distancename}{d}\n\\newcommand{\\denoiser}[2]{{\\operatorname{D}_{{#2}}\\left({#1}\\right)}}\n\\newcommand{\\denoisername}{\\operatorname{D}_{\\sigma}}\n\\newcommand{\\xset}{\\mathcal{X}}\n\\newcommand{\\yset}{\\mathcal{Y}}\n\\newcommand{\\group}{\\mathcal{G}}\n\\newcommand{\\metric}[2]{{d\\left({#1},{#2}\\right)}}\n\\newcommand{\\loss}[1]{{\\mathcal\\left({#1}\\right)}}\n\\newcommand{\\conj}[1]{{\\overline{#1}^{\\top}}}\n$$",
      "metadata": {
        "language": "markdown"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "language": "markdown"
      },
      "source": "# Regularization by Denoising (RED) for Super-Resolution.\n\nImplementation of (Romano et al., 2017) using as plug-in denoiser the Gradient-Step Denoiser (GSPnP) (Hurault et al., 2021) which provides an explicit prior."
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "import deepinv as dinv\nfrom pathlib import Path\nimport torch\nfrom torch.utils.data import DataLoader\nfrom deepinv.optim.data_fidelity import L2\nfrom deepinv.optim.prior import RED\nfrom deepinv.optim import PGD\nfrom deepinv.training import test\nfrom torchvision import transforms\nfrom deepinv.utils.parameters import get_GSPnP_params\nfrom deepinv.utils import load_dataset, load_degradation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "language": "markdown"
      },
      "source": "## Setup paths for data loading and results."
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "BASE_DIR = Path(\".\")\nDATA_DIR = BASE_DIR / \"measurements\"\nRESULTS_DIR = BASE_DIR / \"results\"\nDEG_DIR = BASE_DIR / \"degradations\"\n\n# Set the global random seed from pytorch to ensure\n# the reproducibility of the example.\ntorch.manual_seed(0)\ndevice = dinv.utils.get_device()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "language": "markdown"
      },
      "source": "## Load base image datasets and degradation operators.\nIn this example, we use the Set3C dataset and a motion blur kernel from (Levin et al., 2009)."
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "dataset_name = \"set3c\"\nimg_size = 256 if torch.cuda.is_available() else 32\noperation = \"super-resolution\"\nval_transform = transforms.Compose(\n    [transforms.CenterCrop(img_size), transforms.ToTensor()]\n)\ndataset = load_dataset(dataset_name, transform=val_transform)\n\n# Generate the degradation operator.\nkernel_index = 1\nkernel_torch = load_degradation(\n    \"kernels_12.npy\", DEG_DIR / \"kernels\", index=kernel_index\n)\nkernel_torch = kernel_torch.unsqueeze(0).unsqueeze(\n    0\n)  # add batch and channel dimensions\n\n# Use parallel dataloader if using a GPU to speed up training, otherwise, as all computes are on CPU, use synchronous dataloading.\nnum_workers = 4 if torch.cuda.is_available() else 0\n\nfactor = 2  # down-sampling factor\nn_channels = 3  # 3 for color images, 1 for gray-scale images\nn_images_max = 3  # Maximal number of images to restore from the input dataset\nnoise_level_img = 0.03  # Gaussian Noise standard deviation for the degradation\np = dinv.physics.Downsampling(\n    img_size=(n_channels, img_size, img_size),\n    factor=factor,\n    filter=kernel_torch,\n    device=device,\n    noise_model=dinv.physics.GaussianNoise(sigma=noise_level_img),\n)\n\n# Generate a dataset in a HDF5 folder in \"{dir}/dinv_dataset0.h5'\" and load it.\nmeasurement_dir = DATA_DIR / dataset_name / operation\ndinv_dataset_path = dinv.datasets.generate_dataset(\n    train_dataset=dataset,\n    test_dataset=None,\n    physics=p,\n    device=device,\n    save_dir=measurement_dir,\n    train_datapoints=n_images_max,\n    num_workers=num_workers,\n)\ndataset = dinv.datasets.HDF5Dataset(path=dinv_dataset_path, train=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "language": "markdown"
      },
      "source": "## Setup the PnP algorithm. This involves in particular the definition of a custom prior class.\nWe use the proximal gradient algorithm to solve the super-resolution problem with GSPnP."
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# Parameters of the algorithm to solve the inverse problem\nearly_stop = True  # Stop algorithm when convergence criteria is reached\ncrit_conv = \"cost\"  # Convergence is reached when the difference of cost function between consecutive iterates is\n# smaller than thres_conv\nthres_conv = 1e-5\nbacktracking = True\nbatch_size = 1  # batch size for evaluation is necessarily 1 for early stopping and backtracking to work.\n\n# load specific parameters for GSPnP\nlambda_reg, sigma_denoiser, stepsize, max_iter = get_GSPnP_params(\n    operation, noise_level_img\n)\n\n# Select the data fidelity term\ndata_fidelity = L2()\n\n\n# The GSPnP prior corresponds to a RED prior with an explicit `g`.\n# We thus write a class that inherits from RED for this custom prior.\nclass GSPnP(RED):\n    r\"\"\"\n    Gradient-Step Denoiser prior.\n    \"\"\"\n\n    def __init__(self, *args, **kwargs):\n        super().__init__(*args, **kwargs)\n        self.explicit_prior = True\n\n    def forward(self, x, *args, **kwargs):\n        r\"\"\"\n        Computes the prior :math:`g(x)`.\n\n        :param torch.Tensor x: Variable :math:`x` at which the prior is computed.\n        :return: (torch.Tensor) prior :math:`g(x)`.\n        \"\"\"\n        return self.denoiser.potential(x, *args, **kwargs)\n\n\nmethod = \"GSPnP\"\ndenoiser_name = \"gsdrunet\"\n# Specify the Denoising prior\nprior = GSPnP(denoiser=dinv.models.GSDRUNet(pretrained=\"download\").to(device))\n\n\n# we want to output the intermediate PGD update to finish with a denoising step.\ndef custom_output(X):\n    return X[\"est\"][1]\n\n\n# instantiate the algorithm class to solve the IP problem.\nmodel = PGD(\n    prior=prior,\n    g_first=True,\n    data_fidelity=data_fidelity,\n    sigma_denoiser=sigma_denoiser,\n    lambda_reg=lambda_reg,\n    stepsize=stepsize,\n    early_stop=early_stop,\n    max_iter=max_iter,\n    crit_conv=crit_conv,\n    thres_conv=thres_conv,\n    backtracking=backtracking,\n    get_output=custom_output,\n    verbose=False,\n)\n\n# Set the model to evaluation mode. We do not require training here.\nmodel.eval()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "language": "markdown"
      },
      "source": "## Evaluate the model on the problem.\nWe evaluate the PnP algorithm on the test dataset, compute the PSNR metrics and plot reconstruction results."
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "save_folder = RESULTS_DIR / method / operation / dataset_name\nplot_convergence_metrics = True  # plot metrics. Metrics are saved in save_folder.\nplot_images = True  # plot images. Images are saved in save_folder.\n\ndataloader = DataLoader(\n    dataset, batch_size=batch_size, num_workers=num_workers, shuffle=False\n)\n\ntest(\n    model=model,\n    test_dataloader=dataloader,\n    physics=p,\n    device=device,\n    plot_images=plot_images,\n    save_folder=RESULTS_DIR / method / operation / dataset_name,\n    plot_convergence_metrics=plot_convergence_metrics,\n    verbose=True,\n)"
      ]
    },
    {
      "id": "a2a57f11",
      "cell_type": "markdown",
      "source": "## References\n\n- Romano, Yaniv and Elad, Michael and Milanfar, Peyman (2017). *The little engine that could: Regularization by denoising (RED)*. SIAM Journal on Imaging Sciences.\n- Hurault, Samuel and Leclaire, Arthur and Papadakis, Nicolas (2021). *Gradient Step Denoiser for convergent Plug-and-Play*. International Conference on Learning Representations.\n- Levin, Anat and Weiss, Yair and Durand, Fredo and Freeman, William T (2009). *Understanding and evaluating blind deconvolution algorithms*. 2009 IEEE conference on computer vision and pattern recognition.\n",
      "metadata": {
        "language": "markdown"
      }
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.14"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}