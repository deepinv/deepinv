{
  "cells": [
    {
      "id": "1489a4a8",
      "cell_type": "code",
      "metadata": {
        "language": "python"
      },
      "execution_count": null,
      "source": "# Install deepinv (skip if already installed)\n%pip install deepinv",
      "outputs": []
    },
    {
      "id": "c4d2c254",
      "cell_type": "markdown",
      "source": "<!-- MathJax macro definitions inserted automatically -->\n$$\n\\newcommand{\\forw}[1]{{A\\left({#1}\\right)}}\n\\newcommand{\\noise}[1]{{N\\left({#1}\\right)}}\n\\newcommand{\\inverse}[1]{{R\\left({#1}\\right)}}\n\\newcommand{\\inversef}[2]{{R\\left({#1},{#2}\\right)}}\n\\newcommand{\\inversename}{R}\n\\newcommand{\\reg}[1]{{g_\\sigma\\left({#1}\\right)}}\n\\newcommand{\\regname}{g_\\sigma}\n\\newcommand{\\sensor}[1]{{\\eta\\left({#1}\\right)}}\n\\newcommand{\\datafid}[2]{{f\\left({#1},{#2}\\right)}}\n\\newcommand{\\datafidname}{f}\n\\newcommand{\\distance}[2]{{d\\left({#1},{#2}\\right)}}\n\\newcommand{\\distancename}{d}\n\\newcommand{\\denoiser}[2]{{\\operatorname{D}_{{#2}}\\left({#1}\\right)}}\n\\newcommand{\\denoisername}{\\operatorname{D}_{\\sigma}}\n\\newcommand{\\xset}{\\mathcal{X}}\n\\newcommand{\\yset}{\\mathcal{Y}}\n\\newcommand{\\group}{\\mathcal{G}}\n\\newcommand{\\metric}[2]{{d\\left({#1},{#2}\\right)}}\n\\newcommand{\\loss}[1]{{\\mathcal\\left({#1}\\right)}}\n\\newcommand{\\conj}[1]{{\\overline{#1}^{\\top}}}\n$$",
      "metadata": {
        "language": "markdown"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "language": "markdown"
      },
      "source": "# Learned Iterative Soft-Thresholding Algorithm (LISTA) for compressed sensing\n\nThis example shows how to implement the LISTA algorithm (Gregor & LeCun 2010),\nfor a compressed sensing problem. In a nutshell, LISTA is an unfolded proximal gradient algorithm involving a\nsoft-thresholding proximal operator with learnable thresholding parameters."
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "from pathlib import Path\nimport torch\nfrom torchvision import datasets\nfrom torchvision import transforms\n\nimport deepinv as dinv\nfrom torch.utils.data import DataLoader\nfrom deepinv.optim.data_fidelity import L2\nfrom deepinv.optim import PGD\nfrom deepinv.utils import get_data_home\nfrom deepinv.models.utils import get_weights_url"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "language": "markdown"
      },
      "source": "## Setup paths for data loading and results."
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "BASE_DIR = Path(\".\")\nDATA_DIR = BASE_DIR / \"measurements\"\nRESULTS_DIR = BASE_DIR / \"results\"\nCKPT_DIR = BASE_DIR / \"ckpts\"\nORIGINAL_DATA_DIR = get_data_home()\n\n# Set the global random seed from pytorch to ensure reproducibility of the example.\ntorch.manual_seed(0)\n\ndevice = dinv.utils.get_device()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "language": "markdown"
      },
      "source": "## Load base image datasets and degradation operators.\nIn this example, we use MNIST as the base dataset."
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "img_size = 28\nn_channels = 1\noperation = \"compressed-sensing\"\ntrain_dataset_name = \"MNIST_train\"\n\n# Generate training and evaluation datasets in HDF5 folders and load them.\ntrain_test_transform = transforms.Compose([transforms.ToTensor()])\ntrain_base_dataset = datasets.MNIST(\n    root=ORIGINAL_DATA_DIR, train=True, transform=train_test_transform, download=True\n)\ntest_base_dataset = datasets.MNIST(\n    root=ORIGINAL_DATA_DIR, train=False, transform=train_test_transform, download=True\n)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "language": "markdown"
      },
      "source": "## Generate a dataset of compressed measurements and load it.\nWe use the compressed sensing class from the physics module to generate a dataset of highly-compressed measurements\n(10% of the total number of pixels).\n\nThe forward operator is defined as $y = Ax$\nwhere $A$ is a (normalized) random Gaussian matrix."
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# Use parallel dataloader if using a GPU to speed up training, otherwise, as all computes are on CPU, use synchronous\n# data loading.\nnum_workers = 4 if torch.cuda.is_available() else 0\n\n# Generate the compressed sensing measurement operator with 5x under-sampling factor.\nphysics = dinv.physics.CompressedSensing(\n    m=157, img_size=(n_channels, img_size, img_size), fast=True, device=device\n)\nmy_dataset_name = \"demo_LISTA\"\nn_images_max = (\n    5000 if torch.cuda.is_available() else 200\n)  # maximal number of images used for training\nmeasurement_dir = DATA_DIR / train_dataset_name / operation\ngenerated_datasets_path = dinv.datasets.generate_dataset(\n    train_dataset=train_base_dataset,\n    test_dataset=test_base_dataset,\n    physics=physics,\n    device=device,\n    save_dir=measurement_dir,\n    train_datapoints=n_images_max,\n    test_datapoints=8,\n    num_workers=num_workers,\n    dataset_filename=str(my_dataset_name),\n)\n\ntrain_dataset = dinv.datasets.HDF5Dataset(path=generated_datasets_path, train=True)\ntest_dataset = dinv.datasets.HDF5Dataset(path=generated_datasets_path, train=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "language": "markdown"
      },
      "source": "## Define the unfolded Proximal Gradient algorithm.\nIn this example, following the original LISTA algorithm (Gregor & LeCun 2010)\nthe backbone algorithm we unfold is the proximal gradient algorithm which minimizes the following objective function\n\n\\begin{align}\\begin{equation}\n         \\tag{1}\n         \\min_x \\frac{1}{2} \\|y - Ax\\|_2^2 + \\lambda \\|Wx\\|_1\n         \\end{equation}\\end{align}\n\nwhere $\\lambda$ is the regularization parameter.\nThe proximal gradient iteration (see also [`deepinv.optim.optim_iterators.PGDIteration`](https://deepinv.github.io/deepinv/api/stubs/deepinv.optim.optim_iterators.PGDIteration.html)) is defined as\n\n> **Math**\n>\n> x_{k+1} = \\text{prox}_{\\gamma \\lambda g}(x_k - \\gamma A^T (Ax_k - y))\n>\n\nwhere $\\gamma$ is the stepsize and $\\text{prox}_{g}$ is the proximity operator of $g(x) = \\|Wx\\|_1$\nwhich corresponds to soft-thresholding with a wavelet basis (see [`deepinv.optim.WaveletPrior`](https://deepinv.github.io/deepinv/api/stubs/deepinv.optim.WaveletPrior.html)).\n\nWe use [`deepinv.optim.PGD`](https://deepinv.github.io/deepinv/api/stubs/deepinv.optim.PGD.html)  with `unfold=True` to define the unfolded algorithm\nand set both the stepsizes of the LISTA algorithm $\\gamma$ (``stepsize``) and the soft\nthresholding parameters $\\lambda$ as learnable parameters.\nThese parameters are initialized with a table of length max_iter,\nyielding a distinct ``stepsize`` value for each iteration of the algorithm."
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# Select the data fidelity term\ndata_fidelity = L2()\nmax_iter = 10  # Number of unrolled iterations\nstepsize = [torch.ones(1, device=device)] * max_iter  # initialization of the stepsizes.\n# A distinct stepsize is trained for each iteration.\n\n# Set up the trainable denoising prior; here, the soft-threshold in a wavelet basis.\n# If the prior is initialized with a list of length max_iter,\n# then a distinct weight is trained for each PGD iteration.\n# For fixed trained model prior across iterations, initialize with a single model.\nlevel = 3\nprior = [\n    dinv.optim.WaveletPrior(wv=\"db8\", level=level, device=device)\n    for i in range(max_iter)\n]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "language": "markdown"
      },
      "source": "In practice, it is common to apply a different thresholding parameter for each wavelet sub-band. This means that\nthe thresholding parameter is a tensor of shape (n_levels, n_wavelet_subbands) and the associated problem (1) is\nreformulated as\n\n\\begin{align}\\begin{equation}\n         \\min_x \\frac{1}{2} \\|y - Ax\\|_2^2 +  \\sum_{i, j} \\lambda_{i, j} \\|\\left(Wx\\right)_{i, j}\\|_1\n         \\end{equation}\\end{align}\n\nwhere $\\lambda_{i, j}$ is the thresholding parameter for the wavelet sub-band $j$ at level $i$.\nNote that in this case, the prior is a list of elements containing the terms $\\|\\left(Wx\\right)_{i, j}\\|_1=g_{i, j}(x)$,\nand that it is necessary that the dimension of the thresholding parameter matches that of $g_{i, j}$."
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# Unrolled optimization algorithm parameters.\nsigma_denoiser = [\n    torch.ones(1, 3, 3, device=device)\n    * 0.01  # initialization of the regularization parameter. One thresholding parameter per wavelet sub-band and level.\n] * max_iter  # A distinct regularization parameter is trained for each iteration.\n\ntrainable_params = [\n    \"stepsize\",\n    \"sigma_denoiser\",\n]  # define which parameters are trainable\n\n# Define the unfolded trainable model.\nmodel = PGD(\n    unfold=True,\n    trainable_params=trainable_params,\n    data_fidelity=data_fidelity,\n    max_iter=max_iter,\n    prior=prior,\n    stepsize=stepsize,\n    sigma_denoiser=sigma_denoiser,\n).to(device)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "language": "markdown"
      },
      "source": "## Define the training parameters.\n\nWe now define training-related parameters,\nnumber of epochs, optimizer (Adam) and its hyperparameters, and the train and test batch sizes."
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# Training parameters\nepochs = 5 if torch.cuda.is_available() else 1\nlearning_rate = 1e-2\n\n# Choose optimizer and scheduler\noptimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n\n# Choose supervised training loss\nlosses = [dinv.loss.SupLoss(metric=dinv.metric.MSE())]\n\n# Logging parameters\nverbose = True\n\n# Batch sizes and data loaders\ntrain_batch_size = 128 if torch.cuda.is_available() else 2\ntest_batch_size = 128 if torch.cuda.is_available() else 8\n\ntrain_dataloader = DataLoader(\n    train_dataset, batch_size=train_batch_size, num_workers=num_workers, shuffle=True\n)\ntest_dataloader = DataLoader(\n    test_dataset, batch_size=test_batch_size, num_workers=num_workers, shuffle=False\n)\n\n# If working on CPU, start with a pretrained model to reduce training time\nif not torch.cuda.is_available():\n    file_name = \"ckp_10_demo_LISTA.pth.tar\"\n    url = get_weights_url(model_name=\"demo\", file_name=file_name)\n    ckpt = torch.hub.load_state_dict_from_url(\n        url, map_location=lambda storage, loc: storage, file_name=file_name\n    )\n    model.load_state_dict(ckpt[\"state_dict\"])\n    optimizer.load_state_dict(ckpt[\"optimizer\"])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "language": "markdown"
      },
      "source": "## Train the network.\n\nWe train the network using the [`deepinv.Trainer`](https://deepinv.github.io/deepinv/api/stubs/deepinv.Trainer.html) class."
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "trainer = dinv.Trainer(\n    model,\n    physics=physics,\n    train_dataloader=train_dataloader,\n    eval_dataloader=test_dataloader,\n    epochs=epochs,\n    losses=losses,\n    optimizer=optimizer,\n    device=device,\n    save_path=str(CKPT_DIR / operation),\n    verbose=verbose,\n    show_progress_bar=False,  # disable progress bar for better vis in sphinx gallery.\n)\n\nmodel = trainer.train()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "language": "markdown"
      },
      "source": "## Test the network.\n\nWe now test the learned unrolled network on the test dataset. In the plotted results, the first column shows the\nmeasurements back-projected in the image domain, the second column shows the output of our LISTA network,\nand the third shows the ground truth."
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "trainer.test(test_dataloader)\n\ntest_sample, _ = next(iter(test_dataloader))\nmodel.eval()\ntest_sample = test_sample.to(device)\n\n# Get the measurements and the ground truth\ny = physics(test_sample)\nwith torch.no_grad():  # it is important to disable gradient computation during testing.\n    rec = model(y, physics=physics)\n\nbackprojected = physics.A_adjoint(y)\n\ndinv.utils.plot(\n    [backprojected, rec, test_sample],\n    titles=[\"Linear\", \"Reconstruction\", \"Ground truth\"],\n    suptitle=\"Reconstruction results\",\n)"
      ]
    },
    {
      "id": "627c8810",
      "cell_type": "markdown",
      "source": "## References\n\n- Gregor, Karol and LeCun, Yann (2010). *Learning fast approximations of sparse coding*. Proceedings of the 27th international conference on international conference on machine learning.\n",
      "metadata": {
        "language": "markdown"
      }
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.14"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}