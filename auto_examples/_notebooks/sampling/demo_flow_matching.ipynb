{
  "cells": [
    {
      "id": "8e9d306b",
      "cell_type": "code",
      "metadata": {
        "language": "python"
      },
      "execution_count": null,
      "source": "# Install deepinv (skip if already installed)\n%pip install deepinv",
      "outputs": []
    },
    {
      "id": "f0182406",
      "cell_type": "markdown",
      "source": "<!-- MathJax macro definitions inserted automatically -->\n$$\n\\newcommand{\\forw}[1]{{A\\left({#1}\\right)}}\n\\newcommand{\\noise}[1]{{N\\left({#1}\\right)}}\n\\newcommand{\\inverse}[1]{{R\\left({#1}\\right)}}\n\\newcommand{\\inversef}[2]{{R\\left({#1},{#2}\\right)}}\n\\newcommand{\\inversename}{R}\n\\newcommand{\\reg}[1]{{g_\\sigma\\left({#1}\\right)}}\n\\newcommand{\\regname}{g_\\sigma}\n\\newcommand{\\sensor}[1]{{\\eta\\left({#1}\\right)}}\n\\newcommand{\\datafid}[2]{{f\\left({#1},{#2}\\right)}}\n\\newcommand{\\datafidname}{f}\n\\newcommand{\\distance}[2]{{d\\left({#1},{#2}\\right)}}\n\\newcommand{\\distancename}{d}\n\\newcommand{\\denoiser}[2]{{\\operatorname{D}_{{#2}}\\left({#1}\\right)}}\n\\newcommand{\\denoisername}{\\operatorname{D}_{\\sigma}}\n\\newcommand{\\xset}{\\mathcal{X}}\n\\newcommand{\\yset}{\\mathcal{Y}}\n\\newcommand{\\group}{\\mathcal{G}}\n\\newcommand{\\metric}[2]{{d\\left({#1},{#2}\\right)}}\n\\newcommand{\\loss}[1]{{\\mathcal\\left({#1}\\right)}}\n\\newcommand{\\conj}[1]{{\\overline{#1}^{\\top}}}\n$$",
      "metadata": {
        "language": "markdown"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "language": "markdown"
      },
      "source": "# Flow-Matching for posterior sampling and unconditional generation\n\nThis demo shows you how to perform unconditional image generation and posterior sampling using Flow Matching (FM).\n\nFlow matching consists in building a continuous transportation between a reference distribution $p_1$ which is easy to sample from (e.g., a Gaussian distribution) and the data distribution $p_0$.\nSampling is done by solving the following ordinary differential equation (ODE) defined by a time-dependent velocity field $v_\\theta(x,t)$:\n\n\\begin{align}\\frac{dx_t}{dt} = v_\\theta(x_t,t), \\quad x_0 \\sim p_0 \\quad t \\in [0,1]\\end{align}\n\nThe velocity field $v_\\theta(x,t)$ is typically trained to approximate the conditional expectation:\n\n\\begin{align}v_\\theta(x_t,t) \\approx \\mathbb{E}_{x_0 \\sim p_0, x_1 \\sim p_1}\\Big[ \\frac{d}{dt} x_t | x_t = a(t) x_0 + b(t) x_1 \\Big]\\end{align}\n\nwhere $a(t)$ and $b(t)$ are interpolation coefficients such that $x_t$ interpolates between $x_0$ and $x_1$.\nWhen the reference distribution $p_0$ is the standard Gaussian, the velocity field can be expressed as a function of a Gaussian denoiser $D(x, \\sigma)$ as follows:\n\n\\begin{align}v_\\theta(x_t,t) = - \\frac{b'(t)}{b(t)} x_t + \\frac{1}{2}\\frac{a(t) b'(t) - a'(t) b(t)}{a(t) b(t)} \\left(D\\left(\\frac{x_t}{a(t)}, \\frac{b(t)}{a(t)} \\right) - x_t\\right)\\end{align}\n\nThe most common choice of time schedulers is the linear schedule $a(t) = 1 - t$ and $b(t) = t$.\n\nIn this demo, we will show how to :\n\n-  Perform unconditional generation using, instead of a trained denoiser, the closed-form MMSE denoiser\n\n\\begin{align}D(x, \\sigma) = \\mathbb{E}_{x_0 \\sim p_{data}, \\epsilon \\sim \\mathcal{N}(0, I)} \\Big[ x_0 | x = x_0 + \\sigma \\epsilon \\Big]\\end{align}\n\nGiven a dataset of clean images, it can be computed by evaluating the distance between the input image and all the points of the dataset (see [`deepinv.models.MMSE`](https://deepinv.github.io/deepinv/api/stubs/deepinv.models.MMSE.html)).\n\n-  Perform posterior sampling using Flow-Matching combined with a DPS data fidelity term (see [`sampling/demo_diffusion_sde.py`](https://deepinv.github.io/deepinv/auto_examples/sampling/demo_diffusion_sde.html#sphx-glr-auto-examples-sampling-demo-diffusion-sde-py) for more details)\n\n-  Explore different choices of time schedulers $a(t)$ and $b(t)$."
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "import torch\nimport deepinv as dinv\nfrom deepinv.sampling import (\n    PosteriorDiffusion,\n    DPSDataFidelity,\n    EulerSolver,\n    FlowMatching,\n)\nimport numpy as np\nfrom torchvision import datasets, transforms\nfrom deepinv.models import MMSE"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "language": "markdown"
      },
      "source": "-----------------------------\n\nWe start by working with the closed-form MMSE denoser.  It is calculated by computing the distance between the input image and all the points of the dataset.\nThis can be quite long to compute for large images and large datasets.  In this toy example, we use the validation set of MNIST.\nWhen using this closed-form MMSE denoiser, the sampling is guaranteed to output an image of the dataset."
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "device = dinv.utils.get_device()\ndtype = torch.float32\n\nfigsize = 2.5\n\n# We use the closed-form MMSE denoiser defined using as atoms the testset of MNIST.\n# The deepinv MMSE denoiser takes as input a dataloader.\ndataset = datasets.MNIST(\n    root=\".\", train=False, download=True, transform=transforms.ToTensor()\n)\ndataloader = torch.utils.data.DataLoader(dataset, batch_size=1000, shuffle=False)\nn_max = (\n    1000  # limit the number of images to speed up the computation of the MMSE denoiser\n)\ntensors = torch.cat([data[0] for data in iter(dataloader)], dim=0)  # (N,1,28,28)\ntensors = tensors[:n_max].to(device)\ndenoiser = MMSE(dataloader=tensors, device=device, dtype=dtype)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "language": "markdown"
      },
      "source": "---------------------------------------------------------------------\n\nThe FlowMatching module [`deepinv.sampling.FlowMatching`](https://deepinv.github.io/deepinv/api/stubs/deepinv.sampling.FlowMatching.html) uses by default the following schedules: $a_t=1-t$, $b_t=t$.\nThe module FlowMatching module takes as input the denoiser and the ODE solver."
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "num_steps = 100\ntimesteps = torch.linspace(0.99, 0.0, num_steps)\nrng = torch.Generator(device).manual_seed(5)\nsolver = EulerSolver(timesteps=timesteps, rng=rng)\nsde = FlowMatching(denoiser=denoiser, solver=solver, device=device, dtype=dtype)\n\n\nsample, trajectory = sde(\n    x_init=(1, 1, 28, 28),\n    seed=0,\n    get_trajectory=True,\n)\n\ndinv.utils.plot(\n    sample,\n    titles=\"Unconditional FM generation\",\n    save_fn=\"FM_sample.png\",\n    figsize=(figsize, figsize),\n)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "language": "markdown"
      },
      "source": "-----------------------------------------------------------------------\n\nNow, we can use the Flow-Matching model to perform posterior sampling.\nWe consider the inpainting problem, where we have a masked image and we want to recover the original image.\nWe use DPS [`deepinv.sampling.DPSDataFidelity`](https://deepinv.github.io/deepinv/api/stubs/deepinv.sampling.DPSDataFidelity.html) as data fidelity term (see [`sampling/demo_diffusion_sde.py`](https://deepinv.github.io/deepinv/auto_examples/sampling/demo_diffusion_sde.html#sphx-glr-auto-examples-sampling-demo-diffusion-sde-py) for more details).\nNote that due to the division by $a(t)$ in the velocity field, initialization close to t=1 causes instability."
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "x = next(iter(dataloader))[0][:1].to(device)\n\nmask = torch.ones_like(x)\nmask[..., 10:20, 10:20] = 0.0\nphysics = dinv.physics.Inpainting(\n    img_size=x.shape[1:],\n    mask=mask,\n    device=device,\n    noise_model=dinv.physics.GaussianNoise(sigma=0.1),\n)\ny = physics(x)\ndps_fidelity = DPSDataFidelity(denoiser=denoiser, weight=1.0)\nmodel = PosteriorDiffusion(\n    data_fidelity=dps_fidelity,\n    sde=sde,\n    solver=solver,\n    dtype=dtype,\n    device=device,\n    verbose=True,\n)\nx_hat, trajectory = model(\n    y,\n    physics,\n    x_init=None,\n    get_trajectory=True,\n    seed=0,\n)\n\n# Here, we plot the original image, the measurement and the posterior sample\ndinv.utils.plot(\n    [x, y, x_hat],\n    show=True,\n    titles=[\"Original\", \"Measurement\", \"Posterior sample\"],\n    figsize=(figsize * 3, figsize),\n    save_fn=\"FM_posterior.png\",\n)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "language": "markdown"
      },
      "source": "----------------------------------------------------------------\n\nFinally, we show how to use different choices of time schedulers $a_t$ and $b_t$.\nHere, we use another typical choice of schedulers $a_t = \\cos(\\frac{\\pi}{2} t)$ and $b_t = \\sin(\\frac{\\pi}{2} t)$ which also satisfy the interpolation condition $a_0 = 1$, $b_0 = 0$, $a_1 = 0$, $b_1 = 1$.\nNote that, again, due to the division by $a_t$ in the velocity field, initialization close to t=1 causes instability."
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "a_t = lambda t: torch.cos(np.pi / 2 * t)\na_prime_t = lambda t: -np.pi / 2 * torch.sin(np.pi / 2 * t)\nb_t = lambda t: torch.sin(np.pi / 2 * t)\nb_prime_t = lambda t: np.pi / 2 * torch.cos(np.pi / 2 * t)\n\nsde = FlowMatching(\n    a_t=a_t,\n    a_prime_t=a_prime_t,\n    b_t=b_t,\n    b_prime_t=b_prime_t,\n    denoiser=denoiser,\n    solver=solver,\n    device=device,\n    dtype=dtype,\n)\n\nmodel = PosteriorDiffusion(\n    data_fidelity=dps_fidelity,\n    sde=sde,\n    solver=solver,\n    dtype=dtype,\n    device=device,\n    verbose=True,\n)\n\nx_hat, trajectory = model(\n    y,\n    physics,\n    x_init=None,\n    get_trajectory=True,\n)\n\n# Here, we plot the original image, the measurement and the posterior sample\ndinv.utils.plot(\n    [x, y, x_hat],\n    show=True,\n    titles=[\"Original\", \"Measurement\", \"Posterior sample\"],\n    figsize=(figsize * 3, figsize),\n    save_fn=\"FM_posterior_new_at_bt.png\",\n)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.14"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}