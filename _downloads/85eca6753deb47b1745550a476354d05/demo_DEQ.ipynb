{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# \ud83d\ude80 To get started, install DeepInverse by creating a new cell and running `%pip install deepinv`"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n# Deep Equilibrium (DEQ) algorithms for image deblurring\n\nThis a toy example to show you how to use DEQ to solve a deblurring problem.\nNote that this is a small dataset for training. For optimal results, use a larger dataset.\n\nFor now DEQ is only possible with PGD, HQS and GD optimization algorithms.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "import deepinv as dinv\nfrom pathlib import Path\nimport torch\nfrom torch.utils.data import DataLoader\nfrom deepinv.optim.data_fidelity import L2\nfrom deepinv.optim.prior import PnP\nfrom deepinv.unfolded import DEQ_builder\nfrom torchvision import transforms\nfrom deepinv.utils import load_dataset, load_degradation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Setup paths for data loading and results.\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "BASE_DIR = Path(\".\")\nDATA_DIR = BASE_DIR / \"measurements\"\nRESULTS_DIR = BASE_DIR / \"results\"\nCKPT_DIR = BASE_DIR / \"ckpts\"\nDEG_DIR = BASE_DIR / \"degradations\"\n\n# Set the global random seed from pytorch to ensure reproducibility of the example.\ntorch.manual_seed(0)\n\ndevice = dinv.utils.get_freer_gpu() if torch.cuda.is_available() else \"cpu\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Load base image datasets and degradation operators.\nIn this example, we use the CBSD500 dataset and the Set3C dataset for testing.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "img_size = 32\nn_channels = 3  # 3 for color images, 1 for gray-scale images\noperation = \"deblurring\"\n# For simplicity, we use a small dataset for training.\n# To be replaced for optimal results. For example, you can use the larger \"drunet\" dataset.\ntrain_dataset_name = \"CBSD500\"\ntest_dataset_name = \"set3c\"\n# Generate training and evaluation datasets in HDF5 folders and load them.\ntest_transform = transforms.Compose(\n    [transforms.CenterCrop(img_size), transforms.ToTensor()]\n)\ntrain_transform = transforms.Compose(\n    [transforms.RandomCrop(img_size), transforms.ToTensor()]\n)\ntrain_base_dataset = load_dataset(train_dataset_name, transform=train_transform)\ntest_base_dataset = load_dataset(test_dataset_name, transform=test_transform)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Generate a dataset of low resolution images and load it.\nWe use the Downsampling class from the physics module to generate a dataset of low resolution images.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# Use parallel dataloader if using a GPU to speed up training, otherwise, as all computes are on CPU, use synchronous\n# dataloading.\nnum_workers = 4 if torch.cuda.is_available() else 0\n\n# Degradation parameters\nnoise_level_img = 0.03\n\n# Generate a motion blur operator.\nkernel_index = 1  # which kernel to chose among the 8 motion kernels from 'Levin09.mat'\nkernel_torch = load_degradation(\"Levin09.npy\", DEG_DIR / \"kernels\", index=kernel_index)\nkernel_torch = kernel_torch.unsqueeze(0).unsqueeze(\n    0\n)  # add batch and channel dimensions\n\n# Generate the gaussian blur downsampling operator.\nphysics = dinv.physics.BlurFFT(\n    img_size=(n_channels, img_size, img_size),\n    filter=kernel_torch,\n    device=device,\n    noise_model=dinv.physics.GaussianNoise(sigma=noise_level_img),\n)\n\nmy_dataset_name = \"demo_DEQ\"\nn_images_max = (\n    1000 if torch.cuda.is_available() else 10\n)  # maximal number of images used for training\nmeasurement_dir = DATA_DIR / train_dataset_name / operation\ngenerated_datasets_path = dinv.datasets.generate_dataset(\n    train_dataset=train_base_dataset,\n    test_dataset=test_base_dataset,\n    physics=physics,\n    device=device,\n    save_dir=measurement_dir,\n    train_datapoints=n_images_max,\n    num_workers=num_workers,\n    dataset_filename=str(my_dataset_name),\n)\n\ntrain_dataset = dinv.datasets.HDF5Dataset(path=generated_datasets_path, train=True)\ntest_dataset = dinv.datasets.HDF5Dataset(path=generated_datasets_path, train=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Define the  DEQ algorithm.\nWe use the helper function :func:`deepinv.unfolded.DEQ_builder` to defined the DEQ architecture.\nThe chosen algorithm is here HQS (Half Quadratic Splitting).\nNote for DEQ, the prior and regularization parameters should be common for all iterations\nto keep a constant fixed-point operator.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# Select the data fidelity term\ndata_fidelity = L2()\n\n# Set up the trainable denoising prior. Here the prior model is common for all iterations. We use here a pretrained denoiser.\nprior = PnP(denoiser=dinv.models.DnCNN(depth=20, pretrained=\"download\").to(device))\n\n# Unrolled optimization algorithm parameters\nmax_iter = 20 if torch.cuda.is_available() else 10\nstepsize = [1.0]  # stepsize of the algorithm\nsigma_denoiser = [0.03]  # noise level parameter of the denoiser\njacobian_free = False  # does not perform Jacobian inversion.\n\nparams_algo = {  # wrap all the restoration parameters in a 'params_algo' dictionary\n    \"stepsize\": stepsize,\n    \"g_param\": sigma_denoiser,\n}\ntrainable_params = [\n    \"stepsize\",\n    \"g_param\",\n]  # define which parameters from 'params_algo' are trainable\n\n# Define the unfolded trainable model.\nmodel = DEQ_builder(\n    iteration=\"PGD\",  # For now DEQ is only possible with PGD, HQS and GD optimization algorithms.\n    params_algo=params_algo.copy(),\n    trainable_params=trainable_params,\n    data_fidelity=data_fidelity,\n    max_iter=max_iter,\n    prior=prior,\n    anderson_acceleration=True,\n    anderson_acceleration_backward=True,\n    history_size_backward=3,\n    history_size=3,\n    max_iter_backward=20,\n    jacobian_free=jacobian_free,\n)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Define the training parameters.\nWe use the Adam optimizer and the StepLR scheduler.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# training parameters\nepochs = 10 if torch.cuda.is_available() else 2\nlearning_rate = 1e-4\ntrain_batch_size = 32 if torch.cuda.is_available() else 1\ntest_batch_size = 3\n\n\n# choose optimizer and scheduler\noptimizer = torch.optim.Adam(model.parameters(), lr=learning_rate, weight_decay=1e-8)\nscheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=int(epochs * 0.8))\n\n# choose supervised training loss\nlosses = [dinv.loss.SupLoss(metric=dinv.metric.MSE())]\n\n# Logging parameters\nverbose = True\n\ntrain_dataloader = DataLoader(\n    train_dataset, batch_size=train_batch_size, num_workers=num_workers, shuffle=True\n)\ntest_dataloader = DataLoader(\n    test_dataset, batch_size=test_batch_size, num_workers=num_workers, shuffle=False\n)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Train the network\nWe train the network using the library's train function.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "trainer = dinv.Trainer(\n    model=model,\n    physics=physics,\n    epochs=epochs,\n    scheduler=scheduler,\n    device=device,\n    losses=losses,\n    optimizer=optimizer,\n    train_dataloader=train_dataloader,\n    eval_dataloader=test_dataloader,\n    save_path=str(CKPT_DIR / operation),\n    verbose=verbose,\n    show_progress_bar=True,  # disable progress bar for better vis in sphinx gallery.\n)\n\ntrainer.train()\nmodel = trainer.load_best_model()  # load model with best validation PSNR"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Test the network\n\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "trainer.test(test_dataloader)\n\ntest_sample, _ = next(iter(test_dataloader))\nmodel.eval()\ntest_sample = test_sample.to(device)\n\n# Get the measurements and the ground truth\ny = physics(test_sample)\nwith torch.no_grad():\n    rec = model(y, physics=physics)\n\nbackprojected = physics.A_adjoint(y)\n\ndinv.utils.plot(\n    [backprojected, rec, test_sample],\n    titles=[\"Linear\", \"Reconstruction\", \"Ground truth\"],\n    suptitle=\"Reconstruction results\",\n)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}