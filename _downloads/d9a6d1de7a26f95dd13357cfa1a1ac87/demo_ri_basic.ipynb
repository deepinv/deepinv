{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# \ud83d\ude80 To get started, install DeepInverse by creating a new cell and running `%pip install deepinv`"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n# Radio interferometric imaging with deepinverse\n\nIn this example, we investigate a simple 2D Radio Interferometry (RI) imaging task with deepinverse.\nThe following example and data are taken from :footcite:t:`aghabiglou2024r2d2`.\nIf you are interested in RI imaging problem and would like to see more examples or try the state-of-the-art algorithms, please check [BASPLib](https://basp-group.github.io/BASPLib/).\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Import required packages\nWe rely on the `TorchKbNufft` as the non-uniform FFT backend in this problem.\nThis first snippet is just here to check that dependencies are installed properly.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "import torch\nimport numpy as np\nimport torchkbnufft as tkbn\n\nimport deepinv as dinv\nfrom deepinv.utils.plotting import plot, plot_curves, scatter_plot, plot_inset\nfrom deepinv.utils import load_np_url, get_image_url, get_degradation_url\nfrom deepinv.utils.tensorlist import dirac_like\n\ndevice = \"cuda\" if torch.cuda.is_available() else \"cpu\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## The RI measurement operator\nThe RI inverse problem aims at restoring the target image $x\\in \\mathbb{R}^{n}$ from complex measurements (or visibilities) $y \\in \\mathbb{C}^{m}$, reads:\n\n\\begin{align}\\begin{equation*}\n      y = Ax+\\epsilon,\n  \\end{equation*}\\end{align}\n\nwhere $A$ can be decomposed as $A = GFZ \\in \\mathbb{C}^{m \\times n}$.\nThere, $G \\in \\mathbb{C}^{m \\times d}$ is a sparse interpolation matrix,\nencoding the non-uniform Fourier transform,\n$F \\in \\mathbb{C}^{d\\times d}$ is the 2D Discrete Fourier Transform,\n$Z \\in \\mathbb{R}^{d\\times n}$ is a zero-padding operator,\nincorporating the correction for the convolution performed through the operator $G$,\nand $\\epsilon \\in \\mathbb{C}^{m}$ is a realization of some i.i.d. Gaussian random noise.\n\nThis operator can be implemented with [TorchKbNUFFT](https://github.com/mmuckley/torchkbnufft).\nBelow, we propose an implementation using the :class:`deepinv.physics.LinearPhysics`.\nAs such, operations like grad and prox are available.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "from deepinv.physics import LinearPhysics\n\n\nclass RadioInterferometry(LinearPhysics):\n    r\"\"\"\n    Radio Interferometry measurement operator.\n\n    Args:\n        img_size (tuple): Size of the target image, e.g., (H, W).\n        samples_loc (torch.Tensor): Normalized sampling locations in the Fourier domain.\n        dataWeight (torch.Tensor): Data weighting for the measurements.\n        interp_points (Union[int, Sequence[int]]): Number of neighbors to use for interpolation in each dimension. Default is `7`.\n        k_oversampling (float): Oversampling of the k space grid, should be between `1.25` and `2`. Default is `2`.\n        real_projection (bool): Apply real projection after the adjoint NUFFT.\n        device (torch.device): Device where the operator is computed.\n    \"\"\"\n\n    def __init__(\n        self,\n        img_size,\n        samples_loc,\n        dataWeight=torch.tensor(\n            [\n                1.0,\n            ]\n        ),\n        k_oversampling=2,\n        interp_points=7,\n        real_projection=True,\n        device=\"cpu\",\n        **kwargs,\n    ):\n        super(RadioInterferometry, self).__init__(**kwargs)\n\n        self.device = device\n        self.k_oversampling = k_oversampling\n        self.interp_points = interp_points\n        self.img_size = img_size\n        self.real_projection = real_projection\n\n        # Check image size format\n        assert len(self.img_size) == 2\n\n        # Define oversampled grid\n        self.grid_size = (\n            int(img_size[0] * self.k_oversampling),\n            int(img_size[1] * self.k_oversampling),\n        )\n\n        self.samples_loc = samples_loc.to(self.device)\n        self.dataWeight = dataWeight.to(self.device)\n\n        self.nufftObj = tkbn.KbNufft(\n            im_size=self.img_size,\n            grid_size=self.grid_size,\n            numpoints=self.interp_points,\n            device=self.device,\n        )\n        self.adjnufftObj = tkbn.KbNufftAdjoint(\n            im_size=self.img_size,\n            grid_size=self.grid_size,\n            numpoints=self.interp_points,\n            device=self.device,\n        )\n\n        # Define adjoint operator projection\n        if self.real_projection:\n            self.adj_projection = lambda x: torch.real(x).to(torch.float)\n        else:\n            self.adj_projection = lambda x: x\n\n    def setWeight(self, w):\n        self.dataWeight = w.to(self.device)\n\n    def A(self, x):\n        return (\n            self.nufftObj(x.to(torch.cfloat), self.samples_loc, norm=\"ortho\")\n            * self.dataWeight\n        )\n\n    def A_adjoint(self, y):\n        return self.adj_projection(\n            self.adjnufftObj(y * self.dataWeight, self.samples_loc, norm=\"ortho\")\n        )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "This measurement operator is readily available in the Physics module in :class:`deepinv.physics.RadioInterferometry`\nand can be used directly as\n\n::\n\n        from deepinv.physics import RadioInterferometry\n\n        physics = RadioInterferometry(img_size=img_size, samples_loc=samples_loc, device=device)\n\n\n## Groundtruth image\nThe following data is our groundtruth with the settings of Experiment II in :footcite:t:`aghabiglou2024r2d2`.\nThe groundtruth data has been normalized in the [0, 1] range.\nAs usual in radio interferometric imaging, the data has high dynamic range,\ni.e. the ratio between the faintest and highest emissions is higher than in traditional low-level vision tasks.\nIn the case of this particular image, this ratio is of ``5000``.\nFor this reason, unlike in other applications, we tend to visualize the logarithmic scale of the data instead of the data itself.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "image_gdth = (\n    load_np_url(get_image_url(\"3c353_gdth.npy\")).unsqueeze(0).unsqueeze(0).to(device)\n)\n\n\ndef to_logimage(im, rescale=False, dr=5000):\n    r\"\"\"\n    A function plotting the image in logarithmic scale with specified dynamic range\n    \"\"\"\n    if rescale:\n        im = im - im.min()\n        im = im / im.max()\n    else:\n        im = torch.clamp(im, 0, 1)\n    return torch.log10(dr * im + 1.0) / np.log10(dr)\n\n\nimgs = [image_gdth, to_logimage(image_gdth)]\nplot(\n    imgs,\n    titles=[f\"Groundtruth\", f\"Groundtruth \\nin logarithmic scale\"],\n    cmap=\"inferno\",\n    cbar=True,\n)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Sampling pattern\nWe'll load a simulated sampling pattern of [Very Large Array](https://public.nrao.edu/telescopes/vla/) telescope.\nFor simplicity, the coordinates of the sampling points have been normalized to the range of $[-\\pi, \\pi]$.\nIn RI imaging task, a super-resolution factor will normally be introduced in imaging step,\nso that the possibility of point sources appearing on the boundaries of pixels can be reduced.\nHere, this factor is ``1.5``.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "uv = load_np_url(get_degradation_url(\"uv_coordinates.npy\")).to(device)\n\nscatter_plot([uv], titles=[\"uv coverage\"], s=0.2, linewidths=0.0)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Simulating the measurements\nWe now have all the data and tools to generate our measurements!\nThe noise level $\\tau$ in the spacial Fourier domain is set to ``0.5976 * 2e-3``.\nThis value will preserve the dynamic range of the groundtruth image in this case.\nPlease check :footcite:t:`terris2023image` and :footcite:t:`aghabiglou2024r2d2`.\nfor more information about the relationship between the noise level in the Fourier domain and the dynamic range of the target image.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "tau = 0.5976 * 2e-3\n\n# build sensing operator\nphysics = RadioInterferometry(\n    img_size=image_gdth.shape[-2:],\n    samples_loc=uv.permute((1, 0)),\n    real_projection=True,\n    device=device,\n)\n\n# Generate the physics\ntorch.manual_seed(0)\ny = physics.A(image_gdth)\nnoise = (torch.randn_like(y) + 1j * torch.randn_like(y)) / np.sqrt(2)\ny = y + tau * noise"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Natural weighting and Briggs weighting\nA common practice in RI consists is weighting the measurements in the Fourier domain to\nwhiten the noise level in the spatial Fourier domain and compensate the over-sampling of visibilities at low-frequency regions.\nWe here provide the Briggs-weighting scheme associated to the above uv-sampling pattern.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# load pre-computed Briggs weighting\nnWimag = (\n    load_np_url(get_degradation_url(\"briggs_weight.npy\")).reshape(1, 1, -1).to(device)\n)\n\n# apply natural weighting and Briggs weighting to measurements\ny *= nWimag / tau\n\n# add image weighting to the sensing operator\nphysics.setWeight(nWimag / tau)\n\n# compute operator norm (note: increase the iteration number for higher precision)\nopnorm = physics.compute_sqnorm(\n    torch.randn_like(image_gdth, device=device),\n    max_iter=20,\n    tol=1e-6,\n    verbose=False,\n).item()\nprint(\"Operator norm: \", opnorm)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The PSF, defined as $\\operatorname{PSF} = A \\delta$ (where $\\delta$ is a Dirac), can be computed\nwith the help of the :func:`deepinv.utils.dirac_like` function.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "dirac = dirac_like(image_gdth).to(device)\nPSF = physics.A_adjoint(physics.A(dirac))\nprint(\"PSF peak value: \", PSF.max().item())\n\npsf_log = to_logimage(PSF, rescale=True)\n\nplot_inset(\n    [psf_log],\n    titles=[\"PSF (logscale)\"],\n    cmap=\"viridis\",\n    extract_loc=(0.46, 0.46),\n    extract_size=0.08,\n    inset_loc=(0.0, 0.6),\n    inset_size=0.4,\n)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The backprojected image $A^{\\top}Ay$ is shown below.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "back = physics.A_adjoint(y)\n\nimgs = [to_logimage(image_gdth), to_logimage(back, rescale=True)]\nplot(\n    imgs,\n    titles=[f\"Groundtruth \\n(logscale)\", f\"Backprojection \\n(logscale)\"],\n    cmap=\"inferno\",\n)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Solving the problem with a wavelet prior\nA traditional approach for solving the RI problem consists in solving the optimization problem\n\n\\begin{align}\\begin{equation*}\n      \\underset{x \\geq 0}{\\operatorname{min}} \\,\\, \\frac{1}{2} \\|Ax-y\\|_2^2 + \\lambda \\sum_i \\|\\Psi_i x\\|_{1}(x),\n  \\end{equation*}\\end{align}\n\nwhere $1/2 \\|A(x)-y\\|_2^2$ is the a data-fidelity term, and each $\\|\\Psi_i x\\|_{1}(x)$ is a sparsity\ninducing prior for the image $x$, and $\\lambda>0$ is a regularisation parameter. Simlarly to the [SARA](https://basp-group.github.io/BASPLib/SARA_family.html)\nalgorithm, we use a dictionnary of 8 Daubechies wavelets as the prior.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "from deepinv.optim.data_fidelity import L2\nfrom deepinv.optim.prior import WaveletPrior\n\n# Select the data fidelity term\ndata_fidelity = L2()\n\n# Specify the prior (we redefine it with a smaller number of iteration for faster computation)\nwv_list = [\"db1\", \"db2\", \"db3\", \"db4\", \"db5\", \"db6\", \"db7\", \"db8\"]\nprior = WaveletPrior(level=3, wv=wv_list, p=1, device=\"cpu\", clamp_min=0)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The problem is quite challenging and to reduce optimization time,\nwe can start from an approximate guess of the solution that is pseudo-inverse reconstruction.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "def custom_init(y, physics):\n    x_init = torch.clamp(physics.A_dagger(y), 0)\n    return {\"est\": (x_init, x_init)}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We are now ready to implement the FISTA algorithm.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "from deepinv.optim.optimizers import optim_builder\n\n# Logging parameters\nverbose = True\n\nplot_convergence_metrics = (\n    True  # compute performance and convergence metrics along the algorithm.\n)\n\n# Algorithm parameters\nstepsize = 1.0 / (1.5 * opnorm)\nlamb = 1e-3 * opnorm  # wavelet regularisation parameter\nparams_algo = {\"stepsize\": stepsize, \"lambda\": lamb}\nmax_iter = 50\nearly_stop = True\n\n# Instantiate the algorithm class to solve the problem.\nmodel = optim_builder(\n    iteration=\"FISTA\",\n    prior=prior,\n    data_fidelity=data_fidelity,\n    early_stop=early_stop,\n    max_iter=max_iter,\n    verbose=verbose,\n    params_algo=params_algo,\n    custom_init=custom_init,\n)\n\n# reconstruction with FISTA algorithm\nx_model, metrics = model(y, physics, x_gt=image_gdth, compute_metrics=True)\n\n# compute PSNR\nprint(\n    f\"Linear reconstruction PSNR: {dinv.metric.PSNR()(image_gdth, back).item():.2f} dB\"\n)\nprint(\n    f\"FISTA reconstruction PSNR: {dinv.metric.PSNR()(image_gdth, x_model).item():.2f} dB\"\n)\n\n# plot images\n# sphinx_gallery_multi_image = \"single\"\nimgs = [\n    to_logimage(image_gdth),\n    to_logimage(back, rescale=True),\n    to_logimage(x_model, rescale=True),\n]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "plot(imgs, titles=[\"GT\", \"Linear\", \"Recons.\"], cmap=\"inferno\", cbar=True)\n\n# plot convergence curves\nif plot_convergence_metrics:\n    plot_curves(metrics)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We can see that the bright sources are generally recovered,\nbut not for the faint and extended emissions.\nWe kindly point the readers to [BASPLib](https://basp-group.github.io/BASPLib/)\nfor the state-of-the-art RI imaging algorithms, such as\n[R2D2](https://basp-group.github.io/BASPLib/R2D2.html),\n[AIRI](https://basp-group.github.io/BASPLib/AIRI.html),\n[SARA](https://basp-group.github.io/BASPLib/SARA_family.html),\nand corresponding reconstructions.\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        ":References:\n\n.. footbibliography::\n\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}