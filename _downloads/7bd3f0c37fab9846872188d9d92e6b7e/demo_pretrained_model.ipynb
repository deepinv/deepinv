{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# \ud83d\ude80 To get started, install DeepInverse by creating a new cell and running `%pip install deepinv`"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n# Use a pretrained model\n\nFollow this example to reconstruct images using a pretrained model in one line.\n\nWe show three sets of general pretrained reconstruction methods, including:\n\n* Pretrained feedforward :class:`Reconstruct Anything Model (RAM) <deepinv.models.RAM>`;\n* `Plug-and-play <iterative>` with a pretrained denoiser.\n* Pretrained `diffusion model <diffusion>`;\n\nSee `pretrained models <pretrained-models>` for a principled comparison between methods demonstrated in this example.\n\n.. tip::\n\n    * Want to use your own dataset? See `sphx_glr_auto_examples_basics_demo_custom_dataset.py`\n    * Want to use your own physics? See `sphx_glr_auto_examples_basics_demo_custom_physics.py`\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "import deepinv as dinv\nimport torch\n\ndevice = dinv.utils.get_freer_gpu() if torch.cuda.is_available() else \"cpu\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Let's say you want to reconstruct a butterfly from noisy, blurry measurements:\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# Ground truth\nx = dinv.utils.load_example(\"butterfly.png\", device=device)\n\n# Define physics\nphysics = dinv.physics.BlurFFT(\n    x.shape[1:],\n    filter=dinv.physics.blur.gaussian_blur((5, 5)),\n    noise_model=dinv.physics.GaussianNoise(\n        sigma=0.1, rng=torch.Generator(device=x.device).manual_seed(123)\n    ),\n    device=device,\n)\n\ny = physics(x)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "For each model, define model in one line and reconstruct in one line.\nPretrained Reconstruct Anything Model:\n\n.. seealso::\n    See `sphx_glr_auto_examples_models_demo_foundation_model.py` for further one-line examples for the RAM model across various domains.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "model = dinv.models.RAM(pretrained=True, device=device)\n\nwith torch.no_grad():\n    x_hat1 = model(y, physics)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "PnP algorithm with pretrained denoiser:\n\n.. seealso::\n    See `pretrained denoisers <pretrained-weights>` for a full list of denoisers that can be plugged into iterative/sampling algorithms.\n\n    See `sphx_glr_auto_examples_plug-and-play_demo_PnP_DPIR_deblur.py` for a further example of using plug-and-play with a pretrained denoiser.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "denoiser = dinv.models.DRUNet(device=device)\nmodel = dinv.optim.DPIR(sigma=0.1, denoiser=denoiser, device=device)\n\nx_hat2 = model(y, physics)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Pretrained diffusion model (we reduce the image size for demo speed on CPU, as diffusion model is slow):\n\n.. seealso::\n    See `sphx_glr_auto_examples_sampling_demo_ddrm.py` for a further example of using a pretrained diffusion model.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "model = dinv.sampling.DDRM(denoiser, sigmas=torch.linspace(1, 0, 20)).to(device)\n\nx_hat3 = model(y, physics)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Plot results\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "dinv.utils.plot(\n    {\n        \"Ground Truth\": x,\n        \"Measurement\": y,\n        \"Pretrained \\nRAM\": x_hat1,\n        \"Pretrained \\nPnP\": x_hat2,\n        \"Pretrained \\nDiffusion\": x_hat3,\n    },\n    subtitles=[\n        \"PSNR:\",\n        f\"{dinv.metric.PSNR()(y, x).item():.2f} dB\",\n        f\"{dinv.metric.PSNR()(x_hat1, x).item():.2f} dB\",\n        f\"{dinv.metric.PSNR()(x_hat2, x).item():.2f} dB\",\n        f\"{dinv.metric.PSNR()(x_hat3, x).item():.2f} dB\",\n    ],\n    figsize=(10, 5),\n)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\ud83c\udf89 Well done, you now know how to use pretrained models!\n\n## What's next?\n* Check out the `example on how to fine-tune a foundation model to your own problem <sphx_glr_auto_examples_models_demo_foundation_model.py>`.\n* See `pretrained models <pretrained-models>` for a comparison between methods demonstrated in this example.\n* See `diffusion <diffusion>` and `iterative <iterative>` for how to fully customize your sampling or iterative algorithm using a pretrained denoiser.\n\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}