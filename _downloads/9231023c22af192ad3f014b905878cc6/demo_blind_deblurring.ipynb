{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# \ud83d\ude80 To get started, install DeepInverse by creating a new cell and running `%pip install deepinv`"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n# Blind deblurring with kernel estimation network\n\nThis example demonstrates blind image deblurring using the pretrained kernel estimation network from\nthe paper :footcite:t:`carbajal2023blind`. The network estimates spatially-varying blur kernels from a blurred image,\nwhich are then used in a space-varying blur physics model to reconstruct the sharp image using a non-blind deblurring algorithm.\n\nThe model estimates 25 spatially-varying (33 x 33) blur kernels and corresponding spatial multipliers (weights) of the space-varying blur model:\n\n\\begin{align}y \\approx \\sum_{k=1}^{25} h_k \\star (w_k \\odot x)\\end{align}\n\nwhere $\\star$ is a convolution, $\\odot$ is a Hadamard product,  $w_k$ are multipliers $h_k$ are filters.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "import torch\nimport deepinv as dinv\nfrom deepinv.models import KernelIdentificationNetwork, RAM\nfrom deepinv.optim import DPIR\n\ndevice = dinv.utils.get_freer_gpu() if torch.cuda.is_available() else \"cpu\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Load blurry image\n\nWe load a real motion-blurred image from the Kohler dataset.\nYou can access the whole dataset using :class:`deepinv.datasets.Kohler`.\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "y = dinv.utils.load_example(\"kohler.png\", device=device)[:, :3, ...]\n\ndinv.utils.plot({\"Blurry Image\": y})  # plot blurry image"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Estimate blur kernels\n\nWe use the pretrained kernel estimation network to estimate the spatially-varying blur kernels from the blurry image.\nThe network provides 25 filters and corresponding spatial multipliers (weights) of the space-varying blur model (:class:`deepinv.physics.SpaceVaryingBlur`).\n\nWe can visualise the estimated kernels by applying the forward operator to a Dirac comb input.\n\n<div class=\"alert alert-info\"><h4>Note</h4><p>The kernel estimation network is trained on non-gamma corrected images.\n    If your input image is gamma-corrected (e.g., standard sRGB images),\n    consider applying an inverse gamma correction before passing it to the network for better results.</p></div>\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# load pretrained kernel estimation network\nkernel_estimator = KernelIdentificationNetwork(device=device)\n\n# define space-varying blur physics\nphysics = dinv.physics.SpaceVaryingBlur(device=device, padding=\"constant\")\n\nwith torch.no_grad():\n    params = kernel_estimator(y)  # this outputs {\"filters\": ..., \"multipliers\": ...}\n    physics.update(**params)\n    dirac_comb = dinv.utils.dirac_comb_like(y, step=32)\n    kernel_map = physics.A(dirac_comb)\n\n    # visualize on a zoomed region\n    dinv.utils.plot(\n        {\n            \"Estimated Kernels\": kernel_map[..., 128:512, 128:512],\n            \"Blurry Image\": y[..., 200:300, 200:300],\n        }\n    )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Deblur using non-blind reconstruction methods\n\nFinally, we use two different non-blind deblurring algorithms to reconstruct the sharp image from the blurry observation and the estimated blur kernels:\nHere we use the general reconstruction model :class:`deepinv.models.RAM` and the plug-and-play method :class:`deepinv.optim.DPIR`.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "model = RAM(device=device)\nwith torch.no_grad():\n    x_ram = model(y, physics, sigma=0.05)\n    x_ram = x_ram.clamp(0, 1)\n\nmodel = DPIR(sigma=0.05, device=device)\nx_dpir = model(y, physics)\nx_dpir = x_dpir.clamp(0, 1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## No reference metrics and visualization\n\nAs here we assume that we do not have access to the ground truth sharp image,\nwe cannot compute reference metrics such as PSNR or SSIM.\nHowever, we can still compute no-reference metrics such as NIQE (lower is better), Blur Strengh (lower is better) and\nSharpness Index (higher is better)\nto assess the quality of the reconstructions.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "center_crop = -10  # remove 10 pixels from each border to avoid boundary effects\n\nniqe = dinv.metric.NIQE(center_crop=center_crop)\n\nniqe_blurry = niqe(y).item()\nniqe_ram = niqe(x_ram).item()\nniqe_dpir = niqe(x_dpir).item()\n\nbs = dinv.metric.BlurStrength(center_crop=center_crop)\n\nbs_blurry = bs(y).item()\nbs_ram = bs(x_ram).item()\nbs_dpir = bs(x_dpir).item()\n\nsi = dinv.metric.SharpnessIndex(center_crop=center_crop)\n\nsi_blurry = si(y).item()\nsi_ram = si(x_ram).item()\nsi_dpir = si(x_dpir).item()\n\n\ndinv.utils.plot(\n    {\"Blurry\": y, \"RAM\": x_ram, \"DPIR\": x_dpir},\n    subtitles=[\n        f\"SI: {si_blurry:.0f} \\n BS: {bs_blurry:.3f} \\n  NIQE: {niqe_blurry:.2f}\",\n        f\"SI: {si_ram:.0f} \\n BS: {bs_ram:.3f} \\n  NIQE: {niqe_ram:.2f} \",\n        f\"SI: {si_dpir:.0f} \\n BS: {bs_dpir:.3f} \\n  NIQE: {niqe_dpir:.2f} \",\n    ],\n    figsize=(10, 5),\n)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        ":References:\n\n.. footbibliography::\n\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.14"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}