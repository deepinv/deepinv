{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# \ud83d\ude80 To get started, install DeepInverse by creating a new cell and running `%pip install deepinv`"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n# Inverse scattering problem\n\nIn this example we show how to use the :class:`deepinv.physics.Scattering` forward model.\n\nThe scattering inverse problem consists in reconstructing the contrast of an unknown object\nfrom measurements of the scattered wave field resulting from the interaction of an incident\nwave with the object.\n\nFor each of the $i=1,\\dots,T$ transmitters, the 2D forward model is given by inhomogeneous Helmholtz equation (see e.g., :cite:t:`soubies2017efficient`):\n\n\n\\begin{align}\\nabla^2 u_i(\\mathbf{r}) + k^2(\\mathbf{r})  u_i(\\mathbf{r}) = - (k^2(\\mathbf{r}) - k^2_b)  v_i(\\mathbf{r})  \\quad \\mathbf{r} \\in \\mathbb{R}^2\\end{align}\n\nwhere $u_i$ is the (unknown) scattered field, $k_b$ is the (known scalar) wavenumber of the incident wave in the background medium,\n$k(\\mathbf{r})$ is the (unknown) spatially-varying wavenumber of the object to be recovered,\nand $v_i$ is the incident field generated by the ith transmitter in the absence of the object.\nThe total field (scattered + incident) is measured at $R$ different receiver locations surrounding the object.\n\nParametrizing the unknown spatially-varying wavenumber as $k^2(\\mathbf{r}) = k_b^2 (x(\\mathbf{r})+1)$, where\n$k_b$ is the background wavenumber, and $x = k^2/k_b^2 - 1$ is the scattering potential of the object to be recovered,\nthe forward problem can be reformulated in the **Lippmann-Schwinger** integral equation form:\n\n\\begin{align}u_i &= g * \\left( x \\circ (u_i+v_i) \\right) \\\\\n    y_i &= G_s \\left( x \\circ (u_i+v_i) \\right)\\end{align}\n\nwhere $g(\\mathbf{r}) = k_b^2 \\frac{i}{4} H_0^1(k_b\\|\\mathbf{r}\\|)$ is Green's function in 2D (normalized by $k_b^2$),\n$y \\in \\mathbb{C}^{R}$ are the measurements at the receivers for the ith transmitter,\nand $G_s$ denotes the convolution with Green's operator plus sampling at the $R$ different receiver locations.\n\n.. tip::\n\n    This parametrization ensures that the scattering potential $x$ is dimensionless, and can be used for different physical\n    modalities:\n    In **microwave tomography** applications, the scattering potential is related to the object's relative permittivity $\\epsilon_r$ as $x(\\mathbf{r}) = \\epsilon_r(\\mathbf{r}) - 1$.\n    In **optical diffraction tomography**, the scattering potential is related to the refractive index $n$ as $x(\\mathbf{r}) = n^2(\\mathbf{r}) - 1$.\n\n    Moreover, the wavenumber can be also provided in a dimensionless form by normalizing it with respect to the box length $L$ as $k_b = 2 \\pi L / \\lambda$,\n    where $\\lambda$ is the wavelength of the incident wave.\n\nThis example shows how to define the scattering forward model, generate measurements,\nand perform reconstructions (i.e., recover the contrast of the object) using both a linear (Born approximation) solver and a non-linear\ngradient descent solver. We also explore the trade-off between resolution and non-linearity\nby varying the wavenumber of the incident wave.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "import deepinv as dinv\nimport torch\nfrom matplotlib import pyplot as plt\n\ndevice = dinv.utils.get_freer_gpu() if torch.cuda.is_available() else \"cpu\"\n\nimg_width = 32\n\nx = dinv.utils.load_example(\n    \"SheppLogan.png\",\n    img_size=img_width,\n    resize_mode=\"resize\",\n    device=device,\n    grayscale=True,\n)\n\ncontrast = (\n    0.5 if device != \"cpu\" else 0.1\n)  # reduce contrast for CPU for faster convergence\nx = x * contrast\n\npsnr = dinv.metric.PSNR(max_pixel=contrast)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Define the forward model\n\nWe define a scattering forward model with circularly distributed transmitters and receivers.\n\nThe forward operator internally solves the Lippmann-Schwinger equation for the scattered field of each\ntransmitter:\n\n\\begin{align}u_i = g * \\left(x \\circ (u_i + v_i) \\right)\\end{align}\n\nusing a linear system solver, which aims at finding the solution $u_i$ of\n\n\\begin{align}\\left(I - G_s \\text{diag}(x)\\right) u_i = b_i\\end{align}\n\nwhere $G_s$ is the convolution operator with Green's function $g$, and $b_i = G_s (x \\circ v_i)$.\n\nThis linear system becomes highly ill-conditioned for high contrast objects (i.e., large $\\|x\\|_{\\infty}$) and/or high wavenumber\n(which induces a high spectral norm of the Green operator $\\|G_s\\|_2$), and the solver\nmay fail to converge. In that case, one can try to increase the number of iterations, or change the solver (see\n:class:`deepinv.physics.Scattering.SolverConfig` for more details).\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "sensors = 32\ntransmitters, receivers = dinv.physics.scattering.circular_sensors(\n    sensors, radius=1, device=device\n)\nwavenumber = 5 * (2 * torch.pi)\n\nconfig = dinv.physics.Scattering.SolverConfig(\n    max_iter=200, tol=1e-5, solver=\"lsqr\", adjoint_state=True\n)\n\nphysics = dinv.physics.Scattering(\n    img_width=img_width,\n    device=device,\n    background_wavenumber=wavenumber,\n    solver_config=config,\n    transmitters=transmitters,\n    receivers=receivers,\n)\nphysics.normalize(x)\n\n\nphysics.set_verbose(True)\ny = physics(x)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Visualize sensor positions\nIn this example, we assume we have 64 sensors that can be used both as transmitters and receivers,\nplaced on a circle of radius 1 around the object. Each transmitter emits a cylindrical wave, and the rest of the sensors\nmeasure the scattered field.\nWe first visualize the position of the first transmitter and its associated receivers.\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "plt.figure()\nplt.scatter(\n    transmitters[0, 0].cpu(), transmitters[1, 0].cpu(), c=\"r\", label=\"Transmitter\"\n)\nplt.scatter(\n    receivers[0, 0, :].cpu(), receivers[1, 0, :].cpu(), c=\"b\", label=\"Receivers\"\n)\n# draw square of length1\nplt.plot(\n    [-0.5, 0.5, 0.5, -0.5, -0.5],\n    [-0.5, -0.5, 0.5, 0.5, -0.5],\n    c=\"k\",\n    label=\"box where object is located\",\n)\nplt.legend()\nplt.title(\"First transmitter and associated receiver positions\")\nplt.axis(\"equal\")\nplt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Visualize incident and total fields\nWe now visualize the incident and scattered fields for the first transmitter.\nThe incident field $v_i$ is the field that would be present in the absence of the object,\nwhile the total field $u_i + v_i$ is the sum of the incident and scattered fields.\n\nSince the fields are complex-valued, we only visualize their real part here.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "incident_field = physics.incident_field\nscattered_field = physics.compute_total_field(x) - incident_field\ndinv.utils.plot(\n    [incident_field[:, :1, ...].real, scattered_field[:, :1, ...].real],\n    titles=[\"Incident field\", \"Scattered field\"],\n    figsize=(4, 2),\n)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Computing gradients through the physics operator\nThe gradient computation is fully compatible with PyTorch autograd, allowing to\neasily plug this physics operator into more complex optimization or learning-based algorithms.\n\nGradients can be computed with less memory using the adjoint-state method under the hood, requiring a single additional solver pass per\ngradient evaluation (see e.g. :cite:t:`soubies2017efficient`), and does not require storing all intermediate variables (as in standard backpropagation via PyTorch autograd).\nHere we show that the gradients computed using the adjoint-state method are consistent with those computed via standard PyTorch autograd.\n\n<div class=\"alert alert-info\"><h4>Note</h4><p>If you are using a GPU, the peak memory usage during gradient computation is also displayed for comparison.</p></div>\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "def compute_grad(x, y, physics):\n    if device != \"cpu\":\n        torch.cuda.reset_peak_memory_stats()  # Reset peak memory tracking\n\n    x_ = x.clone()\n    x_[\n        ..., img_width // 4 : 3 * img_width // 4, img_width // 4 : 3 * img_width // 4\n    ] = 0.0\n    x_ = x_.requires_grad_(True)\n    y_ = physics.A(x_)\n    error = torch.mean((y_ - y).abs() ** 2)\n    grad = torch.autograd.grad(error, x_)[0]\n\n    if device != \"cpu\":\n        print(\n            f\"Peak GPU memory usage for grad computation: \"\n            f\"{torch.cuda.max_memory_allocated() / 1e6 :.1f} MB\",\n        )\n    return x_, grad\n\n\nx_, grad = compute_grad(x, y, physics)\n# set solver to not use adjoint state\nconfig2 = dinv.physics.Scattering.SolverConfig(\n    max_iter=200, tol=1e-5, solver=\"lsqr\", adjoint_state=False\n)\nphysics.set_solver(config2)\n_, grad2 = compute_grad(x, y, physics)\n\ndinv.utils.plot(\n    [x_.real, grad, grad2],\n    titles=[\n        \"Image where grad is computed\",\n        \"Grad with adjoint state\",\n        \"Grad via Pytorch autograd\",\n    ],\n    figsize=(8, 4),\n)\n\nprint(\"Difference between gradients:\", (grad - grad2).abs().mean().item())\n\n# go back to adjoint state solver\nphysics.set_solver(config)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Reconstruction with linear (Born approximation) solver\n\nThe born (first-order) approximation consists in assuming that the scattered field is small\ncompared to the incident field, i.e., $u_i \\ll v_i$. This allows to\napproximate the Lippmann-Schwinger equation as:\n\n\\begin{align}y_i = G_s \\left(x \\circ v_i\\right)\\end{align}\n\nwhich is a linear forward model in $x$. This linear model can be inverted\nusing its linear pseudo-inverse, computed with a linear solver.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "physics.set_verbose(False)\n\nx_lin = physics.A_dagger(y, linear=True)\n\nprint(f\"PSNR of Born approximation: {psnr(x, x_lin).item():2f} dB\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Reconstruction with gradient descent\n\nThe linear Born approximation is only valid for weakly scattering objects.\nWe now perform a non-linear reconstruction using gradient descent to minimize the\nleast-squares data-fidelity term:\n\n\\begin{align}\\min_x \\frac{1}{2} \\sum_{i=1}^T \\| y_i - A_i(x) \\|_2^2\\end{align}\n\nwhere $A_i(x)$ is the non-linear forward operator for the ith transmitter, given by the Lippmann-Schwinger equation above.\n\n<div class=\"alert alert-info\"><h4>Note</h4><p>We can use a step size of 1 here since we have normalized the physics operator to have\n   a (local) Lipschitz constant of 1.</p></div>\n\n<div class=\"alert alert-info\"><h4>Note</h4><p>Here we only do 50 iterations for demonstration purposes. In practice, more iterations may be needed\n   to reach convergence.</p></div>\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "data_fid = dinv.optim.L2()\ngd_solver = dinv.optim.GD(\n    max_iter=50,\n    data_fidelity=data_fid,\n    stepsize=1,\n    custom_init=lambda y, physics: physics.A_dagger(y, linear=True),\n)\n\nx_gd = gd_solver(y, physics)\n\nprint(f\"PSNR of gradient descent reconstruction: {psnr(x, x_gd).item():.2f} dB\")\n\ndinv.utils.plot(\n    [x, x_lin, x_gd],\n    titles=[\n        \"ground truth\",\n        f\"Born approximation\\nPSNR={psnr(x, x_lin).item():.2f}dB\",\n        f\"Gradient descent\\nPSNR={psnr(x, x_gd).item():.2f}dB\",\n    ],\n    figsize=(10, 3),\n)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Understanding the trade-off between resolution and non-linearity\n\nThe background wavenumber $k_b$ (or equivalently the frequency) of the transmitted wave\nplays a key role in the scattering process. Higher wavenumbers lead to smaller waves which\ncan resolve smaller details in the object being imaged. However, higher wavenumbers also\nlead to stronger multiple scattering effects, since\nthe non-linearity of the problem is roughly proportional to $\\|x\\|_{\\infty} k_b$ (i.e., the product of the object contrast and the wavenumber).\n\nWe now compare the Born approximation reconstruction with a gradient descent reconstruction\nfor different normalized wavenumbers (i.e. different resolutions).\n\n<div class=\"alert alert-info\"><h4>Note</h4><p>This example requires a GPU to run in a reasonable time.</p></div>\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "if device != \"cpu\":\n\n    imgs = [x.detach().cpu()]\n    titles = [\"ground truth\"]\n\n    wavenumbers = [1, 5, 7]\n    for wavenumber in wavenumbers:\n        physics = dinv.physics.Scattering(\n            img_width=img_width,\n            device=device,\n            background_wavenumber=wavenumber * (2 * torch.pi),\n            transmitters=transmitters,\n            receivers=receivers,\n        )\n        physics.normalize(x)\n        y = physics(x)\n\n        x_gd = gd_solver(y, physics)\n\n        metric = psnr(x_gd, x)\n        titles = titles + [f\"wavenumber={wavenumber} \\n PSNR={metric.item():.2f}dB\"]\n        imgs = imgs + [x_gd.detach().cpu()]\n\n    dinv.utils.plot(imgs, titles=titles, figsize=(10, 3))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Going further\n\nYou can check out the following examples to go further:\n\n- Try other sensor configurations, e.g., a linear array of transmitters on one side of the object, and receivers on the opposite side.\n- Use a pretrained denoiser to perform plug-and-play reconstruction, as in `sphx_glr_auto_examples_plug-and-play_demo_vanilla_PnP.py`\n- Learn a reconstruction network using an unrolled architecture, as in `sphx_glr_auto_examples_unfolded_demo_vanilla_unfolded.py`.\n\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        ":References:\n\n.. footbibliography::\n\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.14"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}