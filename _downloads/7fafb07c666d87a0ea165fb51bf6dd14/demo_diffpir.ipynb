{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# \ud83d\ude80 To get started, install DeepInverse by creating a new cell and running `%pip install deepinv`"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n# Implementing DiffPIR\n\nIn this tutorial, we revisit the implementation of the DiffPIR diffusion algorithm for image reconstruction from :footcite:t:`zhu2023denoising`.\nThe full algorithm is implemented in :class:`deepinv.sampling.DiffPIR`.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "import numpy as np\nimport torch\nimport matplotlib.pyplot as plt\nfrom tqdm import tqdm\nimport deepinv as dinv\nfrom deepinv.utils.plotting import plot\nfrom deepinv.optim.data_fidelity import L2\nfrom deepinv.utils import load_example"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Generate an inverse problem\n\nWe first generate a deblurring problem with the butterfly image. We use a square blur kernel of size 5x5 and\nGaussian noise with standard deviation 12.75/255.0.\n\n<div class=\"alert alert-info\"><h4>Note</h4><p>We work with an image of size 64x64 to reduce the computational time of this example.\n          The algorithm works best with images of size 256x256.</p></div>\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "device = dinv.utils.get_freer_gpu() if torch.cuda.is_available() else \"cpu\"\ntorch.manual_seed(1)\n\nx_true = load_example(\"69037.png\", img_size=256, device=device)\n\nx = x_true.clone()\nmask = torch.ones_like(x)\nmask[:, :, 50:100, 50:100] = 0\nmask[:, :, 80:130, 50:100] = 0\n\nsigma_noise = 12.75 / 255.0  # noise level\nphysics = dinv.physics.Inpainting(\n    mask=mask,\n    img_size=x.shape[1:],\n    noise_model=dinv.physics.GaussianNoise(sigma=sigma_noise),\n    device=device,\n)\n\ny = physics(x)\n\nplot(\n    {\n        \"Measurement\": y,\n        \"Ground Truth\": x_true,\n    }\n)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## The DiffPIR algorithm\n\nNow that the inverse problem is defined, we can apply the DiffPIR algorithm to solve it. The DiffPIR algorithm is\na diffusion algorithm that alternates between a denoising step, a proximal step and a reverse diffusion sampling step.\nThe algorithm writes as follows, for $t$ decreasing from $T$ to $1$:\n\n\\begin{align}\\begin{equation*}\n        \\begin{aligned}\n        \\mathbf{x}_{0}^{t} &= \\denoiser{\\mathbf{x}_t}{\\sqrt{1-\\overline{\\alpha}_t}/\\sqrt{\\overline{\\alpha}_t}} \\\\\n        \\widehat{\\mathbf{x}}_{0}^{t} &= \\operatorname{prox}_{2 f(y, \\cdot) /{\\rho_t}}(\\mathbf{x}_{0}^{t}) \\\\\n        \\widehat{\\mathbf{\\varepsilon}} &= \\left(\\mathbf{x}_t - \\sqrt{\\overline{\\alpha}_t} \\,\\,\n        \\widehat{\\mathbf{x}}_{0}^t\\right)/\\sqrt{1-\\overline{\\alpha}_t} \\\\\n        \\mathbf{\\varepsilon}_t &= \\mathcal{N}(0, \\mathbf{I}) \\\\\n        \\mathbf{x}_{t-1} &= \\sqrt{\\overline{\\alpha}_t} \\,\\, \\widehat{\\mathbf{x}}_{0}^t + \\sqrt{1-\\overline{\\alpha}_t}\n        \\left(\\sqrt{1-\\zeta} \\,\\, \\widehat{\\mathbf{\\varepsilon}} + \\sqrt{\\zeta} \\,\\, \\mathbf{\\varepsilon}_t\\right),\n        \\end{aligned}\n        \\end{equation*}\\end{align}\n\nwhere $\\denoiser{\\cdot}{\\sigma}$ is a denoising network with noise level $\\sigma$,\n$\\mathcal{N}(0, \\mathbf{I})$ is a Gaussian noise\nwith zero mean and unit variance, $\\zeta$ is a parameter that controls the amount of noise added at each\niteration and $f$ refers to the data fidelity/measurement consistency term,\nwhich for Gaussian Noise (implemented as :class:`deepinv.optim.data_fidelity.L2`) is given by:\n\n\\begin{align}f(\\mathbf{y}, \\mathbf{x}) = \\frac{1}{2}\\|\\mathbf{y} - \\mathcal{A}(\\mathbf{x})\\|^2\\end{align}\n\nNote that other data fidelity terms can be used, such as :class:`deepinv.optim.PoissonLikelihood`.\nThe parameters $(\\overline{\\alpha}_t)_{0\\leq t\\leq T}$ and $(\\rho_t)_{0\\leq t\\leq T}$ are\nsequences of positive numbers, which we will detail later on.\n\nLet us now implement each step of this algorithm.\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Denoising step\n\nIn this section, we show how to use the denoising diffusion model from DiffPIR.\nThe denoising step is implemented by a denoising network conditioned on the noise power. The authors\nof DiffPIR use a U-Net architecture from :footcite:t:`ho2020denoising`,\nwhich can be loaded as follows:\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "model = dinv.models.DiffUNet(large_model=False).to(device)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Before being able to use the pretrained model, we need to define the sequence\n$(\\overline{\\alpha}_t)_{0\\leq t\\leq T}$.\nThe following function returns these sequence:\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "T = 1000  # Number of timesteps used during training\n\n\ndef get_alphas(beta_start=0.1 / 1000, beta_end=20 / 1000, num_train_timesteps=T):\n    betas = np.linspace(beta_start, beta_end, num_train_timesteps, dtype=np.float32)\n    betas = torch.from_numpy(betas).to(device)\n    alphas = 1.0 - betas\n    alphas_cumprod = np.cumprod(alphas.cpu(), axis=0)  # This is \\overline{\\alpha}_t\n    return torch.tensor(alphas_cumprod)\n\n\nalphas_cumprod = get_alphas()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Now that we have the sequence of interest, there remains to link noise power to the timestep. The following function\nreturns the timestep corresponding to a given noise power, which is given by\n\n\\begin{align}\\sigma_t = \\sqrt{1-\\overline{\\alpha}_t}/\\overline{\\alpha}_t.\\end{align}\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "sigmas = torch.sqrt(1.0 - alphas_cumprod) / alphas_cumprod.sqrt()\n\n\ndef find_nearest(array, value):\n    array = np.asarray(array)\n    idx = (np.abs(array - value)).argmin()\n    return idx\n\n\nt = 100  # choose arbitrary timestep\n\n# We can now apply the model to a noisy image. We first generate a noisy image\nx_noisy = x_true + torch.randn_like(x_true) * sigmas[t]\n\nden = model(x_noisy, sigmas[t])\n\nplot(\n    {\n        \"Noisy Input\": x_noisy,\n        \"Denoised Image\": den,\n        \"Error\": den - x_true,\n    }\n)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Data fidelity step\n\nThe data fidelity step is easily implemented in this library. We simply need to define a data fidelity function and use\nits prox attribute. For instance:\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "data_fidelity = L2()\n\n# In order to take a meaningful data fidelity step, it is best if we apply it to denoised measurements.\n# First, denoise the measurements. To do so, we need to estimate the timestep associated with the noise level of the\n# measurements. This is done as follows:\nt_temp = find_nearest(sigmas.cpu().numpy(), sigma_noise * 2)\ny_denoised = model(y, sigmas[t_temp] / 2.0)\n\n# Next, apply the proximity operator of the data fidelity term (this is the data fidelity step). In the algorithm,\n# the regularization parameter is carefully chosen. Here, for simplicity, we set it to :math:`1/\\sigma`.\nx_prox = data_fidelity.prox(y_denoised, y, physics, gamma=(1 / sigmas[t]).to(device))\n\nplot(\n    {\n        \"Measurement\": y,\n        \"Denoised Measurement\": y_denoised,\n        \"Data Fidelity Step\": x_prox,\n    },\n    tight=False,\n)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Sampling step\n\nThe last step to be implemented is the DiffPIR sampling step and this can be computed in two steps.\nFirstly, we need to compute the effective noise in the estimated reconstruction,\ni.e. the residual between the previous\nreconstruction and the data fidelity step. This is done as follows:\n\n<div class=\"alert alert-info\"><h4>Note</h4><p>The diffPIR algorithm assumes that the images are in the range [-1, 1], whereas standard denoisers\n          usually output images in the range [0, 1]. This is why we rescale the images before applying the steps.</p></div>\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "x_prox_scaled = 2 * x_prox - 1  # Rescale the output of the proximal step in [-1, 1]\ny_scaled = 2 * y - 1  # Rescale the measurement in [-1, 1]\n\nt_i = find_nearest(\n    sigmas.cpu().numpy(), sigma_noise * 2\n)  # time step associated with the noise level sigma\neps = (y_scaled - alphas_cumprod[t_i].sqrt() * x_prox_scaled) / torch.sqrt(\n    1.0 - alphas_cumprod[t_i]\n)  # effective noise\n\n# (notice the rescaling)\n#"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Secondly, we need to perform the sampling step, which is a linear combination between the estimated noise and\nthe realizations of a Gaussian white noise. This is done as follows:\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "zeta = 0.3\nx_sampled_scaled = alphas_cumprod[t_i - 1].sqrt() * x_prox_scaled + torch.sqrt(\n    1.0 - alphas_cumprod[t_i - 1]\n) * (np.sqrt(1 - zeta) * eps + np.sqrt(zeta) * torch.randn_like(x))\n\nx_sampled = (x_sampled_scaled + 1) / 2  # Rescale the output in [0, 1]\n\nimgs = {\n    \"Measurement\": y,\n    \"Denoised Measurement\": y_denoised,\n    \"Data Fidelity Step\": x_prox,\n    \"Sampling Step\": x_sampled,\n}\nplot(imgs, tight=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "(notice that noise has been added everywhere in the image, including in the masked region)\n\n## Setting the noise and regularization schedules\n\nThe only remaining step is to set the noise schedule (i.e. the sequence of noise powers and regularization parameters)\nappropriately. This is done with the following function:\n\n<div class=\"alert alert-info\"><h4>Note</h4><p>We only use 30 steps to reduce the computational time of this example. As suggested by the authors of DiffPIR, the\n  algorithm works best with ``diffusion_steps = 100``.</p></div>\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "max_iter = 30  # maximum number of iterations of the DiffPIR algorithm\n\n# Useful sequences for the algorithm\nsqrt_1m_alphas_cumprod = torch.sqrt(1.0 - alphas_cumprod)\nsqrt_alphas_cumprod = torch.sqrt(alphas_cumprod)\nreduced_alpha_cumprod = torch.div(\n    sqrt_1m_alphas_cumprod, sqrt_alphas_cumprod\n)  # equivalent noise sigma on image\nsqrt_recip_alphas_cumprod = torch.sqrt(1.0 / alphas_cumprod)\n\n\n# noise schedule of the algorithm\ndef get_noise_schedule(sigma, lambda_=7.0, num_train_timesteps=1000, max_iter=max_iter):\n    sigmas = []\n    sigma_ks = []\n    rhos = []\n    for i in range(num_train_timesteps):\n        sigmas.append(reduced_alpha_cumprod[num_train_timesteps - 1 - i])\n        sigma_ks.append((sqrt_1m_alphas_cumprod[i] / sqrt_alphas_cumprod[i]))\n        rhos.append(lambda_ * (sigma**2) / (sigma_ks[i] ** 2))\n    rhos, sigmas = torch.tensor(rhos).to(device), torch.tensor(sigmas).to(device)\n\n    seq = np.sqrt(np.linspace(0, num_train_timesteps**2, max_iter))\n    seq = [int(s) for s in list(seq)]\n    seq[-1] = seq[-1] - 1\n\n    return rhos, sigmas, seq\n\n\nrhos, sigmas, seq = get_noise_schedule(sigma_noise)\n\n# Plot the noise and regularization schedules\nplt.figure(figsize=(6, 3))\nplt.rcParams.update({\"font.size\": 9})\nplt.subplot(121)\nplt.plot(\n    2 / rhos.cpu().numpy()[::-1]\n)  # Note that the regularization parameter is 2/rho and not rho\nplt.xlabel(r\"$t$\")\nplt.ylabel(r\"$\\rho$\")\nplt.subplot(122)\nplt.plot(sigmas.cpu().numpy()[::-1])\nplt.xlabel(r\"$t$\")\nplt.ylabel(r\"$\\sigma$\")\nplt.suptitle(\"Regularisation parameter and noise schedules (fully sampled)\")\nplt.tight_layout()\nplt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "In the algorithm, we will only use sub-sampled versions of the noise and regularization schedules. Let's visualize\nthose.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "list_sigmas_algo = [sigmas[seq[i]].cpu().item() for i in range(max_iter)]\nlist_rhos_algo = [rhos[seq[i]].cpu().item() for i in range(max_iter)]\n\nplt.figure(figsize=(6, 3))\nplt.subplot(121)\nplt.plot(\n    2 / torch.tensor(list_rhos_algo).cpu().numpy()\n)  # Note that the regularization parameter is 2/rho and not rho\nplt.xlabel(r\"$t$\")\nplt.ylabel(r\"$\\rho$\")\nplt.subplot(122)\nplt.plot(list_sigmas_algo)\nplt.xlabel(r\"$t$\")\nplt.ylabel(r\"$\\sigma$\")\nplt.suptitle(f\"Regularisation parameter and noise schedules (for {max_iter} steps)\")\nplt.tight_layout()\nplt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Putting it all together: the DiffPIR algorithm\n\nWe can now put all the steps together and implement the DiffPIR algorithm! First, we initialize the algorithm, and\nthen we iterate over the different steps detailed above.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# Initialization\nx = 2 * physics.A_adjoint(y) - 1  # Rescale\nx = (\n    x + (sigmas[seq[0]] ** 2 - 4 * sigma_noise**2).sqrt() * torch.randn_like(x)\n) / sqrt_recip_alphas_cumprod[\n    -1\n]  # Add noise (simpler than the original code, may be suboptimal)\n\n# Images to save for visualization\nlist_denoised, list_prox, list_noisy = [], [], []\nsave_steps = [0, 1, 2, 5, 10, 20, 29]\n\nwith torch.no_grad():\n    for i in tqdm(range(len(seq))):\n\n        sigma_cur = sigmas[seq[i]]\n\n        # time step associated with the noise level sigmas[i]\n        t_i = find_nearest(reduced_alpha_cumprod, sigma_cur.cpu().numpy())\n        at = 1 / sqrt_recip_alphas_cumprod[t_i] ** 2\n\n        # Denoising step\n        x_aux = x / (2 * at.sqrt()) + 0.5  # renormalize in [0, 1]\n        out = model(x_aux, sigma_cur / 2)\n        denoised = 2 * out - 1  # back to [-1, 1]\n        x0 = denoised.clamp(-1, 1)  # optional\n\n        if not seq[i] == seq[-1]:\n            # 2. Data fidelity step\n            x0 = data_fidelity.prox(x0, y, physics, gamma=1 / (2 * rhos[t_i]))\n\n            # 3. Sampling step\n            next_sigma = sigmas[T - 1 - seq[i + 1]].cpu().numpy()\n            t_im1 = find_nearest(\n                sigmas.cpu().numpy(), next_sigma\n            )  # time step associated with the next noise level\n\n            eps = (x - alphas_cumprod[t_i].sqrt() * x0) / torch.sqrt(\n                1.0 - alphas_cumprod[t_i]\n            )  # effective noise\n\n            x = alphas_cumprod[t_im1].sqrt() * x0 + torch.sqrt(\n                1.0 - alphas_cumprod[t_im1]\n            ) * (np.sqrt(1 - zeta) * eps + np.sqrt(zeta) * torch.randn_like(x))\n\n        if i in save_steps:\n            list_noisy.append(x_aux)\n            list_denoised.append(denoised)\n            list_prox.append(x0)\n\n# Renormalize in [0, 1]\nx = (x + 1) / 2\n\n# Plotting the results\nplot(\n    {\n        \"Measurement\": y,\n        \"Model Output\": x,\n        \"Ground Truth\": x_true,\n    }\n)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Let's visualize the sample, its denoised version and the proximal steps at different iterations.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# sphinx_gallery_thumbnail_number = 9\n# sphinx_gallery_multi_image = \"single\"\nplot(\n    list_noisy,\n    titles=[f\"Noisy Sample Step {i}\" for i in save_steps],\n    dpi=1500,\n    tight=False,\n)\n\nplot(\n    list_denoised,\n    titles=[f\"Denoised Step {i}\" for i in save_steps],\n    dpi=1500,\n)\n\nplot(\n    list_prox,\n    titles=[f\"Proximal Step {i}\" for i in save_steps],\n    dpi=1500,\n)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Using the DiffPIR algorithm in your inverse problem\nYou can readily use this algorithm via the :class:`deepinv.sampling.DiffPIR` class.\n\n::\n\n      y = physics(x)\n      model = dinv.sampling.DiffPIR(dinv.models.DiffUNet(), data_fidelity=dinv.optim.data_fidelity.L2())\n      xhat = model(y, physics)\n\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        ":References:\n\n.. footbibliography::\n\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}