{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# \ud83d\ude80 To get started, install DeepInverse by creating a new cell and running `%pip install deepinv`"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n# Blind denoising with noise level estimation\n\nThis example focuses on blind image Gaussian denoising, i.e. the problem\n\n\\begin{align}y = x + \\sigma n \\quad n \\sim \\mathcal{N}(0, I)\\end{align}\n\nwhere $\\sigma$ is unknown. In this example, we first propose to estimate the noise level with different approaches,\nand then show general restoration models available in the library.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "import torch\nimport deepinv as dinv\n\ndevice = dinv.utils.get_freer_gpu() if torch.cuda.is_available() else \"cpu\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Build a noisy image\n\nWe load a noiseless image and generate a noisy (Gaussian) version of this image, with standard deviation that we will\nassume to be unknown. We set it to $\\sigma = 0.042$ for this example.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "x = dinv.utils.load_example(\"butterfly.png\", device=device)\n\nsigma_true = 0.042\n\ny = x + sigma_true * torch.randn_like(x)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## A naive approach\n\nA first naive approach to estimate $\\sigma$ consists in taking a patch of the image, removing the mean, and using\nthe standard deviation of the resulting patch as an estimate of the noise level.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "p = 50\ny_patch = y[:, :, -p:, p - p // 2 : p + p // 2]  # extract a patch\nstd_naive = y_patch.std()\n\nprint(\"Naive noise level estimate: \", std_naive.item())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Noise level estimators\n\nA more advanced approach consists in performing the same approach as above, but in an appropriate domain.\nA good transform is the wavelet transform, where we can expect the noise to dominate high-frequency components.\nWe can illustrate this as follows:\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "import ptwt\nimport pywt\n\ncoeffs = ptwt.wavedec2(y, pywt.Wavelet(\"db8\"), mode=\"constant\", level=1, axes=(-2, -1))\n\nimgs = [coeffs[0], coeffs[1][0], coeffs[1][1], coeffs[1][2]]\ntitles = [\"LF\", \"HF (horizontal)\", \"HF (vertical)\", \"HF (diagonal)\"]\n\ndinv.utils.plot_inset(\n    img_list=imgs,\n    titles=titles,\n    suptitle=\"Wavelet decomposition of noisy image\",\n    extract_size=0.2,\n    extract_loc=(0.7, 0.7),\n    inset_size=0.5,\n    figsize=(len(imgs) * 1.5, 2.5),\n    fontsize=8,\n)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We notice that the high-frequency components are mostly noise.\nWe can thus use these components to estimate the noise level more robustly.\nThis is implemented in :class:`deepinv.models.WaveletNoiseEstimator`. Under the hood, the estimator uses the\nMedian Absolute Deviation (MAD) estimator on the wavelet high-frequency coefficients:\n\n\\begin{align}\\qquad \\hat{\\sigma} = \\frac{\\mathrm{median}(|w|)}{0.6745},\\end{align}\n\nwhere $w$ are the high-frequency wavelet coefficients.\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "wavelet_estimator = dinv.models.WaveletNoiseEstimator()\nsigma_wavelet = wavelet_estimator(y)\nprint(\"Wavelet-based noise level estimate: \", sigma_wavelet.item())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We notice that this approach provides a signficantly better estimate of the noise level compared to the naive approach.\nHowever, it tends to slightly over-estimate the noise level in this example. As noted in the original paper, this\nis due to the presence of residual signal in the high-frequency wavelet coefficients (these are not only noise).\n\nAnother approach is to use the eigenvalues of the covariance matrix of patches extracted from the noisy\nimage. This is implemented in :class:`deepinv.models.PatchCovarianceNoiseEstimator`.\nThe method was initially proposed in :footcite:t:`chen2015efficient`.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "patch_cov_estimator = dinv.models.PatchCovarianceNoiseEstimator()\nsigma_patch_cov = patch_cov_estimator(y)\nprint(\"Patch covariance-based noise level estimate: \", sigma_patch_cov.item())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Blind denoising with estimated noise level\n\nOnce we have estimated the noise level, we can use general denoising models available in the library.\nHere, we use the pretrained DRUNet model from :footcite:t:`zhang2021plug` that can handle a range of noise levels.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "denoiser = dinv.models.DRUNet(device=device)\n\nwith torch.no_grad():\n    denoised_naive = denoiser(y, sigma=std_naive)\n    denoised_wavelet = denoiser(y, sigma=sigma_wavelet)\n    denoised_patch_cov = denoiser(y, sigma=sigma_patch_cov)\n\n\nmetric = dinv.metric.PSNR()\n\npsnr_noisy = metric(y, x).item()\npsnr_naive = metric(denoised_naive, x).item()\npsnr_wavelet = metric(denoised_wavelet, x).item()\npsnr_patch_cov = metric(denoised_patch_cov, x).item()\n\ndinv.utils.plot(\n    {\n        f\"Noisy\\n PSNR: {psnr_noisy:.2f} dB\": y,\n        f\"Denoised (naive)\\n PSNR: {psnr_naive:.2f} dB\": denoised_naive,\n        f\"Denoised (wavelet)\\n PSNR: {psnr_wavelet:.2f} dB\": denoised_wavelet,\n        f\"Denoised (patch cov.)\\n PSNR: {psnr_patch_cov:.2f} dB\": denoised_patch_cov,\n    },\n    fontsize=9,\n)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Which noise level estimator is best?\n\nThis will depend on several parameters, e.g. image size, content and noise level.\nAbove, the patch covariance estimator provides the best results. We can investigate the performance on the above image\nfor different noise levels as follows:\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "list_sigmas = torch.logspace(-2, 0, steps=10)\n\nestimate_errors = {\n    \"wavelet mean\": [],\n    \"wavelet std\": [],\n    \"patch_cov mean\": [],\n    \"patch_cov std\": [],\n}\n\nmean_abs_error = dinv.metric.MAE(reduction=\"mean\")\n\n# run estimations for different noise levels, and average over 10 random seeds\nfor sigma in list_sigmas:\n\n    sigma_wavelet, sigma_patch_cov = [], []\n\n    for seed in range(10):\n        torch.manual_seed(seed)\n        y_ = x + sigma * torch.randn_like(x)\n\n        sigma_wavelet.append(wavelet_estimator(y_))\n        sigma_patch_cov.append(patch_cov_estimator(y_))\n\n    sigma_wavelet = torch.stack(sigma_wavelet)\n    sigma_patch_cov = torch.stack(sigma_patch_cov)\n\n    estimate_errors[\"wavelet mean\"].append(mean_abs_error(sigma_wavelet, sigma).item())\n    estimate_errors[\"wavelet std\"].append(sigma_wavelet.std().item())\n    estimate_errors[\"patch_cov mean\"].append(\n        (sigma_patch_cov - sigma).abs().mean().item()\n    )\n    estimate_errors[\"patch_cov std\"].append(sigma_patch_cov.std().item())\n\n# plot results\nimport matplotlib.pyplot as plt\n\nplt.figure()\nplt.errorbar(\n    list_sigmas.cpu(),\n    estimate_errors[\"wavelet mean\"],\n    yerr=estimate_errors[\"wavelet std\"],\n    label=\"Wavelet-based estimator\",\n    fmt=\"-o\",\n)\nplt.errorbar(\n    list_sigmas.cpu(),\n    estimate_errors[\"patch_cov mean\"],\n    yerr=estimate_errors[\"patch_cov std\"],\n    label=\"Patch covariance-based estimator\",\n    fmt=\"-o\",\n)\nplt.xscale(\"log\")\nplt.xlabel(\"True noise level sigma\")\nplt.ylabel(\"Absolute estimation error\")\nplt.title(\"Noise level estimation error vs true noise level\")\nplt.legend()\nplt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Blind denoising models\n\nFinally, we can also use blind denoising models that are trained to denoise images without knowing the noise level.\nFor instance, we can use the Restormer model from :footcite:t:`zamir2022restormer`. We note that this model provides\nbetter results than the non-blind denoiser with estimated noise level.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "blind_restormer = dinv.models.Restormer(device=device)\n\nwith torch.no_grad():\n    denoised_restormer = blind_restormer(y)\n\npsnr_restormer = metric(denoised_restormer, x).item()\n\ndinv.utils.plot(\n    {\n        \"Noisy\": y,\n        f\"Denoised (blind Restormer)\\n PSNR: {psnr_restormer:.2f} dB\": denoised_restormer,\n    },\n    fontsize=9,\n)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        ":References:\n\n.. footbibliography::\n\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.14"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}