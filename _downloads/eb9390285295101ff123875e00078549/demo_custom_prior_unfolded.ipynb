{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# \ud83d\ude80 To get started, install DeepInverse by creating a new cell and running `%pip install deepinv`"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n# Learned iterative custom prior\n\nThis example shows how to implement a learned unrolled proximal gradient descent algorithm with a custom prior function.\nThe algorithm is trained on a dataset of compressed sensing measurements of MNIST images.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "from pathlib import Path\nimport torch\nfrom torchvision import datasets\nfrom torchvision import transforms\nimport deepinv as dinv\nfrom torch.utils.data import DataLoader\nfrom deepinv.optim.data_fidelity import L2\nfrom deepinv.optim.prior import Prior\nfrom deepinv.unfolded import unfolded_builder\nfrom deepinv.utils import get_data_home"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Setup paths for data loading and results.\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "BASE_DIR = Path(\".\")\nDATA_DIR = BASE_DIR / \"measurements\"\nRESULTS_DIR = BASE_DIR / \"results\"\nCKPT_DIR = BASE_DIR / \"ckpts\"\nORIGINAL_DATA_DIR = get_data_home()\n\n# Set the global random seed from pytorch to ensure reproducibility of the example.\ntorch.manual_seed(0)\n\ndevice = dinv.utils.get_freer_gpu() if torch.cuda.is_available() else \"cpu\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Load base image datasets and degradation operators.\nIn this example, we use MNIST as the base dataset.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "img_size = 28\nn_channels = 1\noperation = \"compressed-sensing\"\ntrain_dataset_name = \"MNIST_train\"\n\n# Generate training and evaluation datasets in HDF5 folders and load them.\ntrain_test_transform = transforms.Compose([transforms.ToTensor()])\ntrain_base_dataset = datasets.MNIST(\n    root=ORIGINAL_DATA_DIR, train=True, transform=train_test_transform, download=True\n)\ntest_base_dataset = datasets.MNIST(\n    root=ORIGINAL_DATA_DIR, train=False, transform=train_test_transform, download=True\n)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Generate a dataset of compressed measurements and load it.\nWe use the compressed sensing class from the physics module to generate a dataset of highly-compressed measurements\n(10% of the total number of pixels).\n\nThe forward operator is defined as $y = Ax$\nwhere $A$ is a (normalized) random Gaussian matrix.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# Use parallel dataloader if using a GPU to speed up training, otherwise, as all computes are on CPU, use synchronous\n# data loading.\nnum_workers = 4 if torch.cuda.is_available() else 0\n\n# Generate the compressed sensing measurement operator with 10x under-sampling factor.\nphysics = dinv.physics.CompressedSensing(\n    m=78, img_size=(n_channels, img_size, img_size), fast=True, device=device\n)\nmy_dataset_name = \"demo_LICP\"\nn_images_max = (\n    1000 if torch.cuda.is_available() else 200\n)  # maximal number of images used for training\nmeasurement_dir = DATA_DIR / train_dataset_name / operation\ngenerated_datasets_path = dinv.datasets.generate_dataset(\n    train_dataset=train_base_dataset,\n    test_dataset=test_base_dataset,\n    physics=physics,\n    device=device,\n    save_dir=measurement_dir,\n    train_datapoints=n_images_max,\n    test_datapoints=8,\n    num_workers=num_workers,\n    dataset_filename=str(my_dataset_name),\n)\n\ntrain_dataset = dinv.datasets.HDF5Dataset(path=generated_datasets_path, train=True)\ntest_dataset = dinv.datasets.HDF5Dataset(path=generated_datasets_path, train=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Define the unfolded Proximal Gradient algorithm.\nIn this example, we propose to minimize a function of the form\n\n\\begin{align}\\min_x \\frac{1}{2} \\|y - Ax\\|_2^2 + \\lambda\\operatorname{TV}_{\\text{smooth}}(x)\\end{align}\n\nwhere $\\operatorname{TV}_{\\text{smooth}}$ is a smooth approximation of TV.\nThe proximal gradient iteration (see also :class:`deepinv.optim.optim_iterators.PGDIteration`) is defined as\n\n  .. math::\n          x_{k+1} = \\text{prox}_{\\gamma \\lambda \\operatorname{TV}_{\\text{smooth}}}(x_k - \\gamma A^T (Ax_k - y))\n\nwhere $\\gamma$ is the stepsize and $\\text{prox}_{g}$ is the proximity operator of $g(x) =\\operatorname{TV}_{\\text{smooth}}(x)$.\n\nWe first define the prior in a functional form.\nIf the prior is initialized with a list of length max_iter,\nthen a distinct weight is trained for each PGD iteration.\nFor fixed trained model prior across iterations, initialize with a single model.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# Define the image gradient operator\ndef nabla(I):\n    b, c, h, w = I.shape\n    G = torch.zeros((b, c, h, w, 2), device=I.device).type(I.dtype)\n    G[:, :, :-1, :, 0] = G[:, :, :-1, :, 0] - I[:, :, :-1]\n    G[:, :, :-1, :, 0] = G[:, :, :-1, :, 0] + I[:, :, 1:]\n    G[:, :, :, :-1, 1] = G[:, :, :, :-1, 1] - I[..., :-1]\n    G[:, :, :, :-1, 1] = G[:, :, :, :-1, 1] + I[..., 1:]\n    return G\n\n\n# Define the smooth TV prior as the mse of the image finite difference.\ndef g(x, *args, **kwargs):\n    dx = nabla(x)\n    tv_smooth = torch.nn.functional.mse_loss(\n        dx, torch.zeros_like(dx), reduction=\"sum\"\n    ).sqrt()\n    return tv_smooth\n\n\n# Define the prior. A prior instance from :class:`deepinv.priors` can be simply defined with an explicit potential :math:`g` function as such:\nprior = Prior(g=g)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We use :func:`deepinv.unfolded.unfolded_builder` to define the unfolded algorithm\nand set both the stepsizes of the PGD algorithm $\\gamma$ (``stepsize``) and the soft\nthresholding parameters $\\lambda$ as learnable parameters.\nThese parameters are initialized with a table of length max_iter,\nyielding a distinct ``stepsize`` and ``g_param`` value for each iteration of the algorithm.\nFor single ``stepsize`` and ``g_param`` shared across iterations, initialize with a single float value.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# Unrolled optimization algorithm parameters\nmax_iter = 5  # Number of unrolled iterations\nlamb = [\n    1.0\n] * max_iter  # initialization of the regularization parameter. A distinct lamb is trained for each iteration.\nstepsize = [\n    1.0\n] * max_iter  # initialization of the stepsizes. A distinct stepsize is trained for each iteration.\nparams_algo = {  # wrap all the restoration parameters in a 'params_algo' dictionary\n    \"stepsize\": stepsize,\n    \"lambda\": lamb,\n}\ntrainable_params = [\n    \"stepsize\",\n    \"lambda\",\n]  # define which parameters from 'params_algo' are trainable\n\n# Select the data fidelity term\ndata_fidelity = L2()\n\n# Logging parameters\nverbose = True\n\n# Define the unfolded trainable model.\nmodel = unfolded_builder(\n    iteration=\"PGD\",\n    params_algo=params_algo.copy(),\n    trainable_params=trainable_params,\n    data_fidelity=data_fidelity,\n    max_iter=max_iter,\n    prior=prior,\n    g_first=True,\n)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Define the training parameters.\nWe now define training-related parameters,\nnumber of epochs, optimizer (Adam) and its hyperparameters, and the train and test batch sizes.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# Training parameters\nepochs = 20 if torch.cuda.is_available() else 10\nlearning_rate = 5e-3  # reduce this parameter when using more epochs\n\n# Choose optimizer and scheduler\noptimizer = torch.optim.Adam(model.parameters(), lr=learning_rate, weight_decay=0.0)\n\n# Choose supervised training loss\nlosses = [dinv.loss.SupLoss(metric=torch.nn.L1Loss())]\n\n# Batch sizes and data loaders\ntrain_batch_size = 64 if torch.cuda.is_available() else 8\ntest_batch_size = 64 if torch.cuda.is_available() else 8\n\ntrain_dataloader = DataLoader(\n    train_dataset, batch_size=train_batch_size, num_workers=num_workers, shuffle=True\n)\ntest_dataloader = DataLoader(\n    test_dataset, batch_size=test_batch_size, num_workers=num_workers, shuffle=False\n)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Train the network.\nWe train the network using the library's train function.\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "trainer = dinv.Trainer(\n    model,\n    physics=physics,\n    train_dataloader=train_dataloader,\n    eval_dataloader=test_dataloader,\n    epochs=epochs,\n    device=device,\n    losses=losses,\n    optimizer=optimizer,\n    save_path=str(CKPT_DIR / operation),\n    verbose=verbose,\n    show_progress_bar=False,  # disable progress bar for better vis in sphinx gallery.\n)\n\n\nmodel = trainer.train()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Test the network.\n\nWe now test the learned unrolled network on the test dataset. In the plotted results, the `Linear` column shows the\nmeasurements back-projected in the image domain, the `Recons` column shows the output of our LISTA network,\nand `GT` shows the ground truth.\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "trainer.test(test_dataloader)\n\ntest_sample, _ = next(iter(test_dataloader))\nmodel.eval()\ntest_sample = test_sample.to(device)\n\n# Get the measurements and the ground truth\ny = physics(test_sample)\nwith torch.no_grad():\n    rec = model(y, physics=physics)\n\nbackprojected = physics.A_adjoint(y)\n\ndinv.utils.plot(\n    [backprojected, rec, test_sample],\n    titles=[\"Linear\", \"Reconstruction\", \"Ground truth\"],\n    suptitle=\"Reconstruction results\",\n)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Plotting the weights of the network.\n\nWe now plot the weights of the network that were learned and check that they are different from their initialization\nvalues. Note that ``g_param`` corresponds to $\\lambda$ in the proximal gradient algorithm.\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "dinv.utils.plotting.plot_parameters(\n    model, init_params=params_algo, save_dir=RESULTS_DIR / \"unfolded_pgd\" / operation\n)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}