{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# \ud83d\ude80 To get started, install DeepInverse by creating a new cell and running `%pip install deepinv`"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n# Implementing DPS\n\nIn this tutorial, we will go over the steps in the Diffusion Posterior Sampling (DPS) algorithm introduced in\n:footcite:t:`chung2022diffusion`. The full algorithm is implemented in :class:`deepinv.sampling.DPS`.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Installing dependencies\nLet us ``import`` the relevant packages, and load a sample\nimage of size 64 x 64. This will be used as our ground truth image.\n\n<div class=\"alert alert-info\"><h4>Note</h4><p>We work with an image of size 64 x 64 to reduce the computational time of this example.\n          The DiffUNet we use in the algorithm works best with images of size 256 x 256.</p></div>\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "import torch\n\nimport deepinv as dinv\nfrom deepinv.utils.plotting import plot\nfrom deepinv.optim.data_fidelity import L2\nfrom deepinv.utils import load_example\nfrom tqdm import tqdm  # to visualize progress\n\ndevice = dinv.utils.get_freer_gpu() if torch.cuda.is_available() else \"cpu\"\n\nx_true = load_example(\"butterfly.png\", img_size=64).to(device)\nx = x_true.clone()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "In this tutorial we consider random inpainting as the inverse problem, where the forward operator is implemented\nin :class:`deepinv.physics.Inpainting`. In the example that we use, 90% of the pixels will be masked out randomly,\nand we will additionally have Additive White Gaussian Noise (AWGN) of standard deviation  12.75/255.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "sigma = 12.75 / 255.0  # noise level\n\nphysics = dinv.physics.Inpainting(\n    img_size=(3, x.shape[-2], x.shape[-1]),\n    mask=0.1,\n    pixelwise=True,\n    device=device,\n)\n\ny = physics(x_true)\n\nplot(\n    {\n        \"Measurement\": y,\n        \"Ground Truth\": x_true,\n    }\n)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Diffusion model loading\n\nWe will take a pre-trained diffusion model that was also used for the DiffPIR algorithm, namely the one trained on\nthe FFHQ 256x256 dataset. Note that this means that the diffusion model was trained with human face images,\nwhich is very different from the image that we consider in our example. Nevertheless, we will see later on that\n``DPS`` generalizes sufficiently well even in such case.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "model = dinv.models.DiffUNet(large_model=False).to(device)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Define diffusion schedule\n\nWe will use the standard linear diffusion noise schedule. Once $\\beta_t$ is defined to follow a linear schedule\nthat interpolates between $\\beta_{\\rm min}$ and $\\beta_{\\rm max}$,\nwe have the following additional definitions:\n$\\alpha_t := 1 - \\beta_t$, $\\bar\\alpha_t := \\prod_{j=1}^t \\alpha_j$.\nThe following equations will also be useful\nlater on (we always assume that $\\mathbf{\\epsilon} \\sim \\mathcal{N}(\\mathbf{0}, \\mathbf{I})$ hereafter.)\n\n\\begin{align}\\mathbf{x}_t = \\sqrt{1 - \\beta_t}\\mathbf{x}_{t-1} + \\sqrt{\\beta_t}\\mathbf{\\epsilon}\n\n          \\mathbf{x}_t = \\sqrt{\\bar\\alpha_t}\\mathbf{x}_0 + \\sqrt{1 - \\bar\\alpha_t}\\mathbf{\\epsilon}\\end{align}\n\nwhere we use the reparametrization trick.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "num_train_timesteps = 1000  # Number of timesteps used during training\n\n\nbetas = torch.linspace(1e-4, 2e-2, num_train_timesteps).to(device)\nalphas = (1 - betas).cumprod(dim=0)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## The DPS algorithm\n\nNow that the inverse problem is defined, we can apply the DPS algorithm to solve it. The DPS algorithm is\na diffusion algorithm that alternates between a denoising step, a gradient step and a reverse diffusion sampling step.\nThe algorithm writes as follows, for $t$ decreasing from $T$ to $1$:\n\n\\begin{align}\\begin{equation*}\n        \\begin{aligned}\n        \\widehat{\\mathbf{x}}_{0} (\\mathbf{x}_t) &= \\denoiser{\\mathbf{x}_t}{\\sqrt{1-\\overline{\\alpha}_t}/\\sqrt{\\overline{\\alpha}_t}}\n        \\\\\n        \\mathbf{g}_t &= \\nabla_{\\mathbf{x}_t} \\log p( \\widehat{\\mathbf{x}}_{0}(\\mathbf{x}_t) | \\mathbf{y} ) \\\\\n        \\mathbf{\\varepsilon}_t &= \\mathcal{N}(0, \\mathbf{I}) \\\\\n        \\mathbf{x}_{t-1} &= a_t \\,\\, \\mathbf{x}_t\n        + b_t \\, \\, \\widehat{\\mathbf{x}}_0\n        + \\tilde{\\sigma}_t \\, \\, \\mathbf{\\varepsilon}_t + \\mathbf{g}_t,\n        \\end{aligned}\n        \\end{equation*}\\end{align}\n\nwhere $\\denoiser{\\cdot}{\\sigma}$ is a denoising network for noise level $\\sigma$,\n$\\eta$ is a hyperparameter in [0, 1], and the constants $\\tilde{\\sigma}_t, a_t, b_t$ are defined as\n\n\\begin{align}\\begin{equation*}\n        \\begin{aligned}\n          \\tilde{\\sigma}_t &= \\eta \\sqrt{ (1 - \\frac{\\overline{\\alpha}_t}{\\overline{\\alpha}_{t-1}})\n          \\frac{1 - \\overline{\\alpha}_{t-1}}{1 - \\overline{\\alpha}_t}} \\\\\n          a_t &= \\sqrt{1 - \\overline{\\alpha}_{t-1} - \\tilde{\\sigma}_t^2}/\\sqrt{1-\\overline{\\alpha}_t} \\\\\n          b_t &= \\sqrt{\\overline{\\alpha}_{t-1}} - \\sqrt{1 - \\overline{\\alpha}_{t-1} - \\tilde{\\sigma}_t^2}\n          \\frac{\\sqrt{\\overline{\\alpha}_{t}}}{\\sqrt{1 - \\overline{\\alpha}_{t}}}\n        \\end{aligned}\n        \\end{equation*}\\end{align}\n\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Denoising step\n\nThe first step of DPS consists of applying a denoiser function to the current image $\\mathbf{x}_t$,\nwith standard deviation $\\sigma_t = \\sqrt{1 - \\overline{\\alpha}_t}/\\sqrt{\\overline{\\alpha}_t}$.\n\nThis is equivalent to sampling $\\mathbf{x}_t \\sim q(\\mathbf{x}_t|\\mathbf{x}_0)$, and then computing the\nposterior mean.\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "t = 200  # choose some arbitrary timestep\nat = alphas[t]\nsigmat = (1 - at).sqrt() / at.sqrt()\n\nx0 = x_true\nxt = x0 + sigmat * torch.randn_like(x0)\n\n# apply denoiser\nx0_t = model(xt, sigmat)\n\n# Visualize\nplot(\n    {\n        \"Ground Truth\": x0,\n        \"Noisy\": xt,\n        \"Posterior Mean\": x0_t,\n    }\n)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## DPS approximation\n\nIn order to perform gradient-based **posterior sampling** with diffusion models, we have to be able to compute\n$\\nabla_{\\mathbf{x}_t} \\log p(\\mathbf{x}_t|\\mathbf{y})$. Applying Bayes rule, we have\n\n\\begin{align}\\nabla_{\\mathbf{x}_t} \\log p(\\mathbf{x}_t|\\mathbf{y}) = \\nabla_{\\mathbf{x}_t} \\log p(\\mathbf{x}_t)\n          + \\nabla_{\\mathbf{x}_t} \\log p(\\mathbf{y}|\\mathbf{x}_t)\\end{align}\n\nFor the former term, we can simply plug-in our estimated score function as in Tweedie's formula. As the latter term\nis intractable, DPS proposes the following approximation (for details, see Theorem 1 of :footcite:t:`chung2022diffusion`)\n\n\\begin{align}\\nabla_{\\mathbf{x}_t} \\log p(\\mathbf{x}_t|\\mathbf{y}) \\approx \\nabla_{\\mathbf{x}_t} \\log p(\\mathbf{x}_t)\n          + \\nabla_{\\mathbf{x}_t} \\log p(\\mathbf{y}|\\widehat{\\mathbf{x}}_{0}(\\mathbf{x_t}))\\end{align}\n\nRemarkably, we can now compute the latter term when we have Gaussian noise, as\n\n\\begin{align}\\log p(\\mathbf{y}|\\widehat{\\mathbf{x}}_0(\\mathbf{x_t})) =\n      -\\frac{\\|\\mathbf{y} - A\\widehat{\\mathbf{x}}_0((\\mathbf{x_t})\\|_2^2}{2\\sigma_y^2}.\\end{align}\n\nMoreover, taking the gradient w.r.t. $\\mathbf{x}_t$ can be performed through automatic differentiation.\nLet's see how this can be done in PyTorch. Note that when we are taking the gradient w.r.t. a tensor,\nwe first have to enable the gradient computation by ``tensor.requires_grad_()``\n\n<div class=\"alert alert-info\"><h4>Note</h4><p>The DPS algorithm assumes that the images are in the range [-1, 1], whereas standard denoisers\n          usually output images in the range [0, 1]. This is why we rescale the images before applying the steps.</p></div>\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "x0 = x_true * 2.0 - 1.0  # [0, 1] -> [-1, 1]\n\ndata_fidelity = L2()\n\n# xt ~ q(xt|x0)\nt = 200  # choose some arbitrary timestep\nat = alphas[t]\nsigma_cur = (1 - at).sqrt() / at.sqrt()\nxt = x0 + sigma_cur * torch.randn_like(x0)\n\n# DPS\nwith torch.enable_grad():\n    # Turn on gradient\n    xt.requires_grad_()\n\n    # normalize to [0, 1], denoise, and rescale to [-1, 1]\n    x0_t = model(xt / 2 + 0.5, sigma_cur / 2) * 2 - 1\n    # Log-likelihood\n    ll = data_fidelity(x0_t, y, physics).sqrt().sum()\n    # Take gradient w.r.t. xt\n    grad_ll = torch.autograd.grad(outputs=ll, inputs=xt)[0]\n\n# Visualize\nplot(\n    {\n        \"Ground Truth\": x0,\n        \"Noisy\": xt,\n        \"Posterior Mean\": x0_t,\n        \"Gradient\": grad_ll,\n    }\n)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## DPS Algorithm\n\nAs we visited all the key components of DPS, we are now ready to define the algorithm. For every denoising\ntimestep, the algorithm iterates the following\n\n1. Get $\\hat{\\mathbf{x}}$ using the denoiser network.\n2. Compute $\\nabla_{\\mathbf{x}_t} \\log p(\\mathbf{y}|\\hat{\\mathbf{x}}_t)$ through backpropagation.\n3. Perform reverse diffusion sampling with DDPM(IM), corresponding to an update with $\\nabla_{\\mathbf{x}_t} \\log p(\\mathbf{x}_t)$.\n4. Take a gradient step with $\\nabla_{\\mathbf{x}_t} \\log p(\\mathbf{y}|\\hat{\\mathbf{x}}_t)$.\n\nThere are two caveats here. First, in the original work, DPS used DDPM ancestral sampling. As the DDIM sampler :footcite:t:`song2020denoising`\nis a generalization of DDPM in a sense that it retrieves DDPM when\n$\\eta = 1.0$, here we consider DDIM sampling.\nOne can freely choose the $\\eta$ parameter here, but since we will consider 1000\nneural function evaluations (NFEs),\nit is advisable to keep it $\\eta = 1.0$. Second, when taking the log-likelihood gradient step,\nthe gradient is weighted so that the actual implementation is a static step size times the $\\ell_2$\nnorm of the residual:\n\n\\begin{align}\\nabla_{\\mathbf{x}_t} \\log p(\\mathbf{y}|\\hat{\\mathbf{x}}_{t}(\\mathbf{x}_t)) \\simeq\n          \\rho \\nabla_{\\mathbf{x}_t} \\|\\mathbf{y} - \\mathbf{A}\\hat{\\mathbf{x}}_{t}\\|_2\\end{align}\n\nWith these in mind, let us solve the inverse problem with DPS!\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<div class=\"alert alert-info\"><h4>Note</h4><p>We only use 200 steps to reduce the computational time of this example. As suggested by the authors of DPS, the\n  algorithm works best with ``num_steps = 1000``.</p></div>\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "num_steps = 200\n\nskip = num_train_timesteps // num_steps\n\nbatch_size = 1\neta = 1.0  # DDPM scheme; use eta < 1 for DDIM\n\n\n# measurement\nx0 = x_true * 2.0 - 1.0\n# x0 = x_true.clone()\ny = physics(x0.to(device))\n\n# initial sample from x_T\nx = torch.randn_like(x0)\n\nxs = [x]\nx0_preds = []\n\nfor t in tqdm(reversed(range(0, num_train_timesteps, skip))):\n    at = alphas[t]\n    at_next = alphas[t - skip] if t - skip >= 0 else torch.tensor(1)\n    # we cannot use bt = betas[t] if skip > 1:\n    bt = 1 - at / at_next\n\n    xt = xs[-1].to(device)\n\n    with torch.enable_grad():\n        xt.requires_grad_()\n\n        # 1. denoising step\n        aux_x = xt / (2 * at.sqrt()) + 0.5  # renormalize in [0, 1]\n        sigma_cur = (1 - at).sqrt() / at.sqrt()  # sigma_t\n\n        x0_t = 2 * model(aux_x, sigma_cur / 2) - 1\n        x0_t = torch.clip(x0_t, -1.0, 1.0)  # optional\n\n        # 2. likelihood gradient approximation\n        l2_loss = data_fidelity(x0_t, y, physics).sqrt().sum()\n\n    norm_grad = torch.autograd.grad(outputs=l2_loss, inputs=xt)[0]\n    norm_grad = norm_grad.detach()\n\n    sigma_tilde = (bt * (1 - at_next) / (1 - at)).sqrt() * eta\n    c2 = ((1 - at_next) - sigma_tilde**2).sqrt()\n\n    # 3. noise step\n    epsilon = torch.randn_like(xt)\n\n    # 4. DDIM(PM) step\n    xt_next = (\n        (at_next.sqrt() - c2 * at.sqrt() / (1 - at).sqrt()) * x0_t\n        + sigma_tilde * epsilon\n        + c2 * xt / (1 - at).sqrt()\n        - norm_grad\n    )\n    x0_preds.append(x0_t.to(\"cpu\"))\n    xs.append(xt_next.to(\"cpu\"))\n\nrecon = xs[-1]\n\n# plot the results\nx = recon / 2 + 0.5\nplot(\n    {\n        \"Measurement\": y,\n        \"Model Output\": x,\n        \"Ground Truth\": x_true,\n    }\n)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Using DPS in your inverse problem\nYou can readily use this algorithm via the :class:`deepinv.sampling.DPS` class.\n\n::\n\n      y = physics(x)\n      model = dinv.sampling.DPS(dinv.models.DiffUNet(), data_fidelity=dinv.optim.data_fidelity.L2())\n      xhat = model(y, physics)\n\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        ":References:\n\n.. footbibliography::\n\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}