{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# \ud83d\ude80 To get started, install DeepInverse by creating a new cell and running `%pip install deepinv`"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n# Self-supervised denoising with the UNSURE loss.\n\nThis example shows you how to train a denoiser network in a fully self-supervised way,\ni.e., using noisy images with unknown noise level only via the UNSURE loss, which is introduced by :footcite:t:`tachella2024unsure`.\n\nThe UNSURE optimization problem for Gaussian denoising with unknown noise level is defined as:\n\n\\begin{align}\\min_{R} \\max_{\\sigma^2} \\frac{1}{m}\\|y-\\inverse{y}\\|_2^2 +\\frac{2\\sigma^2}{m\\tau}b^{\\top} \\left(\\inverse{y+\\tau b}-\\inverse{y}\\right)\\end{align}\n\nwhere $R$ is the trainable network, $y$ is the noisy image with $m$ pixels,\n$b\\sim \\mathcal{N}(0,1)$ is a Gaussian random variable,\n$\\tau$ is a small positive number, and $\\odot$ is an elementwise multiplication.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "from pathlib import Path\n\nimport torch\nfrom torch.utils.data import DataLoader\nfrom torchvision import transforms, datasets\n\nimport deepinv as dinv\nfrom deepinv.utils import get_data_home"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Setup paths for data loading and results.\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "BASE_DIR = Path(\".\")\nDATA_DIR = BASE_DIR / \"measurements\"\nCKPT_DIR = BASE_DIR / \"ckpts\"\nORIGINAL_DATA_DIR = get_data_home()\n\n# Set the global random seed from pytorch to ensure reproducibility of the example.\ntorch.manual_seed(0)\n\ndevice = dinv.utils.get_freer_gpu() if torch.cuda.is_available() else \"cpu\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Load base image datasets\nIn this example, we use the MNIST dataset as the base image dataset.\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "operation = \"denoising\"\ntrain_dataset_name = \"MNIST\"\n\ntransform = transforms.Compose([transforms.ToTensor()])\n\ntrain_dataset = datasets.MNIST(\n    root=ORIGINAL_DATA_DIR, train=True, transform=transform, download=True\n)\ntest_dataset = datasets.MNIST(\n    root=ORIGINAL_DATA_DIR, train=False, transform=transform, download=True\n)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Generate a dataset of noisy images\n\nWe generate a dataset of noisy images corrupted by Gaussian noise.\n\n<div class=\"alert alert-info\"><h4>Note</h4><p>We use a subset of the whole training set to reduce the computational load of the example.\n      We recommend to use the whole set by setting ``n_images_max=None`` to get the best results.</p></div>\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "true_sigma = 0.1\n\n# defined physics\nphysics = dinv.physics.Denoising(dinv.physics.GaussianNoise(sigma=true_sigma))\n\n# Use parallel dataloader if using a GPU to speed up training,\n# otherwise, as all computes are on CPU, use synchronous data loading.\nnum_workers = 4 if torch.cuda.is_available() else 0\n\nn_images_max = (\n    100 if torch.cuda.is_available() else 5\n)  # number of images used for training\n\nmeasurement_dir = DATA_DIR / train_dataset_name / operation\ndeepinv_datasets_path = dinv.datasets.generate_dataset(\n    train_dataset=train_dataset,\n    test_dataset=test_dataset,\n    physics=physics,\n    device=device,\n    save_dir=measurement_dir,\n    train_datapoints=n_images_max,\n    test_datapoints=n_images_max,\n    num_workers=num_workers,\n    dataset_filename=\"demo_sure\",\n)\n\ntrain_dataset = dinv.datasets.HDF5Dataset(path=deepinv_datasets_path, train=True)\ntest_dataset = dinv.datasets.HDF5Dataset(path=deepinv_datasets_path, train=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Set up the denoiser network\n\nWe use a simple U-Net architecture with 2 scales as the denoiser network.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "model = dinv.models.ArtifactRemoval(\n    dinv.models.UNet(in_channels=1, out_channels=1, scales=2).to(device)\n)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Set up the training parameters\nWe set :class:`deepinv.loss.SureGaussianLoss` as the training loss with the ``unsure=True`` option.\nThe optimization with respect to the noise level is done by stochastic gradient descent with momentum\ninside the loss class, so it is seamlessly integrated into the training process.\n\n<div class=\"alert alert-info\"><h4>Note</h4><p>There are (UN)SURE losses for various noise distributions. See also :class:`deepinv.loss.SurePGLoss` for mixed Poisson-Gaussian noise.</p></div>\n\n<div class=\"alert alert-info\"><h4>Note</h4><p>We train for only 10 epochs to reduce the computational load of the example. We recommend to train for more epochs to get the best results.</p></div>\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "epochs = 10  # choose training epochs\nlearning_rate = 5e-4\nbatch_size = 32 if torch.cuda.is_available() else 1\n\nsigma_init = 0.05  # initial guess for the noise level\nstep_size = 1e-4  # step size for the optimization of the noise level\nmomentum = 0.9  # momentum for the optimization of the noise level\n\n# choose self-supervised training loss\nloss = dinv.loss.SureGaussianLoss(\n    sigma=sigma_init, unsure=True, step_size=step_size, momentum=momentum\n)\n\n# choose optimizer and scheduler\noptimizer = torch.optim.Adam(model.parameters(), lr=learning_rate, weight_decay=1e-8)\n\nprint(f\"INIT. noise level {loss.sigma2.sqrt().item():.3f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Train the network\nWe train the network using the :class:`deepinv.Trainer` class.\n\nTo simulate a realistic self-supervised learning scenario, we do not use any supervised metrics for training,\nsuch as PSNR or SSIM, which require clean ground truth images.\n\n.. tip::\n\n      We can use the same self-supervised loss for evaluation (without updating the noise level, which is equivalent to SURE with the estimated noise level),\n      as it does not require clean images,\n      to monitor the training process (e.g. for early stopping). This is done automatically when `metrics=None` and `early_stop>0` in the trainer.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "train_dataloader = DataLoader(\n    train_dataset, batch_size=batch_size, num_workers=num_workers, shuffle=True\n)\n\n# Initialize the trainer\ntrainer = dinv.Trainer(\n    model=model,\n    physics=physics,\n    epochs=epochs,\n    losses=loss,\n    compute_eval_losses=True,  # use self-supervised loss for evaluation\n    early_stop_on_losses=True,  # stop using self-supervised eval loss\n    metrics=None,  # no supervised metrics\n    early_stop=2,  # early stop using the self-supervised loss on the test set\n    optimizer=optimizer,\n    device=device,\n    train_dataloader=train_dataloader,\n    eval_dataloader=train_dataloader,\n    plot_images=False,\n    save_path=str(CKPT_DIR / operation),\n    verbose=True,  # print training information\n    show_progress_bar=False,  # disable progress bar for better vis in sphinx gallery.\n)\n\n# Train the network\nmodel = trainer.train()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Check learned noise level\nWe can verify the learned noise level by checking the estimated noise level from the loss function.\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "est_sigma = loss.sigma2.sqrt().item()\n\nprint(f\"LEARNED noise level {est_sigma:.3f}\")\nprint(f\"Estimation error noise level {abs(est_sigma-true_sigma):.3f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Test the network\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "test_dataloader = DataLoader(\n    test_dataset, batch_size=batch_size, num_workers=num_workers, shuffle=False\n)\n\ntrainer.plot_images = True\ntrainer.test(test_dataloader=test_dataloader, metrics=dinv.metric.PSNR())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        ":References:\n\n.. footbibliography::\n\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}