{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# \ud83d\ude80 To get started, install DeepInverse by creating a new cell and running `%pip install deepinv`"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n# Unfolded Chambolle-Pock for constrained image inpainting\n\nImage inpainting consists in solving $y = Ax$ where $A$ is a mask operator.\nThis problem can be reformulated as the following minimization problem:\n\n\\begin{align}\\begin{equation*}\n    \\underset{x}{\\operatorname{min}} \\,\\, \\iota_{\\mathcal{B}_2(y, r)}(Ax) + \\regname(x)\n    \\end{equation*}\\end{align}\n\n\nwhere $\\iota_{\\mathcal{B}_2(y, r)}$ is the indicator function of the ball of radius $r$ centered at\n$y$ for the $\\ell_2$ norm, and $\\regname$ is a regularisation. Recall that the indicator function of\na convex set $\\mathcal{C}$ is defined as $\\iota_{\\mathcal{C}}(x) = 0$ if $x \\in \\mathcal{C}$ and\n$\\iota_{\\mathcal{C}}(x) = +\\infty$ otherwise.\n\nIn this example, we unfold the Chambolle-Pock algorithm to solve this problem, and learn the thresholding parameters of\na wavelet denoiser in a LISTA fashion.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "from pathlib import Path\nimport torch\nfrom torch.utils.data import DataLoader\nfrom torchvision import transforms\nimport deepinv as dinv\nfrom deepinv.utils import load_dataset\nfrom deepinv.optim.data_fidelity import IndicatorL2\nfrom deepinv.optim.prior import PnP\nfrom deepinv.unfolded import unfolded_builder"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Setup paths for data loading and results.\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "BASE_DIR = Path(\".\")\nDATA_DIR = BASE_DIR / \"measurements\"\nCKPT_DIR = BASE_DIR / \"ckpts\"\n\n# Set the global random seed from pytorch to ensure reproducibility of the example.\ntorch.manual_seed(0)\n\ndevice = dinv.utils.get_freer_gpu() if torch.cuda.is_available() else \"cpu\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Load base image datasets and degradation operators.\nIn this example, we use the CBSD68 dataset for training and the set3c dataset for testing.\nWe work with images of size 32x32 if no GPU is available, else 128x128.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "operation = \"inpainting\"\ntrain_dataset_name = \"CBSD68\"\ntest_dataset_name = \"set3c\"\nimg_size = 128 if torch.cuda.is_available() else 32\n\ntest_transform = transforms.Compose(\n    [transforms.CenterCrop(img_size), transforms.ToTensor()]\n)\ntrain_transform = transforms.Compose(\n    [transforms.RandomCrop(img_size), transforms.ToTensor()]\n)\n\ntrain_base_dataset = load_dataset(train_dataset_name, transform=train_transform)\ntest_base_dataset = load_dataset(test_dataset_name, transform=test_transform)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Define forward operator and generate dataset\nWe define an inpainting operator that randomly masks pixels with probability 0.5.\n\nA dataset of pairs of measurements and ground truth images is then generated using the\n:func:`deepinv.datasets.generate_dataset` function.\n\nOnce the dataset is generated, we can load it using the :class:`deepinv.datasets.HDF5Dataset` class.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "n_channels = 3  # 3 for color images, 1 for gray-scale images\nprobability_mask = 0.5  # probability to mask pixel\n\n# Generate inpainting operator\nphysics = dinv.physics.Inpainting(\n    img_size=(n_channels, img_size, img_size), mask=probability_mask, device=device\n)\n\n\n# Use parallel dataloader if using a GPU to speed up training,\n# otherwise, as all computes are on CPU, use synchronous data loading.\nnum_workers = 4 if torch.cuda.is_available() else 0\nn_images_max = (\n    100 if torch.cuda.is_available() else 50\n)  # maximal number of images used for training\nmy_dataset_name = \"demo_training_inpainting\"\nmeasurement_dir = DATA_DIR / train_dataset_name / operation\ndeepinv_datasets_path = dinv.datasets.generate_dataset(\n    train_dataset=train_base_dataset,\n    test_dataset=test_base_dataset,\n    physics=physics,\n    device=device,\n    save_dir=measurement_dir,\n    train_datapoints=n_images_max,\n    num_workers=num_workers,\n    dataset_filename=str(my_dataset_name),\n)\n\ntrain_dataset = dinv.datasets.HDF5Dataset(path=deepinv_datasets_path, train=True)\ntest_dataset = dinv.datasets.HDF5Dataset(path=deepinv_datasets_path, train=False)\n\n\ntrain_batch_size = 32 if torch.cuda.is_available() else 3\ntest_batch_size = 32 if torch.cuda.is_available() else 3\n\ntrain_dataloader = DataLoader(\n    train_dataset, batch_size=train_batch_size, num_workers=num_workers, shuffle=True\n)\ntest_dataloader = DataLoader(\n    test_dataset, batch_size=test_batch_size, num_workers=num_workers, shuffle=False\n)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Set up the reconstruction network\nWe unfold the Chambolle-Pock algorithm as follows:\n\n     .. math::\n         \\begin{equation*}\n         \\begin{aligned}\n         u_{k+1} &= \\operatorname{prox}_{\\sigma d^*}(u_k + \\sigma A z_k) \\\\\n         x_{k+1} &= \\operatorname{D_{\\sigma}}(x_k-\\tau A^\\top u_{k+1}) \\\\\n         z_{k+1} &= 2x_{k+1} -x_k \\\\\n         \\end{aligned}\n         \\end{equation*}\n\nwhere $\\operatorname{D_{\\sigma}}$ is a wavelet denoiser with thresholding parameters $\\sigma$.\n\nThe learnable parameters of our network are $\\tau$ and $\\sigma$.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# Select the data fidelity term\ndata_fidelity = IndicatorL2(radius=0.0)\n\n# Set up the trainable denoising prior; here, the soft-threshold in a wavelet basis.\n# If the prior is initialized with a list of length max_iter,\n# then a distinct weight is trained for each CP iteration.\n# For fixed trained model prior across iterations, initialize with a single model.\nmax_iter = 30 if torch.cuda.is_available() else 20  # Number of unrolled iterations\nlevel = 3\nprior = [\n    PnP(denoiser=dinv.models.WaveletDenoiser(wv=\"db8\", level=level, device=device))\n    for i in range(max_iter)\n]\n\n# Unrolled optimization algorithm parameters\nstepsize = [\n    1.0\n] * max_iter  # initialization of the stepsizes. A distinct stepsize is trained for each iteration.\nsigma_denoiser = [\n    0.01 * torch.ones(1, level, 3)\n] * max_iter  # thresholding parameters \\sigma\n\nstepsize_dual = 1.0  # dual stepsize for Chambolle-Pock\n\n# Define the parameters of the unfolded Primal-Dual Chambolle-Pock algorithm\n# The CP algorithm requires to specify `params_algo`` the linear operator and its adjoint on which splitting is performed.\n# See the documentation of the CP algorithm :class:`deepinv.optim.optim_iterators.CPIteration` for more details.\nparams_algo = {\n    \"stepsize\": stepsize,  # Stepsize for the primal update.\n    \"g_param\": sigma_denoiser,  # prior parameter.\n    \"stepsize_dual\": stepsize_dual,  # The CP algorithm requires a second stepsize ``sigma`` for the dual update.\n    \"K\": physics.A,\n    \"K_adjoint\": physics.A_adjoint,\n}\n\n# define which parameters from 'params_algo' are trainable\ntrainable_params = [\"g_param\", \"stepsize\"]\n\n\n# Because the CP algorithm uses more than 2 variables, we need to define a custom initialization.\ndef custom_init_CP(y, physics):\n    x_init = physics.A_adjoint(y)\n    u_init = y\n    return {\"est\": (x_init, x_init, u_init)}\n\n\n# Define the unfolded trainable model.\nmodel = unfolded_builder(\n    iteration=\"CP\",\n    trainable_params=trainable_params,\n    params_algo=params_algo.copy(),\n    data_fidelity=data_fidelity,\n    max_iter=max_iter,\n    prior=prior,\n    g_first=False,\n    custom_init=custom_init_CP,\n)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Train the model\nWe train the model using the :class:`deepinv.Trainer` class.\n\nWe perform supervised learning and use the mean squared error as loss function. This can be easily done using the\n:class:`deepinv.loss.SupLoss` class.\n\n<div class=\"alert alert-info\"><h4>Note</h4><p>In this example, we only train for a few epochs to keep the training time short on CPU.\n      For a good reconstruction quality, we recommend to train for at least 50 epochs.</p></div>\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "epochs = 10 if torch.cuda.is_available() else 5  # choose training epochs\nlearning_rate = 1e-3\n\nverbose = True  # print training information\n\n# choose training losses\nlosses = dinv.loss.SupLoss(metric=dinv.metric.MSE())\n\n# choose optimizer and scheduler\noptimizer = torch.optim.Adam(model.parameters(), lr=learning_rate, weight_decay=1e-8)\nscheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=int(epochs * 0.8))\n\ntrainer = dinv.Trainer(\n    model=model,\n    scheduler=scheduler,\n    losses=losses,\n    device=device,\n    optimizer=optimizer,\n    physics=physics,\n    train_dataloader=train_dataloader,\n    save_path=str(CKPT_DIR / operation),\n    verbose=verbose,\n    show_progress_bar=False,  # disable progress bar for better vis in sphinx gallery.\n    epochs=epochs,\n)\n\nmodel = trainer.train()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Test the network\nWe can now test the trained network using the :func:`deepinv.test` function.\n\nThe testing function will compute test_psnr metrics and plot and save the results.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "plot_images = True\nmethod = \"artifact_removal\"\n\ntrainer.test(test_dataloader)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Saving the model\nWe can save the trained model following the standard PyTorch procedure.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# Save the model\ntorch.save(model.state_dict(), CKPT_DIR / operation / \"model.pth\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Loading the model\nSimilarly, we can load our trained unfolded architecture following the standard PyTorch procedure.\nTo check that the loading is performed correctly, we use new variables for the initialization of the model.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# Set up the trainable denoising prior; here, the soft-threshold in a wavelet basis.\nlevel = 3\nmodel_spec = {\n    \"name\": \"waveletprior\",\n    \"args\": {\"wv\": \"db8\", \"level\": level, \"device\": device},\n}\n# If the prior is initialized with a list of length max_iter,\n# then a distinct weight is trained for each PGD iteration.\n# For fixed trained model prior across iterations, initialize with a single model.\nmax_iter = 30 if torch.cuda.is_available() else 20  # Number of unrolled iterations\nprior_new = [\n    PnP(denoiser=dinv.models.WaveletDenoiser(wv=\"db8\", level=level, device=device))\n    for i in range(max_iter)\n]\n\n# Unrolled optimization algorithm parameters\nstepsize = [\n    1.0\n] * max_iter  # initialization of the stepsizes. A distinct stepsize is trained for each iteration.\nsigma_denoiser = [0.01 * torch.ones(1, level, 3)] * max_iter\nstepsize_dual = 1.0  # stepsize for Chambolle-Pock\n\nparams_algo_new = {\n    \"stepsize\": stepsize,\n    \"g_param\": sigma_denoiser,\n    \"stepsize_dual\": stepsize_dual,\n    \"K\": physics.A,\n    \"K_adjoint\": physics.A_adjoint,\n}\n\nmodel_new = unfolded_builder(\n    \"CP\",\n    trainable_params=trainable_params,\n    params_algo=params_algo_new,\n    data_fidelity=data_fidelity,\n    max_iter=max_iter,\n    prior=prior_new,\n    g_first=False,\n    custom_init=custom_init_CP,\n)\nmodel_new.load_state_dict(torch.load(CKPT_DIR / operation / \"model.pth\"))\nmodel_new.eval()\n\n# Test the model and check that the results are the same as before saving\ndinv.training.test(\n    model_new, test_dataloader, physics=physics, device=device, show_progress_bar=False\n)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}