{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# \ud83d\ude80 To get started, install DeepInverse by creating a new cell and running `%pip install deepinv`"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n# Building your custom MCMC sampling algorithm.\n\nThis code shows how to build your custom sampling kernel. Here we build a preconditioned Unadjusted Langevin\nAlgorithm (PreconULA) that takes advantage of the singular value decomposition of the forward operator\nto accelerate the sampling.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "import torch\nfrom typing import Any\nimport deepinv as dinv\nfrom deepinv.utils.plotting import plot\nfrom deepinv.utils import load_example"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Load image from the internet\n\nThis example uses an image of Messi.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "device = dinv.utils.get_freer_gpu() if torch.cuda.is_available() else \"cpu\"\n\nx = load_example(\"messi.jpg\", img_size=32).to(device)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Define forward operator and noise model\n\nWe use a 5x5 box blur as the forward operator and Gaussian noise as the noise model.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "sigma = 0.001  # noise level\nphysics = dinv.physics.BlurFFT(\n    img_size=(3, 32, 32),\n    filter=torch.ones((1, 1, 5, 5), device=device) / 25,\n    device=device,\n    noise_model=dinv.physics.GaussianNoise(sigma=sigma),\n)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Generate the measurement\nApply the forward model to generate the noisy measurement.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "y = physics(x)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Define the sampling iteration\n\nIn order to define a custom sampling kernel (possibly a Markov kernel which depends on the previous sample),\nwe only need to define the iterator which takes the current sample and returns the next sample.\n\nHere we define a preconditioned ULA iterator (for a Gaussian likelihood),\nwhich takes into account the singular value decomposition\nof the forward operator, $A=USV^{\\top}$, in order to accelerate the sampling.\n\nWe modify the standard ULA iteration (see :class:`deepinv.sampling.ULAIterator`) defined as\n\n\\begin{align}x_{k+1} = x_{k} + \\frac{\\eta}{\\sigma^2} A^{\\top}(y-Ax_{k}) +\n       \\eta \\alpha \\nabla \\log p(x_{k}) + \\sqrt{2\\eta}z_{k+1}\\end{align}\n\n\nby using a matrix-valued step size $\\eta = \\eta_0 VRV^{\\top}$ where\n$R$ is a diagonal matrix with entries $R_{i,i} = \\frac{1}{S_{i,i}^2 + \\epsilon}$.\nThe parameter $\\epsilon$ is used to avoid numerical issues when $S_{i,i}^2$ is close to zero.\nAfter some algebra, we obtain the following iteration\n\n\\begin{align}x_{k+1} = x_{k} + \\frac{\\eta_0}{\\sigma^2}  V R S (U^{\\top}y - S V^{\\top}x_{k})\n       +\\eta_0  \\alpha V R V^{\\top}\\nabla \\log p(x_{k}) + \\sqrt{2\\eta_0}V\\sqrt{R}z_{k+1}\\end{align}\n\nWe exploit the methods of :class:`deepinv.physics.DecomposablePhysics` to compute the matrix-vector products\nwith $V$ and $V^{\\top}$ efficiently. Note that computing the matrix-vector product with $R$ and\n$S$ is trivial since they are diagonal matrices.\nSee :class:`deepinv.sampling.BaseSampling` for more details on how to create new iterators.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "class PreconULAIterator(dinv.sampling.SamplingIterator):\n    def __init__(self, algo_params):\n        super().__init__(algo_params)\n\n    def forward(self, X, y, physics, data_fidelity, prior, iteration) -> dict[str, Any]:\n        x = X[\"x\"]\n        x_bar = physics.V_adjoint(x)\n        y_bar = physics.U_adjoint(y)\n\n        step_size = self.algo_params[\"step_size\"] / (\n            self.algo_params[\"epsilon\"] + physics.mask.pow(2)\n        )\n\n        noise = torch.randn_like(x_bar)\n        sigma2_noise = 1 / data_fidelity.norm\n        lhood = -(physics.mask.pow(2) * x_bar - physics.mask * y_bar) / sigma2_noise\n        lprior = (\n            -physics.V_adjoint(prior.grad(x, self.algo_params[\"sigma\"]))\n            * self.algo_params[\"alpha\"]\n        )\n\n        return {\n            \"x\": x\n            + physics.V(step_size * (lhood + lprior) + (2 * step_size).sqrt() * noise)\n        }"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Define the prior\n\nThe score of a distribution can be approximated using a plug-and-play denoiser via the\n:class:`deepinv.optim.ScorePrior` class.\n\n\\begin{align}\\nabla \\log p_{\\sigma_d}(x) \\approx \\frac{1}{\\sigma_d^2} \\left(D(x) - x\\right)\\end{align}\n\nThis example uses a simple median filter as a plug-and-play denoiser.\nThe hyperparameter $\\sigma_d$ controls the strength of the prior.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "prior = dinv.optim.ScorePrior(denoiser=dinv.models.MedianFilter())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Build our sampler\n\nUsing our custom iterator, we can build a sampler class by calling :func:`deepinv.sampling.sampling_builder`\nThis function returns an instance of :class:`deepinv.sampling.BaseSampling` which takes care of the sampling procedure\n(calculating mean and variance, taking into account sample thinning and burnin iterations, etc),\nproviding a convenient interface to the user.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# load Gaussian Likelihood\nlikelihood = dinv.optim.data_fidelity.L2(sigma=sigma)\n\niterations = int(1e2) if torch.cuda.is_available() else 10\n\n# shared ULA/ PreconULA params\nstep_size = 0.5 * (sigma**2)\ndenoiser_sigma = 0.1\n\n# parameters for PreconULA\nparams_preconula = {\n    \"step_size\": step_size,\n    \"sigma\": denoiser_sigma,\n    \"alpha\": 1.0,\n    \"epsilon\": 0.01,\n}\n\n# build our PreconULA sampler\npreconula = dinv.sampling.sampling_builder(\n    PreconULAIterator(params_preconula),\n    likelihood,\n    prior,\n    max_iter=iterations,\n    burnin_ratio=0.1,\n    thinning=1,\n    verbose=True,\n)\n\n# parameters for ULA\nparams_ula = {\n    \"step_size\": step_size,\n    \"sigma\": denoiser_sigma,\n    \"alpha\": 1.0,\n}\n\n# build our ULA sampler\nula = dinv.sampling.sampling_builder(\n    \"ULA\",\n    likelihood,\n    prior,\n    params_algo=params_ula,\n    max_iter=iterations,\n    burnin_ratio=0.1,\n    thinning=1,\n    verbose=True,\n)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Run sampling algorithms and plot results\nEach sampling algorithm returns the posterior mean and variance.\nWe compare the posterior mean of each algorithm with a simple linear reconstruction.\n\nThe preconditioned step size of the new sampler provides a significant acceleration to standard ULA,\nwhich is evident in the PSNR of the posterior mean.\n\n<div class=\"alert alert-info\"><h4>Note</h4><p>The preconditioned ULA sampler requires a forward operator with an easy singular value decomposition\n  (e.g. which inherit from :class:`deepinv.physics.DecomposablePhysics`) and the noise to be Gaussian,\n  whereas ULA is more general.</p></div>\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "ula_mean, ula_var = ula.sample(y, physics)\n\npreconula_mean, preconula_var = preconula.sample(y, physics)\n\n# compute linear inverse\nx_lin = physics.A_adjoint(y)\n\n# compute PSNR\npsnr_lin = dinv.metric.PSNR()(x, x_lin).item()\npsnr_ula = dinv.metric.PSNR()(x, ula_mean).item()\npsnr_preconula = dinv.metric.PSNR()(x, preconula_mean).item()\nprint(f\"Linear reconstruction PSNR: {psnr_lin:.2f} dB\")\nprint(f\"ULA posterior mean PSNR: {psnr_ula:.2f} dB\")\nprint(f\"PreconULA posterior mean PSNR: {psnr_preconula:.2f} dB\")\n\n# plot results\nplot(\n    {\n        \"Ground Truth\": x,\n        \"Measurement\": y,\n        \"ULA\": ula_mean,\n        \"PreconULA\": preconula_mean,\n    },\n    subtitles=[\n        f\"PSNR:\",\n        f\"{psnr_lin:.2f} dB\",\n        f\"{psnr_ula:.2f} dB\",\n        f\"{psnr_preconula:.2f} dB\",\n    ],\n)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}