{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# \ud83d\ude80 To get started, install DeepInverse by creating a new cell and running `%pip install deepinv`"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n# Learned Iterative Soft-Thresholding Algorithm (LISTA) for compressed sensing\n\nThis example shows how to implement the LISTA algorithm :footcite:t:`gregor2010learning`,\nfor a compressed sensing problem. In a nutshell, LISTA is an unfolded proximal gradient algorithm involving a\nsoft-thresholding proximal operator with learnable thresholding parameters.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "from pathlib import Path\nimport torch\nfrom torchvision import datasets\nfrom torchvision import transforms\n\nimport deepinv as dinv\nfrom torch.utils.data import DataLoader\nfrom deepinv.optim.data_fidelity import L2\nfrom deepinv.unfolded import unfolded_builder\nfrom deepinv.utils import get_data_home"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Setup paths for data loading and results.\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "BASE_DIR = Path(\".\")\nDATA_DIR = BASE_DIR / \"measurements\"\nRESULTS_DIR = BASE_DIR / \"results\"\nCKPT_DIR = BASE_DIR / \"ckpts\"\nORIGINAL_DATA_DIR = get_data_home()\n\n# Set the global random seed from pytorch to ensure reproducibility of the example.\ntorch.manual_seed(0)\n\ndevice = dinv.utils.get_freer_gpu() if torch.cuda.is_available() else \"cpu\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Load base image datasets and degradation operators.\nIn this example, we use MNIST as the base dataset.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "img_size = 28\nn_channels = 1\noperation = \"compressed-sensing\"\ntrain_dataset_name = \"MNIST_train\"\n\n# Generate training and evaluation datasets in HDF5 folders and load them.\ntrain_test_transform = transforms.Compose([transforms.ToTensor()])\ntrain_base_dataset = datasets.MNIST(\n    root=ORIGINAL_DATA_DIR, train=True, transform=train_test_transform, download=True\n)\ntest_base_dataset = datasets.MNIST(\n    root=ORIGINAL_DATA_DIR, train=False, transform=train_test_transform, download=True\n)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Generate a dataset of compressed measurements and load it.\nWe use the compressed sensing class from the physics module to generate a dataset of highly-compressed measurements\n(10% of the total number of pixels).\n\nThe forward operator is defined as $y = Ax$\nwhere $A$ is a (normalized) random Gaussian matrix.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# Use parallel dataloader if using a GPU to speed up training, otherwise, as all computes are on CPU, use synchronous\n# data loading.\nnum_workers = 4 if torch.cuda.is_available() else 0\n\n# Generate the compressed sensing measurement operator with 10x under-sampling factor.\nphysics = dinv.physics.CompressedSensing(\n    m=78, img_size=(n_channels, img_size, img_size), fast=True, device=device\n)\nmy_dataset_name = \"demo_LISTA\"\nn_images_max = (\n    1000 if torch.cuda.is_available() else 200\n)  # maximal number of images used for training\nmeasurement_dir = DATA_DIR / train_dataset_name / operation\ngenerated_datasets_path = dinv.datasets.generate_dataset(\n    train_dataset=train_base_dataset,\n    test_dataset=test_base_dataset,\n    physics=physics,\n    device=device,\n    save_dir=measurement_dir,\n    train_datapoints=n_images_max,\n    test_datapoints=8,\n    num_workers=num_workers,\n    dataset_filename=str(my_dataset_name),\n)\n\ntrain_dataset = dinv.datasets.HDF5Dataset(path=generated_datasets_path, train=True)\ntest_dataset = dinv.datasets.HDF5Dataset(path=generated_datasets_path, train=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Define the unfolded Proximal Gradient algorithm.\nIn this example, following the original LISTA algorithm :footcite:t:`gregor2010learning`\nthe backbone algorithm we unfold is the proximal gradient algorithm which minimizes the following objective function\n\n\\begin{align}\\begin{equation}\n         \\tag{1}\n         \\min_x \\frac{1}{2} \\|y - Ax\\|_2^2 + \\lambda \\|Wx\\|_1\n         \\end{equation}\\end{align}\n\nwhere $\\lambda$ is the regularization parameter.\nThe proximal gradient iteration (see also :class:`deepinv.optim.optim_iterators.PGDIteration`) is defined as\n\n  .. math::\n          x_{k+1} = \\text{prox}_{\\gamma \\lambda g}(x_k - \\gamma A^T (Ax_k - y))\n\nwhere $\\gamma$ is the stepsize and $\\text{prox}_{g}$ is the proximity operator of $g(x) = \\|Wx\\|_1$\nwhich corresponds to soft-thresholding with a wavelet basis (see :class:`deepinv.optim.WaveletPrior`).\n\nWe use :func:`deepinv.unfolded.unfolded_builder` to define the unfolded algorithm\nand set both the stepsizes of the LISTA algorithm $\\gamma$ (``stepsize``) and the soft\nthresholding parameters $\\lambda$ as learnable parameters.\nThese parameters are initialized with a table of length max_iter,\nyielding a distinct ``stepsize`` value for each iteration of the algorithm.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# Select the data fidelity term\ndata_fidelity = L2()\nmax_iter = 30 if torch.cuda.is_available() else 10  # Number of unrolled iterations\nstepsize = [torch.ones(1, device=device)] * max_iter  # initialization of the stepsizes.\n# A distinct stepsize is trained for each iteration.\n\n# Set up the trainable denoising prior; here, the soft-threshold in a wavelet basis.\n# If the prior is initialized with a list of length max_iter,\n# then a distinct weight is trained for each PGD iteration.\n# For fixed trained model prior across iterations, initialize with a single model.\nlevel = 3\nprior = [\n    dinv.optim.WaveletPrior(wv=\"db8\", level=level, device=device)\n    for i in range(max_iter)\n]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "In practice, it is common to apply a different thresholding parameter for each wavelet sub-band. This means that\nthe thresholding parameter is a tensor of shape (n_levels, n_wavelet_subbands) and the associated problem (1) is\nreformulated as\n\n\\begin{align}\\begin{equation}\n         \\min_x \\frac{1}{2} \\|y - Ax\\|_2^2 +  \\sum_{i, j} \\lambda_{i, j} \\|\\left(Wx\\right)_{i, j}\\|_1\n         \\end{equation}\\end{align}\n\nwhere $\\lambda_{i, j}$ is the thresholding parameter for the wavelet sub-band $j$ at level $i$.\nNote that in this case, the prior is a list of elements containing the terms $\\|\\left(Wx\\right)_{i, j}\\|_1=g_{i, j}(x)$,\nand that it is necessary that the dimension of the thresholding parameter matches that of $g_{i, j}$.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# Unrolled optimization algorithm parameters\nlamb = [\n    torch.ones(1, 3, 3, device=device)\n    * 0.01  # initialization of the regularization parameter. One thresholding parameter per wavelet sub-band and level.\n] * max_iter  # A distinct lamb is trained for each iteration.\n\n\nparams_algo = {  # wrap all the restoration parameters in a 'params_algo' dictionary\n    \"stepsize\": stepsize,\n    \"lambda\": lamb,\n}\n\ntrainable_params = [\n    \"stepsize\",\n    \"lambda\",\n]  # define which parameters from 'params_algo' are trainable\n\n# Define the unfolded trainable model.\nmodel = unfolded_builder(\n    iteration=\"PGD\",\n    params_algo=params_algo.copy(),\n    trainable_params=trainable_params,\n    data_fidelity=data_fidelity,\n    max_iter=max_iter,\n    prior=prior,\n).to(device)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Define the training parameters.\n\nWe now define training-related parameters,\nnumber of epochs, optimizer (Adam) and its hyperparameters, and the train and test batch sizes.\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# Training parameters\nepochs = 5 if torch.cuda.is_available() else 3\nlearning_rate = 0.01\n\n# Choose optimizer and scheduler\noptimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n\n# Choose supervised training loss\nlosses = [dinv.loss.SupLoss(metric=dinv.metric.MSE())]\n\n# Logging parameters\nverbose = True\n\n# Batch sizes and data loaders\ntrain_batch_size = 64 if torch.cuda.is_available() else 1\ntest_batch_size = 64 if torch.cuda.is_available() else 8\n\ntrain_dataloader = DataLoader(\n    train_dataset, batch_size=train_batch_size, num_workers=num_workers, shuffle=True\n)\ntest_dataloader = DataLoader(\n    test_dataset, batch_size=test_batch_size, num_workers=num_workers, shuffle=False\n)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Train the network.\n\nWe train the network using the :class:`deepinv.Trainer` class.\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "trainer = dinv.Trainer(\n    model,\n    physics=physics,\n    train_dataloader=train_dataloader,\n    eval_dataloader=test_dataloader,\n    epochs=epochs,\n    losses=losses,\n    optimizer=optimizer,\n    device=device,\n    save_path=str(CKPT_DIR / operation),\n    verbose=verbose,\n    show_progress_bar=False,  # disable progress bar for better vis in sphinx gallery.\n)\n\nmodel = trainer.train()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Test the network.\n\nWe now test the learned unrolled network on the test dataset. In the plotted results, the `Linear` column shows the\nmeasurements back-projected in the image domain, the `Recons` column shows the output of our LISTA network,\nand `GT` shows the ground truth.\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "trainer.test(test_dataloader)\n\ntest_sample, _ = next(iter(test_dataloader))\nmodel.eval()\ntest_sample = test_sample.to(device)\n\n# Get the measurements and the ground truth\ny = physics(test_sample)\nwith torch.no_grad():  # it is important to disable gradient computation during testing.\n    rec = model(y, physics=physics)\n\nbackprojected = physics.A_adjoint(y)\n\ndinv.utils.plot(\n    [backprojected, rec, test_sample],\n    titles=[\"Linear\", \"Reconstruction\", \"Ground truth\"],\n    suptitle=\"Reconstruction results\",\n)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Plotting the learned parameters.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "dinv.utils.plotting.plot_parameters(\n    model, init_params=params_algo, save_dir=RESULTS_DIR / \"unfolded_pgd\" / operation\n)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        ":References:\n\n.. footbibliography::\n\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}