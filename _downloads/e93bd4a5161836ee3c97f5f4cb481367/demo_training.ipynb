{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# \ud83d\ude80 To get started, install DeepInverse by creating a new cell and running `%pip install deepinv`"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n# Training a reconstruction model\n\nThis example provides a very simple quick start introduction to training reconstruction networks with\nDeepInverse for solving imaging inverse problems.\n\nTraining requires these components, all of which you can define with DeepInverse:\n\n* A `model` to be trained from `reconstructors <reconstructors>` or define your own.\n* A `physics` from our `list of physics <physics>`. Or, `bring your own physics <sphx_glr_auto_examples_basics_demo_custom_dataset.py>`.\n* A `dataset` of images and/or measurements from `datasets <datasets>`. Or, `bring your own dataset <sphx_glr_auto_examples_basics_demo_custom_dataset.py>`.\n* A `loss` from our `loss functions <loss>`.\n* A `metric` from our `metrics <metric>`.\n\nHere, we demonstrate a simple experiment of training a UNet\non an inpainting task on the Urban100 dataset of natural images.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "import deepinv as dinv\nimport torch\n\ndevice = dinv.utils.get_freer_gpu() if torch.cuda.is_available() else \"cpu\"\nrng = torch.Generator(device=device).manual_seed(0)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Setup\n\nFirst, define the physics that we want to train on.\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "physics = dinv.physics.Inpainting((1, 64, 64), mask=0.8, device=device, rng=rng)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Then define the dataset. Here we simulate a dataset of measurements from Urban100.\n\n.. tip::\n    See `datasets <datasets>` for types of datasets DeepInverse supports: e.g. paired, ground-truth-free,\n    single-image...\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "from torchvision.transforms import Compose, ToTensor, Resize, CenterCrop, Grayscale\n\ndataset = dinv.datasets.Urban100HR(\n    \".\",\n    download=True,\n    transform=Compose([ToTensor(), Grayscale(), Resize(256), CenterCrop(64)]),\n)\n\ntrain_dataset, test_dataset = torch.utils.data.random_split(\n    torch.utils.data.Subset(dataset, range(50)), (0.8, 0.2)\n)\n\ndataset_path = dinv.datasets.generate_dataset(\n    train_dataset=train_dataset,\n    test_dataset=test_dataset,\n    physics=physics,\n    device=device,\n    save_dir=\".\",\n    batch_size=1,\n)\n\ntrain_dataloader = torch.utils.data.DataLoader(\n    dinv.datasets.HDF5Dataset(dataset_path, train=True), shuffle=True\n)\ntest_dataloader = torch.utils.data.DataLoader(\n    dinv.datasets.HDF5Dataset(dataset_path, train=False), shuffle=False\n)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Visualize a data sample:\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "x, y = next(iter(test_dataloader))\ndinv.utils.plot({\"Ground truth\": x, \"Measurement\": y, \"Mask\": physics.mask})"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "For the model we use an artifact removal model, where\n$\\phi_{\\theta}$ is a U-Net\n\n\\begin{align}f_{\\theta}(y) = \\phi_{\\theta}(A^{\\top}(y))\\end{align}\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "model = dinv.models.ArtifactRemoval(\n    dinv.models.UNet(1, 1, scales=2, batch_norm=False).to(device)\n)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Train the model\nWe train the model using the :class:`deepinv.Trainer` class,\nwhich cleanly handles all steps for training.\n\nWe perform supervised learning and use the mean squared error as loss function.\nSee `losses <loss>` for all supported state-of-the-art loss functions.\n\nWe evaluate using the PSNR metric.\nSee `metrics <metric>` for all supported metrics.\n\n<div class=\"alert alert-info\"><h4>Note</h4><p>In this example, we only train for a few epochs to keep the training time short.\n      For a good reconstruction quality, we recommend to train for at least 100 epochs.</p></div>\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "trainer = dinv.Trainer(\n    model=model,\n    physics=physics,\n    optimizer=torch.optim.Adam(model.parameters(), lr=1e-3),\n    train_dataloader=train_dataloader,\n    eval_dataloader=test_dataloader,\n    epochs=5,\n    losses=dinv.loss.SupLoss(metric=dinv.metric.MSE()),\n    metrics=dinv.metric.PSNR(),\n    device=device,\n    plot_images=True,\n    show_progress_bar=False,\n)\n\n_ = trainer.train()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Test the network\nWe can now test the trained network using the :func:`deepinv.test` function.\n\nThe testing function will compute metrics and plot and save the results.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "trainer.test(test_dataloader)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}