{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# \ud83d\ude80 To get started, install DeepInverse by creating a new cell and running `%pip install deepinv`"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n# Using HuggingFace datasets\n\nThis example shows how to load and prepare properly a HuggingFace dataset\nusing the `datasets` library.\n\nAvailable datasets: https://huggingface.co/datasets?search=deepinv\nHere we use [drunet_dataset](https://github.com/samuro95/GSPnP).\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Load libraries\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "from datasets import load_dataset as load_dataset_hf\nfrom torch.utils.data import IterableDataset, DataLoader\nfrom torchvision import transforms\n\nimport deepinv as dinv"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Stream data from Internet\n\nStream data from HuggingFace servers: only a limited number of samples is loaded on memory at all time,\nwhich avoid having to save the dataset on disk and avoid overloading the memory capacity.\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# source : https://huggingface.co/datasets/deepinv/drunet_dataset\n# type : datasets.iterable_dataset.IterableDataset\nraw_hf_train_dataset = load_dataset_hf(\n    \"deepinv/drunet_dataset\", split=\"train\", streaming=True\n)\nprint(\"Number of data files used to store raw data: \", raw_hf_train_dataset.n_shards)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Shuffle data with buffer shuffling\n\n| In streaming mode, we can only read sequentially the data sample in a certain order thus we are not able to do exact shuffling.\n| An alternative way is the buffer shuffling which load a fixed number of samples in memory and let us pick randomly one sample among this fixed number of samples.\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# https://huggingface.co/docs/datasets/about_mapstyle_vs_iterable\nraw_hf_train_dataset = raw_hf_train_dataset.shuffle(seed=42, buffer_size=100)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Apply transformation on dataset\n\nWe define transformation with ``torchvision.transforms`` module, but it can be any other function.\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# Function that should be applied to a PIL Image\nimg_transforms = transforms.Compose(\n    [\n        transforms.Resize((224, 224)),  # Resize all images to 224x224\n        transforms.ToTensor(),\n    ]\n)\n\n\n# Class that apply `transform` on data samples of a datasets.iterable_dataset.IterableDataset\nclass HFDataset(IterableDataset):\n    r\"\"\"\n    Creates an iterable dataset from a HuggingFace dataset to enable streaming.\n    \"\"\"\n\n    def __init__(self, hf_dataset, transforms=None, key=\"png\"):\n        self.hf_dataset = hf_dataset\n        self.transform = transforms\n        self.key = key\n\n    def __iter__(self):\n        for sample in self.hf_dataset:\n            if self.transform:\n                out = self.transform(sample[self.key])\n            else:\n                out = sample[self.key]\n            yield out\n\n\nhf_train_dataset = HFDataset(raw_hf_train_dataset, transforms=img_transforms)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Create a dataloader\n\n| With ``datasets.iterable_dataset.IterableDataset``, data samples are stored in 1 file or in a few files.\n| In case of few files, we can use ``num_workers`` argument to load data samples in parallel.\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "if raw_hf_train_dataset.n_shards > 1:\n    # num_workers <= raw_hf_train_dataset.n_shards (number of data files)\n    # num_workers <= number of available cpu cores\n    num_workers = ...\n    train_dataloader = DataLoader(\n        hf_train_dataset, batch_size=2, num_workers=num_workers\n    )\nelse:\n    train_dataloader = DataLoader(hf_train_dataset, batch_size=2)\n\n# display a batch\nbatch = next(iter(train_dataloader))\ndinv.utils.plot([batch[0], batch[1]])"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}